{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13801528,"sourceType":"datasetVersion","datasetId":8734712}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1908.796521,"end_time":"2025-11-30T03:27:30.270175","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-30T02:55:41.473654","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"03aadf6afa81436fbfaf71b3762a7496":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_40dcdb25c1be40d5bc260c9da9ddff6a","placeholder":"​","style":"IPY_MODEL_de0089e35e21420f84b9a5d849bcc915","tabbable":null,"tooltip":null,"value":" 678/678 [00:00&lt;00:00, 78.6kB/s]"}},"0656c51f82464d42b571f2259dbf969e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06f51758899c485ab32644aedde5d478":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_46a0ec4465ea4e0bb8e516d3023c5821","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db63181ab78d4ce3b3a8dd579982b8b6","tabbable":null,"tooltip":null,"value":1}},"08bd3ad3c21c40028b830f08783cd13a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"08d5fab7d3884ba48824392711943168":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a2273ea7e6043acb6550251e4c4678f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_0e48ddfec28d4c2096a0b42d66591b45","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd4cb07be84a480d86224c652c5236fa","tabbable":null,"tooltip":null,"value":1}},"0cef14d609d3433886c56024328b6312":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e48ddfec28d4c2096a0b42d66591b45":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1ebf1ac9c1ee466b8ce15541f3a1da45":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_08bd3ad3c21c40028b830f08783cd13a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58d956194a3b49d6afe27d0c5248203a","tabbable":null,"tooltip":null,"value":1}},"22fbcfa353e94523965eefb5d5235b9d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23368cc7c7574e5aa4a024318c2682b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_69824571b7d5416fb9069170a4162f49","placeholder":"​","style":"IPY_MODEL_96d1c98433454ac6a2e290dd6458f91a","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"23a452dc33364331bb5ca4745dada4e1":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26092e486bae42aa81aa115f58536185":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"2b7e3c4cfcc54c56a4825f1ca6458cc9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31b3bca07de741d18ff82b4584a12d98":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3567b447119e42cba368d0a1e3adcffd":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3989fcd0a859443fb4c0337f8738dfed":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40dcdb25c1be40d5bc260c9da9ddff6a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41bbc730578d458ba7a8f5f195ba8406":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"4308bd9419ef492497e9840546f46810":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94e01d9fde33474d8bdc9d4bcecf765e","IPY_MODEL_06f51758899c485ab32644aedde5d478","IPY_MODEL_c71b614808d742ab90007dff25374a7c"],"layout":"IPY_MODEL_a66bf1071beb44a1b72d8dae68244641","tabbable":null,"tooltip":null}},"46a0ec4465ea4e0bb8e516d3023c5821":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"55b74c58e84a4ffe8e80b013576cd7b2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d956194a3b49d6afe27d0c5248203a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b4b49f475724f1eb083ca3b29564626":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7be242a0cf5546b9970772e2bb215324","IPY_MODEL_1ebf1ac9c1ee466b8ce15541f3a1da45","IPY_MODEL_716491fb0b204187b350942fd667134f"],"layout":"IPY_MODEL_22fbcfa353e94523965eefb5d5235b9d","tabbable":null,"tooltip":null}},"5d1ebab201114127b3070f2e4a07467a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"62c7c6e740ce4b4fa17d843976f0d56f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"62f308abc04e4f4da200835e068d4978":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"676756837e4b41038a450a4e11abb83b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6769ea4f639448d9b0b0119aafda22bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"69824571b7d5416fb9069170a4162f49":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e6877a4531349b4a3e24d6436666f8a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f648258798d4a0fb1d1603f4c1019a7":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"716491fb0b204187b350942fd667134f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6e6877a4531349b4a3e24d6436666f8a","placeholder":"​","style":"IPY_MODEL_41bbc730578d458ba7a8f5f195ba8406","tabbable":null,"tooltip":null,"value":" 3.13M/? [00:00&lt;00:00, 110MB/s]"}},"7be242a0cf5546b9970772e2bb215324":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_23a452dc33364331bb5ca4745dada4e1","placeholder":"​","style":"IPY_MODEL_c616c1bc0389404c85c3eb74f03e9f43","tabbable":null,"tooltip":null,"value":"tokenizer.json: "}},"7ee6eae0c9184cacb1c8abbc119fab04":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_55b74c58e84a4ffe8e80b013576cd7b2","placeholder":"​","style":"IPY_MODEL_5d1ebab201114127b3070f2e4a07467a","tabbable":null,"tooltip":null,"value":"vocab.txt: "}},"80685693b10240cf8ebc8742418645f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"84487cd7d7424303845ab6f93092fb59":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e90e7e41c3de406ea0bdc4c311202d08","IPY_MODEL_bdba942cfe5b47b18d9e1b6bcf768bc1","IPY_MODEL_a2fc3dcb7c83452aa4cb5e2bc0a4d531"],"layout":"IPY_MODEL_0cef14d609d3433886c56024328b6312","tabbable":null,"tooltip":null}},"94e01d9fde33474d8bdc9d4bcecf765e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_dce848b21a83477c8c2193c198253b89","placeholder":"​","style":"IPY_MODEL_62c7c6e740ce4b4fa17d843976f0d56f","tabbable":null,"tooltip":null,"value":"bpe.codes: "}},"96d1c98433454ac6a2e290dd6458f91a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"98cf29d8b21a419eb8dde9978a12e2ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_f2da7a337ef14d1398e82315d4f48478","max":678,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0656c51f82464d42b571f2259dbf969e","tabbable":null,"tooltip":null,"value":678}},"9b2f35f219924ddbb94041eb65344287":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3567b447119e42cba368d0a1e3adcffd","placeholder":"​","style":"IPY_MODEL_26092e486bae42aa81aa115f58536185","tabbable":null,"tooltip":null,"value":" 895k/? [00:00&lt;00:00, 36.0MB/s]"}},"a2538b060359434ab2d4586b0111b029":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23368cc7c7574e5aa4a024318c2682b5","IPY_MODEL_98cf29d8b21a419eb8dde9978a12e2ce","IPY_MODEL_03aadf6afa81436fbfaf71b3762a7496"],"layout":"IPY_MODEL_62f308abc04e4f4da200835e068d4978","tabbable":null,"tooltip":null}},"a2fc3dcb7c83452aa4cb5e2bc0a4d531":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6f648258798d4a0fb1d1603f4c1019a7","placeholder":"​","style":"IPY_MODEL_6769ea4f639448d9b0b0119aafda22bd","tabbable":null,"tooltip":null,"value":" 540M/540M [00:03&lt;00:00, 173MB/s]"}},"a66bf1071beb44a1b72d8dae68244641":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acbd884b920d421db11663a2911d6fd6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdba942cfe5b47b18d9e1b6bcf768bc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_31b3bca07de741d18ff82b4584a12d98","max":540322347,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3989fcd0a859443fb4c0337f8738dfed","tabbable":null,"tooltip":null,"value":540322347}},"c616c1bc0389404c85c3eb74f03e9f43":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c71b614808d742ab90007dff25374a7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_acbd884b920d421db11663a2911d6fd6","placeholder":"​","style":"IPY_MODEL_676756837e4b41038a450a4e11abb83b","tabbable":null,"tooltip":null,"value":" 1.14M/? [00:00&lt;00:00, 60.2MB/s]"}},"db63181ab78d4ce3b3a8dd579982b8b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dce848b21a83477c8c2193c198253b89":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de0089e35e21420f84b9a5d849bcc915":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e90e7e41c3de406ea0bdc4c311202d08":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2b7e3c4cfcc54c56a4825f1ca6458cc9","placeholder":"​","style":"IPY_MODEL_80685693b10240cf8ebc8742418645f1","tabbable":null,"tooltip":null,"value":"pytorch_model.bin: 100%"}},"f2da7a337ef14d1398e82315d4f48478":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f431db2ee0594b83985faf648c4b8912":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ee6eae0c9184cacb1c8abbc119fab04","IPY_MODEL_0a2273ea7e6043acb6550251e4c4678f","IPY_MODEL_9b2f35f219924ddbb94041eb65344287"],"layout":"IPY_MODEL_08d5fab7d3884ba48824392711943168","tabbable":null,"tooltip":null}},"fd4cb07be84a480d86224c652c5236fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ac38cfc4","cell_type":"code","source":"# ========== KIỂM TRA VÀ CÀI ĐẶT THƯ VIỆN ==========\n# Mục đích: Tự động phát hiện môi trường (Kaggle hoặc Local) và cài đặt thư viện cần thiết\n\nimport os\nimport subprocess\nimport csv\nimport json\nimport warnings\nimport time\n\n# Phát hiện môi trường: Kiểm tra thư mục đặc trưng của Kaggle\nIS_KAGGLE = os.path.exists('/kaggle/input')\nprint(f\"Môi trường: {'Kaggle' if IS_KAGGLE else 'Local'}\")\n\nif IS_KAGGLE:\n    print(\"Đang cài đặt các thư viện cần thiết...\")\n    \n    # Cài đặt seqeval: Thư viện tính metrics cho NER (Named Entity Recognition)\n    try:\n        import seqeval\n        pass\n    except ImportError:\n        subprocess.check_call(['pip', 'install', '-q', 'seqeval'])\n        print(\"Đã cài seqeval\")\n    \n    # Kiểm tra transformers và torch đã được cài sẵn trên Kaggle\n    import transformers\n    import torch\n    pass\nelse:\n    print(\"Môi trường Local: Cần cài đặt: pip install transformers seqeval torch\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:11:45.998857Z","iopub.execute_input":"2025-12-15T14:11:45.999101Z","iopub.status.idle":"2025-12-15T14:11:57.580113Z","shell.execute_reply.started":"2025-12-15T14:11:45.999084Z","shell.execute_reply":"2025-12-15T14:11:57.579500Z"},"papermill":{"duration":13.874187,"end_time":"2025-11-30T02:55:59.283061","exception":false,"start_time":"2025-11-30T02:55:45.408874","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Môi trường: Kaggle\nĐang cài đặt các thư viện cần thiết...\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 1.3 MB/s eta 0:00:00\nĐã cài seqeval\n","output_type":"stream"}],"execution_count":1},{"id":"ac1aaac6","cell_type":"markdown","source":"## 1. Import thư viện","metadata":{"papermill":{"duration":0.010885,"end_time":"2025-11-30T02:55:59.305549","exception":false,"start_time":"2025-11-30T02:55:59.294664","status":"completed"},"tags":[]}},{"id":"c565693d","cell_type":"code","source":"# ========== IMPORT THƯ VIỆN ==========\n\n# Xử lý dữ liệu\nimport pandas as pd  \nimport numpy as np  \n\nimport torch\nimport torch.nn as nn  \nimport torch.nn.functional as F \nfrom torch.utils.data import Dataset, DataLoader \n\n# Transformers (Hugging Face)\nfrom transformers import (\n    AutoTokenizer,           \n    AutoModel,               \n    AutoConfig,              \n    RobertaModel,            \n    TrainingArguments,       \n    Trainer,                 \n    EarlyStoppingCallback,   \n    TrainerCallback         \n)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n\nfrom seqeval.metrics import classification_report as ner_classification_report\nfrom seqeval.metrics import f1_score as ner_f1_score\nfrom seqeval.metrics import precision_score as ner_precision_score\nfrom seqeval.metrics import recall_score as ner_recall_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Kiểm tra GPU: Sử dụng GPU nếu có, không thì dùng CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Thiết bị: {device}\")\nprint(f\"PyTorch version: {torch.__version__}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:11:57.581487Z","iopub.execute_input":"2025-12-15T14:11:57.581989Z","iopub.status.idle":"2025-12-15T14:12:23.918406Z","shell.execute_reply.started":"2025-12-15T14:11:57.581970Z","shell.execute_reply":"2025-12-15T14:12:23.917472Z"},"papermill":{"duration":34.085721,"end_time":"2025-11-30T02:56:33.402156","exception":false,"start_time":"2025-11-30T02:55:59.316435","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"2025-12-15 14:12:05.430293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765807925.592889      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765807925.639009      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Thiết bị: cuda\nPyTorch version: 2.6.0+cu124\nGPU: Tesla T4\n","output_type":"stream"}],"execution_count":2},{"id":"ba7c399b","cell_type":"markdown","source":"## 2. Đọc dữ liệu","metadata":{"papermill":{"duration":0.011446,"end_time":"2025-11-30T02:56:33.425528","exception":false,"start_time":"2025-11-30T02:56:33.414082","status":"completed"},"tags":[]}},{"id":"41d7520d","cell_type":"code","source":"# Tự động chọn đường dẫn CSV dựa trên môi trường\nif IS_KAGGLE:\n    csv_path = \"/kaggle/input/tlcn-mangxahoi/FB_TikTok_Label.csv\"\nelse:\n    csv_path = r\"d:\\Data_Engineer\\TLCN\\Crawl\\fb_crawl\\test_model\\data_model_label\\FB_TikTok_Label.csv\"\n\nprint(f\"CSV path: {csv_path}\")\n\n# Đọc file với csv module để xử lý dấu phẩy trong text\ndata_rows = []\nwith open(csv_path, 'r', encoding='utf-8') as f:\n    reader = csv.reader(f)\n    header = next(reader) \n    \n    for i, row in enumerate(reader, start=2):  # Start từ 2 vì dòng 1 là header\n        if len(row) == 5:  # Đảm bảo có đủ 5 cột\n            data_rows.append(row)\n        else:\n            pass\n\ndf = pd.DataFrame(data_rows, columns=header)\n\nprint(f\"Tổng số mẫu hợp lệ: {len(df)}\")\nprint(f\"Các cột trong dataset: {df.columns.tolist()}\")\nprint(f\"Mẫu dữ liệu:\")\nprint(df[['Description_Normalized', 'Label_NER']].head(3))","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:23.919250Z","iopub.execute_input":"2025-12-15T14:12:23.920016Z","iopub.status.idle":"2025-12-15T14:12:23.982045Z","shell.execute_reply.started":"2025-12-15T14:12:23.919995Z","shell.execute_reply":"2025-12-15T14:12:23.981400Z"},"papermill":{"duration":0.102082,"end_time":"2025-11-30T02:56:33.538676","exception":false,"start_time":"2025-11-30T02:56:33.436594","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"CSV path: /kaggle/input/tlcn-mangxahoi/FB_TikTok_Label.csv\nTổng số mẫu hợp lệ: 2329\nCác cột trong dataset: ['\\ufeffID', 'Description_Normalized', 'Label_NER', 'Label_Topic', 'Label_Intent']\nMẫu dữ liệu:\n                              Description_Normalized  \\\n0  Chạy nhanh còn kịp ! Top ngành không nên học :...   \n1       Học Quản trị Nhân_sự thì sao ? huongnghiep .   \n2  Nếu tốt_nghiệp 4 chuyên_ngành này của VMU ( Đạ...   \n\n                                           Label_NER  \n0                  O O O O O O O O O O O B-MAJ O O O  \n1                      O B-MAJ I-MAJ I-MAJ O O O O O  \n2  O O O O O O B-ORG O B-ORG I-ORG I-ORG O O O O ...  \n","output_type":"stream"}],"execution_count":3},{"id":"d24cb0a4","cell_type":"markdown","source":"## 3. Tiền xử lý dữ liệu","metadata":{"papermill":{"duration":0.011768,"end_time":"2025-11-30T02:56:33.562693","exception":false,"start_time":"2025-11-30T02:56:33.550925","status":"completed"},"tags":[]}},{"id":"87f0f80f","cell_type":"code","source":"def parse_multi_task_data(df):\n    \"\"\"\n    Hàm chuyển đổi dữ liệu từ DataFrame sang format phù hợp cho Multi-task Learning\n    \n    Multi-task Learning: Huấn luyện model để thực hiện 3 nhiệm vụ đồng thời:\n        1. NER (Named Entity Recognition) - Nhận diện thực thể\n        2. Topic Classification - Phân loại chủ đề\n        3. Intent Classification - Phân loại ý định\n    \n    Args:\n        df: DataFrame chứa dữ liệu từ CSV\n    \n    Returns:\n        texts: list các câu (mỗi câu là list các từ)\n        ner_labels: list các nhãn NER (tương ứng từng từ)\n        topic_labels: list các nhãn Topic (có thể multi-label: \"ADMISSION|MAJOR\")\n        intent_labels: list các nhãn Intent (single-label)\n    \"\"\"\n    texts = []\n    ner_labels = []\n    topic_labels = []\n    intent_labels = []\n    \n\n    for idx, row in df.iterrows():\n        text = row['Description_Normalized']      # Câu văn đã được chuẩn hóa\n        ner_label_str = row['Label_NER']         # Nhãn NER (VD: \"O O B-ORG I-ORG O\")\n        topic_label_str = row['Label_Topic']     # Nhãn Topic (VD: \"ADMISSION|MAJOR\")\n        intent_label_str = row['Label_Intent']   # Nhãn Intent (VD: \"ask_info\")\n        \n        words = text.split()           # [\"Em\", \"muốn\", \"thi\", \"vào\", \"...\"]\n        ner_tags = ner_label_str.split()  # [\"O\", \"O\", \"O\", \"O\", \"B-ORG\", ...]\n        \n        # Kiểm tra tính hợp lệ: Số lượng từ phải bằng số lượng nhãn NER\n        if len(words) == len(ner_tags):\n            texts.append(words)\n            ner_labels.append(ner_tags)\n            topic_labels.append(topic_label_str)  # Giữ nguyên string (sẽ xử lý sau)\n            intent_labels.append(intent_label_str)\n        else:\n            print(f\"Cảnh báo: Dòng {idx} không khớp - số từ: {len(words)}, số nhãn: {len(ner_tags)}\")\n    \n    return texts, ner_labels, topic_labels, intent_labels\n\n# Parse dữ liệu\ntexts, ner_labels, topic_labels, intent_labels = parse_multi_task_data(df)\nprint(f\"Số lượng câu: {len(texts)}\")\nprint(f\"Ví dụ câu 1:\")\nprint(f\"  Text: {' '.join(texts[0])}\")\nprint(f\"  NER Labels: {' '.join(ner_labels[0])}\")\nprint(f\"  Topic Label: {topic_labels[0]}\")\nprint(f\"  Intent Label: {intent_labels[0]}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:23.982889Z","iopub.execute_input":"2025-12-15T14:12:23.983189Z","iopub.status.idle":"2025-12-15T14:12:24.110571Z","shell.execute_reply.started":"2025-12-15T14:12:23.983159Z","shell.execute_reply":"2025-12-15T14:12:24.110007Z"},"papermill":{"duration":0.139153,"end_time":"2025-11-30T02:56:33.713538","exception":false,"start_time":"2025-11-30T02:56:33.574385","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Số lượng câu: 2329\nVí dụ câu 1:\n  Text: Chạy nhanh còn kịp ! Top ngành không nên học : Điều_dưỡng như_thế_nào ? .\n  NER Labels: O O O O O O O O O O O B-MAJ O O O\n  Topic Label: MAJOR\n  Intent Label: share_info\n","output_type":"stream"}],"execution_count":4},{"id":"c5b94903","cell_type":"code","source":"# Tạo ánh xạ nhãn cho NER\nunique_ner_labels = set()\nfor label_seq in ner_labels:\n    unique_ner_labels.update(label_seq)\n\nunique_ner_labels = sorted(list(unique_ner_labels))\nner_label2id = {label: idx for idx, label in enumerate(unique_ner_labels)}\nner_id2label = {idx: label for label, idx in ner_label2id.items()}\n\nprint(f\"Số lượng nhãn NER: {len(unique_ner_labels)}\")\nprint(f\"Danh sách nhãn NER: {unique_ner_labels[:10]}...\")\n\n# Tạo ánh xạ nhãn cho Topic (xử lý multi-label)\n# Tách các topic riêng lẻ từ format \"ADMISSION|MAJOR\"\nall_topics = set()\nfor topic_str in topic_labels:\n    topics = topic_str.split('|')\n    all_topics.update(topics)\n\nunique_topics = sorted(list(all_topics))\ntopic_label2id = {label: idx for idx, label in enumerate(unique_topics)}\ntopic_id2label = {idx: label for label, idx in topic_label2id.items()}\n\nprint(f\"Số lượng topic labels: {len(unique_topics)}\")\nprint(f\"Danh sách topics: {unique_topics}\")\n\n# Tạo ánh xạ nhãn cho Intent\nunique_intents = sorted(list(set(intent_labels)))\nintent_label2id = {label: idx for idx, label in enumerate(unique_intents)}\nintent_id2label = {idx: label for label, idx in intent_label2id.items()}\n\nprint(f\"Số lượng intent labels: {len(unique_intents)}\")\nprint(f\"Danh sách intents: {unique_intents}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:24.112436Z","iopub.execute_input":"2025-12-15T14:12:24.113100Z","iopub.status.idle":"2025-12-15T14:12:24.124467Z","shell.execute_reply.started":"2025-12-15T14:12:24.113073Z","shell.execute_reply":"2025-12-15T14:12:24.123524Z"},"papermill":{"duration":0.024588,"end_time":"2025-11-30T02:56:33.749692","exception":false,"start_time":"2025-11-30T02:56:33.725104","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Số lượng nhãn NER: 25\nDanh sách nhãn NER: ['B-DATE', 'B-EX', 'B-FEE', 'B-LOC', 'B-MAJ', 'B-MISC', 'B-ORG', 'B-PRO', 'B-SAL', 'B-SCO']...\nSố lượng topic labels: 10\nDanh sách topics: ['CAREER', 'CERTIFICATE', 'LANGUAGE', 'MAJOR', 'OTHER', 'STUDENT_LIFE', 'STUDY', 'SUBJECT_COMBINATION', 'TUITION', 'UNIVERSITY']\nSố lượng intent labels: 7\nDanh sách intents: ['ask_advice', 'ask_comparison', 'ask_confirmation', 'ask_experience', 'ask_info', 'other', 'share_info']\n","output_type":"stream"}],"execution_count":5},{"id":"558bb6ba","cell_type":"markdown","source":"## 4. Chia dữ liệu","metadata":{"papermill":{"duration":0.011905,"end_time":"2025-11-30T02:56:33.773120","exception":false,"start_time":"2025-11-30T02:56:33.761215","status":"completed"},"tags":[]}},{"id":"901697d4","cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 1) Chia Train (70%) + Remaining (30%)\ntrain_texts, temp_texts, \\\ntrain_ner_labels, temp_ner_labels, \\\ntrain_topic_labels, temp_topic_labels, \\\ntrain_intent_labels, temp_intent_labels = train_test_split(\n    texts, ner_labels, topic_labels, intent_labels,\n    test_size=0.30, random_state=42\n)\n\n# 2) Chia remaining thành Validation (15%) và Test (15%)\nval_texts, test_texts, \\\nval_ner_labels, test_ner_labels, \\\nval_topic_labels, test_topic_labels, \\\nval_intent_labels, test_intent_labels = train_test_split(\n    temp_texts, temp_ner_labels, temp_topic_labels, temp_intent_labels,\n    test_size=0.50, random_state=42\n)\n\nprint(\"=\"*80)\nprint(\"DATA SPLIT: TRAIN / VAL / TEST\")\nprint(\"=\"*80)\n\nprint(f\"Train set:      {len(train_texts):5d} samples ({len(train_texts)/len(texts)*100:.1f}%)\")\nprint(f\"Validation set: {len(val_texts):5d} samples ({len(val_texts)/len(texts)*100:.1f}%)\")\nprint(f\"Test set:       {len(test_texts):5d} samples ({len(test_texts)/len(texts)*100:.1f}%)\")\nprint(\"=\"*80)\n\nprint(\"\\nLƯU Ý:\")\nprint(\"  - Train: model học\")\nprint(\"  - Validation: chọn best model, early stopping, tune hyperparameters\")\nprint(\"  - Test: đánh giá cuối cùng, không dùng trong training/validation\")\nprint(\"=\"*80)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:24.125227Z","iopub.execute_input":"2025-12-15T14:12:24.125606Z","iopub.status.idle":"2025-12-15T14:12:24.138649Z","shell.execute_reply.started":"2025-12-15T14:12:24.125582Z","shell.execute_reply":"2025-12-15T14:12:24.137980Z"},"papermill":{"duration":0.024279,"end_time":"2025-11-30T02:56:33.837205","exception":false,"start_time":"2025-11-30T02:56:33.812926","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nDATA SPLIT: TRAIN / VAL / TEST\n================================================================================\nTrain set:       1630 samples (70.0%)\nValidation set:   349 samples (15.0%)\nTest set:         350 samples (15.0%)\n================================================================================\n\nLƯU Ý:\n  - Train: model học\n  - Validation: chọn best model, early stopping, tune hyperparameters\n  - Test: đánh giá cuối cùng, không dùng trong training/validation\n================================================================================\n","output_type":"stream"}],"execution_count":6},{"id":"10eb210c","cell_type":"markdown","source":"## 6. Tạo Dataset","metadata":{"papermill":{"duration":0.011144,"end_time":"2025-11-30T02:56:33.859849","exception":false,"start_time":"2025-11-30T02:56:33.848705","status":"completed"},"tags":[]}},{"id":"57ae62fc","cell_type":"code","source":"# Load tokenizer từ PhoBERT\nphobert_path = \"vinai/phobert-base-v2\"\ntokenizer = AutoTokenizer.from_pretrained(phobert_path)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:24.139529Z","iopub.execute_input":"2025-12-15T14:12:24.139853Z","iopub.status.idle":"2025-12-15T14:12:26.799654Z","shell.execute_reply.started":"2025-12-15T14:12:24.139833Z","shell.execute_reply":"2025-12-15T14:12:26.799024Z"},"papermill":{"duration":1.749683,"end_time":"2025-11-30T02:56:35.620844","exception":false,"start_time":"2025-11-30T02:56:33.871161","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73e4549ec3564eb4ba884c61d0cb9053"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cbb395cddad4e4d851d778b102f8f99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"596a08f878f94314be5ce9a28c675cf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0d818a96ad545e09d3eb3457d3f4f63"}},"metadata":{}}],"execution_count":7},{"id":"c986e055","cell_type":"code","source":"class MultiTaskDataset(Dataset):\n    \"\"\"\n    Custom Dataset cho Multi-task Learning\n    \n    Chức năng:\n        - Tokenize văn bản tiếng Việt bằng PhoBERT tokenizer\n        - Align NER labels với subword tokens (PhoBERT tách từ thành subwords)\n        - Chuyển đổi topic labels thành multi-hot vector\n        - Chuyển đổi intent labels thành integer ID\n        - Padding/Truncate để tất cả sequences có cùng độ dài\n    \"\"\"\n    def __init__(self, texts, ner_labels, topic_labels, intent_labels, \n                 tokenizer, ner_label2id, topic_label2id, intent_label2id, max_length=256):\n        \"\"\"\n        Args:\n            texts: List các câu (mỗi câu là list các từ)\n            ner_labels: List các nhãn NER tương ứng\n            topic_labels: List các nhãn Topic (string có thể chứa | để ngăn cách)\n            intent_labels: List các nhãn Intent (string)\n            tokenizer: PhoBERT tokenizer\n            ner_label2id: Dictionary ánh xạ NER label -> ID\n            topic_label2id: Dictionary ánh xạ Topic label -> ID\n            intent_label2id: Dictionary ánh xạ Intent label -> ID\n            max_length: Độ dài tối đa của sequence (padding/truncate)\n        \"\"\"\n        self.texts = texts\n        self.ner_labels = ner_labels\n        self.topic_labels = topic_labels\n        self.intent_labels = intent_labels\n        self.tokenizer = tokenizer\n        self.ner_label2id = ner_label2id\n        self.topic_label2id = topic_label2id\n        self.intent_label2id = intent_label2id\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        \"\"\"\n        Lấy 1 mẫu dữ liệu theo index\n        \n        Quy trình xử lý:\n            1. Tokenize từng từ thành subword tokens\n            2. Gán NER label cho subword đầu tiên, các subword sau gán -100\n            3. Thêm special tokens: <s> (CLS) đầu câu, </s> (SEP) cuối câu\n            4. Padding đến max_length\n            5. Chuyển topic thành multi-hot vector\n            6. Chuyển intent thành integer ID\n        \"\"\"\n        words = self.texts[idx]              # List các từ: [\"Em\", \"muốn\", \"thi\", ...]\n        ner_tags = self.ner_labels[idx]      # List NER labels: [\"O\", \"O\", \"O\", \"B-ORG\", ...]\n        topic_str = self.topic_labels[idx]   # String: \"ADMISSION|MAJOR\"\n        intent_str = self.intent_labels[idx] # String: \"ask_info\"\n        \n        # ========== Tokenize và align NER labels ==========\n        tokens = []        \n        ner_label_ids = [] \n        \n        # Thêm token đặc biệt <s> (CLS) ở đầu\n        tokens.append(self.tokenizer.cls_token)\n        ner_label_ids.append(-100)  # -100 = ignore token này khi tính loss\n        \n        # Tokenize từng từ\n        for word, label in zip(words, ner_tags):\n            word_tokens = self.tokenizer.tokenize(word)\n            \n            # Chỉ thêm nếu còn chỗ (giới hạn max_length)\n            if len(tokens) + len(word_tokens) < self.max_length - 1:\n                tokens.extend(word_tokens)\n                \n                # Subword đầu tiên nhận label thật, các subword sau nhận -100\n                ner_label_ids.append(self.ner_label2id[label])\n                if len(word_tokens) > 1:\n                    ner_label_ids.extend([-100] * (len(word_tokens) - 1))\n        \n        # Thêm token đặc biệt </s> (SEP) ở cuối\n        tokens.append(self.tokenizer.sep_token)\n        ner_label_ids.append(-100)\n        \n        #Chuyển tokens thành IDs\n        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n        attention_mask = [1] * len(input_ids)  # 1 = token thật, 0 = padding\n        \n        #Padding để đủ max_length \n        padding_length = self.max_length - len(input_ids)\n        input_ids += [self.tokenizer.pad_token_id] * padding_length\n        attention_mask += [0] * padding_length\n        ner_label_ids += [-100] * padding_length\n        \n        # Xử lý Topic labels (multi-label)\n        # Tạo binary vector: [0,0,1,0,1,...] (1 = thuộc topic đó, 0 = không)\n        topic_vector = [0] * len(self.topic_label2id)\n        topics = topic_str.split('|')  # Tách \"ADMISSION|MAJOR\" -> [\"ADMISSION\", \"MAJOR\"]\n        for topic in topics:\n            if topic in self.topic_label2id:\n                topic_vector[self.topic_label2id[topic]] = 1\n        \n        # Xử lý Intent label (single-label)\n        # Chuyển thành integer ID\n        intent_id = self.intent_label2id[intent_str]\n        \n        return {\n            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n            'ner_labels': torch.tensor(ner_label_ids, dtype=torch.long),\n            'topic_labels': torch.tensor(topic_vector, dtype=torch.long),\n            'intent_labels': torch.tensor(intent_id, dtype=torch.long)\n        }\n\n# Tạo datasets\ntrain_dataset = MultiTaskDataset(\n    train_texts, train_ner_labels, train_topic_labels, train_intent_labels,\n    tokenizer, ner_label2id, topic_label2id, intent_label2id\n)\nval_dataset = MultiTaskDataset(\n    val_texts, val_ner_labels, val_topic_labels, val_intent_labels,\n    tokenizer, ner_label2id, topic_label2id, intent_label2id\n)\ntest_dataset = MultiTaskDataset(\n    test_texts, test_ner_labels, test_topic_labels, test_intent_labels,\n    tokenizer, ner_label2id, topic_label2id, intent_label2id\n)\n\nprint(\"=\"*80)\nprint(f\"Train dataset:      {len(train_dataset):5d} samples\")\nprint(f\"Validation dataset: {len(val_dataset):5d} samples\")\nprint(f\"Test dataset:       {len(test_dataset):5d} samples (KHÔNG dùng trong training)\")\nprint(\"=\"*80)\n\n# Kiểm tra một mẫu\nsample = train_dataset[0]\nprint(f\"\\nSample shapes:\")\nprint(f\"  Input IDs: {sample['input_ids'].shape}\")\nprint(f\"  NER labels: {sample['ner_labels'].shape}\")\nprint(f\"  Topic labels: {sample['topic_labels'].shape} (multi-hot vector)\")\nprint(f\"  Intent label: {sample['intent_labels'].shape} (single value)\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:26.800471Z","iopub.execute_input":"2025-12-15T14:12:26.800736Z","iopub.status.idle":"2025-12-15T14:12:26.817862Z","shell.execute_reply.started":"2025-12-15T14:12:26.800717Z","shell.execute_reply":"2025-12-15T14:12:26.817014Z"},"papermill":{"duration":0.030151,"end_time":"2025-11-30T02:56:35.663198","exception":false,"start_time":"2025-11-30T02:56:35.633047","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nTrain dataset:       1630 samples\nValidation dataset:   349 samples\nTest dataset:         350 samples (KHÔNG dùng trong training)\n================================================================================\n\nSample shapes:\n  Input IDs: torch.Size([256])\n  NER labels: torch.Size([256])\n  Topic labels: torch.Size([10]) (multi-hot vector)\n  Intent label: torch.Size([]) (single value)\n","output_type":"stream"}],"execution_count":8},{"id":"bce42f67","cell_type":"markdown","source":"## 7. Định nghĩa Metrics","metadata":{"papermill":{"duration":0.011505,"end_time":"2025-11-30T02:56:35.686607","exception":false,"start_time":"2025-11-30T02:56:35.675102","status":"completed"},"tags":[]}},{"id":"447d2742","cell_type":"code","source":"def compute_multi_task_metrics(pred):\n    \"\"\"\n    Tính metrics cho cả 3 tasks: NER, Topic, Intent\n    \"\"\"\n    predictions = pred.predictions\n    labels = pred.label_ids\n    \n    # predictions và labels là tuple: (ner, topic, intent)\n    # Convert to numpy if they are tensors\n    ner_preds, topic_preds, intent_preds = predictions\n    ner_labels, topic_labels, intent_labels = labels\n    \n    # Convert tensors to numpy if needed\n    if torch.is_tensor(ner_preds):\n        ner_preds = ner_preds.cpu().numpy()\n    if torch.is_tensor(topic_preds):\n        topic_preds = topic_preds.cpu().numpy()\n    if torch.is_tensor(intent_preds):\n        intent_preds = intent_preds.cpu().numpy()\n    if torch.is_tensor(ner_labels):\n        ner_labels = ner_labels.cpu().numpy()\n    if torch.is_tensor(topic_labels):\n        topic_labels = topic_labels.cpu().numpy()\n    if torch.is_tensor(intent_labels):\n        intent_labels = intent_labels.cpu().numpy()\n    \n    results = {}\n    \n    #NER Metrics\n    ner_predictions = np.argmax(ner_preds, axis=2)\n    \n    # Loại bỏ các token đặc biệt (label = -100)\n    true_ner_labels = []\n    true_ner_predictions = []\n    \n    for prediction, label in zip(ner_predictions, ner_labels):\n        true_label = []\n        true_pred = []\n        for p, l in zip(prediction, label):\n            if l != -100:\n                true_label.append(ner_id2label[l])\n                true_pred.append(ner_id2label[p])\n        true_ner_labels.append(true_label)\n        true_ner_predictions.append(true_pred)\n    \n    # Tính NER metrics\n    ner_precision = ner_precision_score(true_ner_labels, true_ner_predictions)\n    ner_recall = ner_recall_score(true_ner_labels, true_ner_predictions)\n    ner_f1 = ner_f1_score(true_ner_labels, true_ner_predictions)\n    \n    # Tính NER accuracy (token-level)\n    total_tokens = sum(len(seq) for seq in true_ner_labels)\n    correct_tokens = sum(1 for true_seq, pred_seq in zip(true_ner_labels, true_ner_predictions) \n                        for t, p in zip(true_seq, pred_seq) if t == p)\n    ner_accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0\n    \n    results.update({\n        'ner_precision': ner_precision,\n        'ner_recall': ner_recall,\n        'ner_f1': ner_f1,\n        'ner_accuracy': ner_accuracy\n    })\n    \n    # Topic Metrics (Multi-label)\n    # Chuyển logits thành binary predictions (threshold = 0.5)\n    topic_predictions = (torch.sigmoid(torch.tensor(topic_preds)) > 0.5).numpy().astype(int)\n    \n    # Tính metrics cho từng topic label\n    topic_precision, topic_recall, topic_f1, _ = precision_recall_fscore_support(\n        topic_labels, topic_predictions, average='samples', zero_division=0\n    )\n    \n    # Tính accuracy (exact match)\n    topic_accuracy = accuracy_score(topic_labels, topic_predictions)\n    \n    results.update({\n        'topic_precision': topic_precision,\n        'topic_recall': topic_recall,\n        'topic_f1': topic_f1,\n        'topic_accuracy': topic_accuracy\n    })\n    \n    # Intent Metrics (Single-label)\n    intent_predictions = np.argmax(intent_preds, axis=1)\n    \n    intent_precision, intent_recall, intent_f1, _ = precision_recall_fscore_support(\n        intent_labels, intent_predictions, average='weighted', zero_division=0\n    )\n    \n    intent_accuracy = accuracy_score(intent_labels, intent_predictions)\n    \n    results.update({\n        'intent_precision': intent_precision,\n        'intent_recall': intent_recall,\n        'intent_f1': intent_f1,\n        'intent_accuracy': intent_accuracy\n    })\n    \n    # Overall Metrics\n    # Trung bình F1 của cả 3 tasks\n    overall_f1 = (ner_f1 + topic_f1 + intent_f1) / 3\n    results['overall_f1'] = overall_f1\n    \n    return results\n\nprint(\"Multi-Task Metrics function defined!\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:26.818868Z","iopub.execute_input":"2025-12-15T14:12:26.819133Z","iopub.status.idle":"2025-12-15T14:12:26.836142Z","shell.execute_reply.started":"2025-12-15T14:12:26.819108Z","shell.execute_reply":"2025-12-15T14:12:26.835531Z"},"papermill":{"duration":0.024258,"end_time":"2025-11-30T02:56:35.722366","exception":false,"start_time":"2025-11-30T02:56:35.698108","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Multi-Task Metrics function defined!\n","output_type":"stream"}],"execution_count":9},{"id":"572e792e","cell_type":"markdown","source":"## 8. Feature Fusion Model","metadata":{"papermill":{"duration":0.013524,"end_time":"2025-11-30T02:56:35.758795","exception":false,"start_time":"2025-11-30T02:56:35.745271","status":"completed"},"tags":[]}},{"id":"b5e21c32","cell_type":"markdown","source":"### 8.1. Định nghĩa Class","metadata":{"papermill":{"duration":0.012091,"end_time":"2025-11-30T02:56:35.784967","exception":false,"start_time":"2025-11-30T02:56:35.772876","status":"completed"},"tags":[]}},{"id":"0893a246","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import RobertaModel\n\n\nclass MultiTaskPhoBERT_WithFusion(nn.Module):\n    \"\"\"\n    Multi-Task PhoBERT với Feature Fusion (Simplified)\n    \"\"\"\n    def __init__(self, phobert_path, num_ner_labels, num_topic_labels, num_intent_labels, dropout=0.2):\n        super(MultiTaskPhoBERT_WithFusion, self).__init__()\n        \n        # Load PhoBERT\n        self.phobert = RobertaModel.from_pretrained(phobert_path)\n        self.phobert.config.hidden_dropout_prob = 0.25\n        self.phobert.config.attention_probs_dropout_prob = 0.25\n        self.hidden_size = self.phobert.config.hidden_size\n        self.num_ner_labels = num_ner_labels\n        \n        # Dropouts: GIỮ 2 loại\n        self.dropout = nn.Dropout(dropout)\n        self.dropout_heavy = nn.Dropout(dropout * 1.5)\n        \n        # NER head\n        self.ner_hidden = nn.Linear(self.hidden_size, self.hidden_size // 2)\n        self.ner_norm = nn.LayerNorm(self.hidden_size // 2)\n        self.ner_classifier = nn.Linear(self.hidden_size // 2, num_ner_labels)\n        \n        # Intent head\n        self.intent_hidden = nn.Linear(self.hidden_size, self.hidden_size // 2)\n        self.intent_norm = nn.LayerNorm(self.hidden_size // 2)\n        self.intent_classifier = nn.Linear(self.hidden_size // 2, num_intent_labels)\n        \n        # Topic Fusion Head (CLS + NER features)\n        fusion_input_size = self.hidden_size + num_ner_labels\n        self.topic_input_proj = nn.Linear(fusion_input_size, self.hidden_size)\n        \n        self.topic_layer1 = nn.Sequential(\n            nn.Linear(self.hidden_size, self.hidden_size),\n            nn.LayerNorm(self.hidden_size),\n            nn.GELU(),\n            nn.Dropout(dropout * 0.5)\n        )\n        self.topic_classifier = nn.Linear(self.hidden_size, num_topic_labels)\n        \n        # ner_attention\n        self.ner_attention = nn.Sequential(\n            nn.Linear(num_ner_labels, num_ner_labels // 2),\n            nn.Tanh(),\n            nn.Linear(num_ner_labels // 2, num_ner_labels),\n            nn.Softmax(dim=-1)\n        )\n        \n        # Cross-Attention: CLS attend to sequence context\n        self.cross_attention = nn.MultiheadAttention(\n            embed_dim=self.hidden_size,\n            num_heads=8,\n            dropout=dropout,\n            batch_first=True\n        )\n        self.cross_attn_norm = nn.LayerNorm(self.hidden_size)\n        \n        # AUX HEAD: dự đoán topic trực tiếp từ NER features\n        self.aux_topic_classifier = nn.Sequential(\n            nn.Linear(num_ner_labels, num_ner_labels // 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(num_ner_labels // 2, num_topic_labels)\n        )\n    \n    def extract_ner_features(self, ner_logits, attention_mask):\n        \"\"\"\n        Trích xuất NER features với attention mechanism\n        MAX + AVG pooling + ner_attention\n        \"\"\"\n        # [batch, seq_len, num_ner_labels]\n        ner_probs = F.softmax(ner_logits, dim=-1)\n        \n        # Mask padding\n        attention_mask_expanded = attention_mask.unsqueeze(-1).expand_as(ner_probs)\n        ner_probs_masked = ner_probs * attention_mask_expanded\n        \n        # MAX pooling → entity mạnh nhất cho từng label\n        # [batch, num_ner_labels]\n        max_features, _ = ner_probs_masked.max(dim=1)\n        \n        # AVG pooling → phân bố tổng thể label trong câu\n        seq_lengths = attention_mask.sum(dim=1, keepdim=True).clamp(min=1)\n        avg_features = ner_probs_masked.sum(dim=1) / seq_lengths\n        \n        # Kết hợp max + avg\n        ner_features = 0.5 * max_features + 0.5 * avg_features\n        \n        # ner_attention: học weight cho từng entity type\n        attention_weights = self.ner_attention(ner_features)\n        ner_features_weighted = ner_features * attention_weights\n        \n        return ner_features_weighted\n    \n    def forward(self, input_ids, attention_mask=None, ner_labels=None, topic_labels=None, intent_labels=None):\n        # PhoBERT outputs\n        outputs = self.phobert(input_ids=input_ids, attention_mask=attention_mask)\n        sequence_output = outputs.last_hidden_state             # [batch, seq_len, hidden]\n        cls_output = sequence_output[:, 0, :]                   # [batch, hidden]\n        \n        # Cross-Attention: CLS attend to full sequence\n        cls_expanded = cls_output.unsqueeze(1)  # [batch, 1, hidden]\n        attn_output, _ = self.cross_attention(\n            query=cls_expanded,\n            key=sequence_output,\n            value=sequence_output,\n            key_padding_mask=(attention_mask == 0) if attention_mask is not None else None\n        )\n        cls_output = self.cross_attn_norm(cls_output + attn_output.squeeze(1))\n        \n        # GIỮ 2 dropout\n        cls_output_dropped = self.dropout_heavy(cls_output)\n        \n        # NER predictions\n        ner_hidden = self.ner_hidden(sequence_output)\n        ner_hidden = self.ner_norm(ner_hidden)\n        ner_hidden = F.gelu(ner_hidden)\n        ner_hidden = self.dropout(ner_hidden)\n        ner_logits = self.ner_classifier(ner_hidden)            # [batch, seq_len, num_ner_labels]\n        \n        # NER features + attention\n        ner_features = self.extract_ner_features(ner_logits, attention_mask)\n        \n        # Fusion CLS + NER features\n        topic_input = torch.cat([cls_output_dropped, ner_features], dim=-1)\n        \n        # Topic fusion với 2 residual block\n        topic_hidden = self.topic_input_proj(topic_input)\n        topic_hidden = topic_hidden + self.topic_layer1(topic_hidden)\n        \n        topic_logits = self.topic_classifier(topic_hidden)      # [batch, num_topic_labels]\n        \n        # Intent predictions\n        intent_hidden = self.intent_hidden(cls_output_dropped)\n        intent_hidden = self.intent_norm(intent_hidden)\n        intent_hidden = F.gelu(intent_hidden)\n        intent_hidden = self.dropout(intent_hidden)\n        intent_logits = self.intent_classifier(intent_hidden)\n        \n        total_loss = None\n        if ner_labels is not None and topic_labels is not None and intent_labels is not None:\n            # --- NER loss ---\n            loss_fct_ner = nn.CrossEntropyLoss(\n                ignore_index=-100,\n                label_smoothing=0.1\n            )\n            active_loss = attention_mask.view(-1) == 1\n            active_logits = ner_logits.view(-1, self.num_ner_labels)\n            active_labels = torch.where(\n                active_loss,\n                ner_labels.view(-1),\n                torch.tensor(loss_fct_ner.ignore_index).type_as(ner_labels)\n            )\n            ner_loss = loss_fct_ner(active_logits, active_labels)\n            \n            # --- Topic loss: DÙNG BCEWithLogitsLoss CHUẨN ---\n            topic_targets = topic_labels.float()\n            loss_fct_topic = nn.BCEWithLogitsLoss()\n            topic_loss = loss_fct_topic(topic_logits, topic_targets)\n            \n            # --- AUX topic loss: dự đoán topic trực tiếp từ NER features ---\n            aux_topic_logits = self.aux_topic_classifier(ner_features)   # [batch, num_topic_labels]\n            aux_topic_loss = F.binary_cross_entropy_with_logits(aux_topic_logits, topic_targets)\n            \n            # --- Intent loss ---\n            loss_fct_intent = nn.CrossEntropyLoss(label_smoothing=0.1)\n            intent_loss = loss_fct_intent(intent_logits, intent_labels)\n            \n            # Có thể chỉnh lại các weight này theo kết quả thực tế\n            total_loss = (\n                1.2 * ner_loss +      \n                4.5 * topic_loss +    \n                0.6 * intent_loss +\n                1.0 * aux_topic_loss \n            )\n        \n        return {\n            'loss': total_loss,\n            'ner_logits': ner_logits,\n            'topic_logits': topic_logits,\n            'intent_logits': intent_logits\n        }\n","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:26.836931Z","iopub.execute_input":"2025-12-15T14:12:26.837229Z","iopub.status.idle":"2025-12-15T14:12:26.855911Z","shell.execute_reply.started":"2025-12-15T14:12:26.837206Z","shell.execute_reply":"2025-12-15T14:12:26.855208Z"},"papermill":{"duration":0.03269,"end_time":"2025-11-30T02:56:35.830090","exception":false,"start_time":"2025-11-30T02:56:35.797400","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"6a9587a0","cell_type":"markdown","source":"### 8.2. Khởi tạo Model","metadata":{"papermill":{"duration":0.011732,"end_time":"2025-11-30T02:56:35.853693","exception":false,"start_time":"2025-11-30T02:56:35.841961","status":"completed"},"tags":[]}},{"id":"eaa30d58","cell_type":"code","source":"# Khởi tạo model fusion với OPTIMAL REGULARIZATION\nmodel_fusion = MultiTaskPhoBERT_WithFusion(\n    phobert_path=phobert_path,\n    num_ner_labels=len(ner_label2id),\n    num_topic_labels=len(topic_label2id),\n    num_intent_labels=len(intent_label2id),\n    dropout=0.3\n).to(device)\n\nprint(f\"Model initialized: {sum(p.numel() for p in model_fusion.parameters()):,} parameters\")\nprint(\"Regularization: OPTIMAL (dropout=0.3)\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:26.856718Z","iopub.execute_input":"2025-12-15T14:12:26.857570Z","iopub.status.idle":"2025-12-15T14:12:32.171453Z","shell.execute_reply.started":"2025-12-15T14:12:26.857552Z","shell.execute_reply":"2025-12-15T14:12:32.170622Z"},"papermill":{"duration":5.371037,"end_time":"2025-11-30T02:56:41.236382","exception":false,"start_time":"2025-11-30T02:56:35.865345","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"811f195381ef46508977fd24526528ac"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model initialized: 139,177,313 parameters\nRegularization: OPTIMAL (dropout=0.3)\n","output_type":"stream"}],"execution_count":11},{"id":"ca27392f","cell_type":"markdown","source":"### 8.3. Cấu hình Training","metadata":{"papermill":{"duration":0.011814,"end_time":"2025-11-30T02:56:41.320876","exception":false,"start_time":"2025-11-30T02:56:41.309062","status":"completed"},"tags":[]}},{"id":"bc8f936f","cell_type":"code","source":"# Training arguments với Early Stopping và Performance Optimization\nfrom transformers import EarlyStoppingCallback\n\ntraining_args_fusion = TrainingArguments(\n    output_dir=\"./phobert_multitask_fusion\",\n    num_train_epochs=100,\n    \n    # BATCH SIZE OPTIMIZATION\n    per_device_train_batch_size=24,  \n    per_device_eval_batch_size=48,   \n    gradient_accumulation_steps=2, \n    \n    # LEARNING RATE OPTIMIZATION - CÂN BẰNG\n    learning_rate=1.5e-5,            # 1e-5 -> 1.5e-5: Tăng để học nhanh hơn\n    warmup_ratio=0.15,               # 0.2 -> 0.15: Giảm warmup\n    lr_scheduler_type=\"cosine\",      # Cosine decay tốt hơn linear\n    weight_decay=0.05,               # 0.06 -> 0.05: Giảm để tăng flexibility\n    \n    # MIXED PRECISION TRAINING\n    fp16=True,                       # Bật mixed precision (float16)\n    fp16_opt_level=\"O1\",            # Optimization level 1 (safe)\n    \n    # EVALUATION & CHECKPOINTING - FREQUENT\n    logging_steps=50,\n    eval_strategy=\"steps\",\n    eval_steps=150,                  \n    save_strategy=\"steps\",\n    save_steps=150,                  \n    save_total_limit=5,              \n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_overall_f1\",\n    greater_is_better=True,\n    \n    # PERFORMANCE OPTIMIZATION\n    dataloader_num_workers=4,        \n    dataloader_pin_memory=True,      \n    group_by_length=True,            \n    gradient_checkpointing=False, \n    \n    report_to=\"none\",\n    remove_unused_columns=False\n)","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:32.172231Z","iopub.execute_input":"2025-12-15T14:12:32.172679Z","iopub.status.idle":"2025-12-15T14:12:32.210169Z","shell.execute_reply.started":"2025-12-15T14:12:32.172650Z","shell.execute_reply":"2025-12-15T14:12:32.209224Z"},"papermill":{"duration":0.045225,"end_time":"2025-11-30T02:56:41.378038","exception":false,"start_time":"2025-11-30T02:56:41.332813","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"id":"761ce48e","cell_type":"markdown","source":"### 11.5. Khởi tạo Trainer","metadata":{"papermill":{"duration":0.014359,"end_time":"2025-11-30T02:56:41.404774","exception":false,"start_time":"2025-11-30T02:56:41.390415","status":"completed"},"tags":[]}},{"id":"0aca88af","cell_type":"code","source":"class MultiTaskTrainer(Trainer):\n    \"\"\"\n    Custom Trainer cho Multi-Task Learning\n    \"\"\"\n    \n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        \"\"\"\n        Tính tổng loss từ 3 tasks\n        \"\"\"\n        # Forward pass\n        outputs = model(**inputs)\n        \n        # Loss đã được tính trong model.forward()\n        loss = outputs['loss']\n        \n        return (loss, outputs) if return_outputs else loss\n    \n    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n        \"\"\"\n        Custom prediction step để xử lý multi-task outputs\n        \"\"\"\n        model.eval()\n        \n        inputs = self._prepare_inputs(inputs)\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n            loss = outputs['loss']\n            \n            ner_logits = outputs['ner_logits']\n            topic_logits = outputs['topic_logits']\n            intent_logits = outputs['intent_logits']\n        \n        if prediction_loss_only:\n            return (loss, None, None)\n        \n        # Keep as tensors, don't convert to numpy yet\n        # Stack logits as tuple of tensors\n        logits = (\n            ner_logits.detach(),\n            topic_logits.detach(),\n            intent_logits.detach()\n        )\n        \n        # Stack labels as tuple of tensors\n        labels = (\n            inputs['ner_labels'].detach(),\n            inputs['topic_labels'].detach(),\n            inputs['intent_labels'].detach()\n        )\n        \n        return (loss, logits, labels)\n\nprint(\"Multi-Task Trainer class defined!\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:32.211044Z","iopub.execute_input":"2025-12-15T14:12:32.211302Z","iopub.status.idle":"2025-12-15T14:12:32.289747Z","shell.execute_reply.started":"2025-12-15T14:12:32.211283Z","shell.execute_reply":"2025-12-15T14:12:32.289039Z"},"papermill":{"duration":0.021214,"end_time":"2025-11-30T02:56:41.438196","exception":false,"start_time":"2025-11-30T02:56:41.416982","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Multi-Task Trainer class defined!\n","output_type":"stream"}],"execution_count":13},{"id":"df7fddce","cell_type":"code","source":"# Data collator cho multi-task\ndef multi_task_data_collator(features):\n    \"\"\"Collate batch data cho multi-task learning\"\"\"\n    batch = {}\n    batch['input_ids'] = torch.stack([f['input_ids'] for f in features])\n    batch['attention_mask'] = torch.stack([f['attention_mask'] for f in features])\n    batch['ner_labels'] = torch.stack([f['ner_labels'] for f in features])\n    batch['topic_labels'] = torch.stack([f['topic_labels'] for f in features])\n    batch['intent_labels'] = torch.stack([f['intent_labels'] for f in features])\n    return batch\n\n# 1. Early Stopping Callback: Dừng khi không cải thiện\nearly_stopping = EarlyStoppingCallback(\n    early_stopping_patience=5,\n    early_stopping_threshold=0.0001\n)\n\n# 2. Overfit Detection Callback: Dừng khi validation loss tăng quá cao so với training loss\nclass OverfitDetectionCallback(TrainerCallback):\n    def __init__(self, max_loss_gap=1.5, patience=3):\n        \"\"\"\n        max_loss_gap: Ngưỡng gap giữa val_loss/train_loss\n        patience: Số lần liên tiếp gap vượt ngưỡng trước khi dừng\n        \"\"\"\n        self.max_loss_gap = max_loss_gap\n        self.patience = patience\n        self.overfit_count = 0\n        self.train_loss_history = []\n        \n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs and 'loss' in logs:\n            self.train_loss_history.append({'step': state.global_step, 'train_loss': logs['loss']})\n    \n    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n        if not metrics or not self.train_loss_history:\n            return\n        \n        val_loss = metrics.get('eval_loss', 0)\n        train_loss = self.train_loss_history[-1]['train_loss']\n        loss_gap = val_loss / train_loss if train_loss > 0 else 1.0\n        \n        if loss_gap > self.max_loss_gap:\n            self.overfit_count += 1\n            print(f\"\\nOVERFIT WARNING - Step {state.global_step}:\")\n            print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Gap: {loss_gap:.2f}x\")\n            print(f\"  Overfit count: {self.overfit_count}/{self.patience}\")\n            \n            if self.overfit_count >= self.patience:\n                print(f\"\\nSTOPPING: Overfit detected {self.patience} times consecutively\")\n                print(f\"Best model will be loaded automatically\")\n                control.should_training_stop = True\n        else:\n            if self.overfit_count > 0:\n                print(f\"Gap normalized: {loss_gap:.2f}x - Reset overfit count\")\n            self.overfit_count = 0\n\noverfit_detector = OverfitDetectionCallback(\n    max_loss_gap=1.5,\n    patience=3\n)\n\n# Khởi tạo trainer\ntrainer_fusion = MultiTaskTrainer(\n    model=model_fusion,\n    args=training_args_fusion,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=multi_task_data_collator,\n    compute_metrics=compute_multi_task_metrics,\n    callbacks=[early_stopping, overfit_detector]\n)\n\nprint(\"Trainer initialized successfully\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:32.292469Z","iopub.execute_input":"2025-12-15T14:12:32.292785Z","iopub.status.idle":"2025-12-15T14:12:32.321528Z","shell.execute_reply.started":"2025-12-15T14:12:32.292767Z","shell.execute_reply":"2025-12-15T14:12:32.320921Z"},"papermill":{"duration":0.040228,"end_time":"2025-11-30T02:56:41.490462","exception":false,"start_time":"2025-11-30T02:56:41.450234","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Trainer initialized successfully\n","output_type":"stream"}],"execution_count":14},{"id":"2a7fefb2","cell_type":"markdown","source":"### 11.6. Training","metadata":{"papermill":{"duration":0.011963,"end_time":"2025-11-30T02:56:41.514855","exception":false,"start_time":"2025-11-30T02:56:41.502892","status":"completed"},"tags":[]}},{"id":"2c7d74bc","cell_type":"code","source":"# Training - Model học quy luật NER -> Topic mỗi epoch\nprint(\"=\"*80)\nprint(\"Training Feature Fusion Model\")\nprint(\"Model will learn NER -> Topic relationships during each epoch\")\nprint(\"=\"*80)\n\nstart_time = time.time()\ntrain_result = trainer_fusion.train()\ntraining_time = (time.time() - start_time) / 60\n\nprint(f\"\\nTraining completed in {training_time:.2f} minutes\")\nprint(f\"Final loss: {train_result.training_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T14:12:32.322229Z","iopub.execute_input":"2025-12-15T14:12:32.322548Z","iopub.status.idle":"2025-12-15T15:02:37.327759Z","shell.execute_reply.started":"2025-12-15T14:12:32.322508Z","shell.execute_reply":"2025-12-15T15:02:37.326903Z"},"papermill":{"duration":1747.936642,"end_time":"2025-11-30T03:25:49.463608","exception":false,"start_time":"2025-11-30T02:56:41.526966","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nTraining Feature Fusion Model\nModel will learn NER -> Topic relationships during each epoch\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48d5d16e8b2f4e00a986d31af1251005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1200' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1200/1700 49:59 < 20:51, 0.40 it/s, Epoch 70/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Ner Precision</th>\n      <th>Ner Recall</th>\n      <th>Ner F1</th>\n      <th>Ner Accuracy</th>\n      <th>Topic Precision</th>\n      <th>Topic Recall</th>\n      <th>Topic F1</th>\n      <th>Topic Accuracy</th>\n      <th>Intent Precision</th>\n      <th>Intent Recall</th>\n      <th>Intent F1</th>\n      <th>Intent Accuracy</th>\n      <th>Overall F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>150</td>\n      <td>4.238200</td>\n      <td>3.565055</td>\n      <td>0.516861</td>\n      <td>0.349255</td>\n      <td>0.416841</td>\n      <td>0.833342</td>\n      <td>0.836199</td>\n      <td>0.707020</td>\n      <td>0.735435</td>\n      <td>0.469914</td>\n      <td>0.775641</td>\n      <td>0.828080</td>\n      <td>0.788518</td>\n      <td>0.828080</td>\n      <td>0.646931</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.788500</td>\n      <td>2.806639</td>\n      <td>0.658596</td>\n      <td>0.715162</td>\n      <td>0.685714</td>\n      <td>0.924281</td>\n      <td>0.884670</td>\n      <td>0.870105</td>\n      <td>0.859667</td>\n      <td>0.664756</td>\n      <td>0.833873</td>\n      <td>0.851003</td>\n      <td>0.826109</td>\n      <td>0.851003</td>\n      <td>0.790497</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>2.294100</td>\n      <td>2.771544</td>\n      <td>0.719057</td>\n      <td>0.801928</td>\n      <td>0.758235</td>\n      <td>0.939446</td>\n      <td>0.881805</td>\n      <td>0.877268</td>\n      <td>0.859831</td>\n      <td>0.659026</td>\n      <td>0.861256</td>\n      <td>0.871060</td>\n      <td>0.854309</td>\n      <td>0.871060</td>\n      <td>0.824125</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.043100</td>\n      <td>2.811001</td>\n      <td>0.748515</td>\n      <td>0.828221</td>\n      <td>0.786353</td>\n      <td>0.944863</td>\n      <td>0.878462</td>\n      <td>0.887536</td>\n      <td>0.863460</td>\n      <td>0.661891</td>\n      <td>0.885162</td>\n      <td>0.888252</td>\n      <td>0.882910</td>\n      <td>0.888252</td>\n      <td>0.844241</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.921700</td>\n      <td>2.867435</td>\n      <td>0.759824</td>\n      <td>0.830412</td>\n      <td>0.793551</td>\n      <td>0.947083</td>\n      <td>0.884909</td>\n      <td>0.882044</td>\n      <td>0.864565</td>\n      <td>0.664756</td>\n      <td>0.874154</td>\n      <td>0.876791</td>\n      <td>0.874441</td>\n      <td>0.876791</td>\n      <td>0.844186</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.859100</td>\n      <td>2.907040</td>\n      <td>0.771817</td>\n      <td>0.844873</td>\n      <td>0.806695</td>\n      <td>0.949521</td>\n      <td>0.882760</td>\n      <td>0.890640</td>\n      <td>0.867690</td>\n      <td>0.664756</td>\n      <td>0.886429</td>\n      <td>0.876791</td>\n      <td>0.878791</td>\n      <td>0.876791</td>\n      <td>0.851059</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.824400</td>\n      <td>2.942520</td>\n      <td>0.771156</td>\n      <td>0.850570</td>\n      <td>0.808919</td>\n      <td>0.948492</td>\n      <td>0.883238</td>\n      <td>0.888491</td>\n      <td>0.866708</td>\n      <td>0.670487</td>\n      <td>0.879335</td>\n      <td>0.879656</td>\n      <td>0.878771</td>\n      <td>0.879656</td>\n      <td>0.851466</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.802900</td>\n      <td>2.956771</td>\n      <td>0.780048</td>\n      <td>0.853199</td>\n      <td>0.814985</td>\n      <td>0.950929</td>\n      <td>0.881328</td>\n      <td>0.888730</td>\n      <td>0.866353</td>\n      <td>0.667622</td>\n      <td>0.885976</td>\n      <td>0.882521</td>\n      <td>0.883271</td>\n      <td>0.882521</td>\n      <td>0.854870</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nOVERFIT WARNING - Step 900:\n  Train Loss: 1.8591 | Val Loss: 2.9070 | Gap: 1.56x\n  Overfit count: 1/3\n\nOVERFIT WARNING - Step 1050:\n  Train Loss: 1.8244 | Val Loss: 2.9425 | Gap: 1.61x\n  Overfit count: 2/3\n\nOVERFIT WARNING - Step 1200:\n  Train Loss: 1.8029 | Val Loss: 2.9568 | Gap: 1.64x\n  Overfit count: 3/3\n\nSTOPPING: Overfit detected 3 times consecutively\nBest model will be loaded automatically\n\nTraining completed in 50.08 minutes\nFinal loss: 2.6641\n","output_type":"stream"}],"execution_count":15},{"id":"ae26d9eb","cell_type":"markdown","source":"### 11.7. Đánh giá Test Set","metadata":{"papermill":{"duration":0.012661,"end_time":"2025-11-30T03:25:49.489754","exception":false,"start_time":"2025-11-30T03:25:49.477093","status":"completed"},"tags":[]}},{"id":"6c6c7dbb","cell_type":"code","source":"# Evaluate on test set\ntest_results_fusion = trainer_fusion.evaluate(test_dataset)\n\nprint(\"=\"*80)\nprint(\"Test Results - Feature Fusion Model\")\nprint(\"=\"*80)\nprint(f\"Overall F1: {test_results_fusion['eval_overall_f1']:.4f}\")\nprint(f\"NER F1: {test_results_fusion['eval_ner_f1']:.4f}\")\nprint(f\"Topic F1: {test_results_fusion['eval_topic_f1']:.4f}\")\nprint(f\"Topic Recall: {test_results_fusion['eval_topic_recall']:.4f}\")\nprint(f\"Intent F1: {test_results_fusion['eval_intent_f1']:.4f}\")\nprint(\"=\"*80)","metadata":{"execution":{"iopub.status.busy":"2025-12-15T15:02:37.328941Z","iopub.execute_input":"2025-12-15T15:02:37.329366Z","iopub.status.idle":"2025-12-15T15:02:40.788295Z","shell.execute_reply.started":"2025-12-15T15:02:37.329339Z","shell.execute_reply":"2025-12-15T15:02:40.787087Z"},"papermill":{"duration":3.220451,"end_time":"2025-11-30T03:25:52.722375","exception":false,"start_time":"2025-11-30T03:25:49.501924","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4/4 00:02]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nOVERFIT WARNING - Step 1200:\n  Train Loss: 1.8029 | Val Loss: 3.1429 | Gap: 1.74x\n  Overfit count: 4/3\n\nSTOPPING: Overfit detected 3 times consecutively\nBest model will be loaded automatically\n================================================================================\nTest Results - Feature Fusion Model\n================================================================================\nOverall F1: 0.8371\nNER F1: 0.8296\nTopic F1: 0.8540\nTopic Recall: 0.8663\nIntent F1: 0.8278\n================================================================================\n","output_type":"stream"}],"execution_count":16},{"id":"0240141d","cell_type":"markdown","source":"### 11.8. Lưu Model","metadata":{"papermill":{"duration":0.013123,"end_time":"2025-11-30T03:25:52.749281","exception":false,"start_time":"2025-11-30T03:25:52.736158","status":"completed"},"tags":[]}},{"id":"c3131e37","cell_type":"code","source":"# Hàm tìm best checkpoint\ndef find_best_checkpoint(output_dir):\n    \"\"\"Tìm checkpoint tốt nhất dựa trên tên folder\"\"\"\n    import glob\n    checkpoints = glob.glob(f\"{output_dir}/checkpoint-*\")\n    if not checkpoints:\n        return None\n    # Sắp xếp theo số step (checkpoint-xxx)\n    checkpoints.sort(key=lambda x: int(x.split('-')[-1]))\n    return checkpoints[-1] if checkpoints else None\n\n# Save model\nfusion_final_path = \"./phobert_multitask_fusion_final\"\nos.makedirs(fusion_final_path, exist_ok=True)\n\ntorch.save(model_fusion.state_dict(), f\"{fusion_final_path}/pytorch_model.bin\")\ntokenizer.save_pretrained(fusion_final_path)\n\n# Save label mappings\nwith open(f\"{fusion_final_path}/label_mappings.json\", 'w', encoding='utf-8') as f:\n    json.dump({\n        'ner_label2id': ner_label2id,\n        'ner_id2label': ner_id2label,\n        'topic_label2id': topic_label2id,\n        'topic_id2label': topic_id2label,\n        'intent_label2id': intent_label2id,\n        'intent_id2label': intent_id2label\n    }, f, ensure_ascii=False, indent=2)\n\n# Save config\nmodel_config_fusion = {\n    'model_type': 'MultiTaskPhoBERT_WithFusion',\n    'phobert_base': phobert_path,\n    'num_ner_labels': len(ner_label2id),\n    'num_topic_labels': len(topic_label2id),\n    'num_intent_labels': len(intent_label2id),\n    'hidden_size': model_fusion.phobert.config.hidden_size,\n    'dropout': 0.1,\n    'test_results': test_results_fusion\n}\n\nwith open(f\"{fusion_final_path}/model_config.json\", 'w', encoding='utf-8') as f:\n    json.dump(model_config_fusion, f, ensure_ascii=False, indent=2)\n\nprint(f\"Model saved to: {fusion_final_path}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T15:02:40.789726Z","iopub.execute_input":"2025-12-15T15:02:40.790157Z","iopub.status.idle":"2025-12-15T15:02:41.581755Z","shell.execute_reply.started":"2025-12-15T15:02:40.790114Z","shell.execute_reply":"2025-12-15T15:02:41.580956Z"},"papermill":{"duration":0.743804,"end_time":"2025-11-30T03:25:53.505396","exception":false,"start_time":"2025-11-30T03:25:52.761592","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Model saved to: ./phobert_multitask_fusion_final\n","output_type":"stream"}],"execution_count":17},{"id":"881aabd1","cell_type":"markdown","source":"## 12. Download Model","metadata":{"papermill":{"duration":0.01261,"end_time":"2025-11-30T03:25:53.531510","exception":false,"start_time":"2025-11-30T03:25:53.518900","status":"completed"},"tags":[]}},{"id":"2c9b827c","cell_type":"code","source":"# TẢI MODEL VỀ MÁY CÁ NHÂN \n\nif IS_KAGGLE:\n    import shutil\n    from pathlib import Path\n    \n    print(\"=\"*80)\n    print(\"CHUẨN BỊ DOWNLOAD MODEL VỀ MÁY CÁ NHÂN\")\n    print(\"=\"*80)\n    \n    # Đường dẫn model đã train (từ checkpoint tốt nhất hoặc final)\n    source_paths = [\n        \"/kaggle/working/phobert_multitask_fusion_final\",  # Model final\n        \"/kaggle/working/phobert_multitask_fusion_model\",  # Thư mục checkpoints\n    ]\n    \n    # Tạo file zip để dễ download\n    zip_output = \"/kaggle/working/phobert_model_download\"\n    \n    print(\"\\nĐang nén model...\")\n    \n    # Nén model final\n    if os.path.exists(source_paths[0]):\n        shutil.make_archive(\n            \"/kaggle/working/phobert_multitask_final\",\n            'zip',\n            source_paths[0]\n        )\n        print(f\"Đã nén: phobert_multitask_final.zip\")\n        print(f\"  Kích thước: {os.path.getsize('/kaggle/working/phobert_multitask_final.zip') / (1024*1024):.1f} MB\")\n    \n    # Nén checkpoint tốt nhất\n    best_checkpoint = find_best_checkpoint(\"/kaggle/working/phobert_multitask_fusion\")\n    if best_checkpoint:\n        checkpoint_name = os.path.basename(best_checkpoint)\n        shutil.make_archive(\n            f\"/kaggle/working/{checkpoint_name}\",\n            'zip',\n            best_checkpoint\n        )\n        print(f\"Đã nén: {checkpoint_name}.zip\")\n        print(f\"  Kích thước: {os.path.getsize(f'/kaggle/working/{checkpoint_name}.zip') / (1024*1024):.1f} MB\")\n    \n    \n    # Liệt kê các file có thể download\n    print(\"\\nCÁC FILE TRONG /kaggle/working:\")\n    print(\"-\" * 80)\n    for file in os.listdir(\"/kaggle/working\"):\n        if file.endswith('.zip') or os.path.isdir(f\"/kaggle/working/{file}\"):\n            path = f\"/kaggle/working/{file}\"\n            if os.path.isfile(path):\n                size = os.path.getsize(path) / (1024*1024)\n                print(f\"   {file:50s} ({size:.1f} MB)\")\n            else:\n                print(f\"   {file}/\")\n    \n    print(\"=\"*80)\n    \nelse:\n    print(\"Code này chỉ chạy trên Kaggle\")\n    print(\"Trên Local, model đã có sẵn tại: ./phobert_multitask_final\")","metadata":{"execution":{"iopub.status.busy":"2025-12-15T15:02:41.582793Z","iopub.execute_input":"2025-12-15T15:02:41.583146Z","iopub.status.idle":"2025-12-15T15:04:16.608121Z","shell.execute_reply.started":"2025-12-15T15:02:41.583127Z","shell.execute_reply":"2025-12-15T15:04:16.607355Z"},"papermill":{"duration":93.296232,"end_time":"2025-11-30T03:27:26.840454","exception":false,"start_time":"2025-11-30T03:25:53.544222","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nCHUẨN BỊ DOWNLOAD MODEL VỀ MÁY CÁ NHÂN\n================================================================================\n\nĐang nén model...\nĐã nén: phobert_multitask_final.zip\n  Kích thước: 494.1 MB\nĐã nén: checkpoint-1200.zip\n  Kích thước: 1154.5 MB\n\nCÁC FILE TRONG /kaggle/working:\n--------------------------------------------------------------------------------\n   phobert_multitask_final.zip                        (494.1 MB)\n   phobert_multitask_fusion_final/\n   checkpoint-1200.zip                                (1154.5 MB)\n   phobert_multitask_fusion/\n   .virtual_documents/\n================================================================================\n","output_type":"stream"}],"execution_count":18}]}