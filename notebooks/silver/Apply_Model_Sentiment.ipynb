{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070f8335",
   "metadata": {},
   "source": [
    "# PhÃ¢n TÃ­ch Cáº£m XÃºc Comment vá»›i Vietnamese-Sentiment-visobert\n",
    "\n",
    "Notebook nÃ y sáº½:\n",
    "1. Láº¥y dá»¯ liá»‡u comment tá»« báº£ng `nessie.silver_tables.comment` trong khoáº£ng thá»i gian nháº¥t Ä‘á»‹nh\n",
    "2. Ãp dá»¥ng model Vietnamese-Sentiment-visobert Ä‘á»ƒ phÃ¢n tÃ­ch cáº£m xÃºc\n",
    "3. Tá»•ng há»£p cÃ¡c chá»‰ sá»‘ POS (tÃ­ch cá»±c), NEG (tiÃªu cá»±c), NEU (trung láº­p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f0214",
   "metadata": {},
   "source": [
    "## 1. Import Libraries vÃ  Khá»Ÿi táº¡o Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3c0099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark Session Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o!\n",
      "Spark Master: spark://spark-master:7077\n",
      "Application ID: app-20251208151458-0001\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, to_date, avg, sum as spark_sum\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Set AWS environment variables for MinIO\n",
    "os.environ['AWS_REGION'] = 'us-east-1'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'admin123'\n",
    "\n",
    "# Khá»Ÿi táº¡o Spark Session vá»›i Iceberg vÃ  Nessie catalog\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Apply_Sentiment_Model\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    # ===== Iceberg Catalog qua Nessie =====\n",
    "    .config(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.uri\", \"http://nessie:19120/api/v2\")\n",
    "    .config(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "    .config(\"spark.sql.catalog.nessie.warehouse\", \"s3a://silver/\")\n",
    "    .config(\"spark.sql.catalog.nessie.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    # ===== Cáº¥u hÃ¬nh MinIO (S3-compatible) =====\n",
    "    .config(\"spark.sql.catalog.nessie.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.access-key-id\", \"admin\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.secret-access-key\", \"admin123\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.path-style-access\", \"true\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.region\", \"us-east-1\")\n",
    "    # ===== Spark + Hadoop S3 connector =====\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin123\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .config(\"spark.hadoop.fs.s3a.region\", \"us-east-1\")\n",
    "    # Propagate environment variables to executors\n",
    "    .config(\"spark.executorEnv.AWS_REGION\", \"us-east-1\")\n",
    "    .config(\"spark.executorEnv.AWS_ACCESS_KEY_ID\", \"admin\")\n",
    "    .config(\"spark.executorEnv.AWS_SECRET_ACCESS_KEY\", \"admin123\")\n",
    "    # ===== JAR files =====\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/hadoop-aws-3.3.4.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"âœ… Spark Session Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o!\")\n",
    "print(f\"Spark Master: {spark.sparkContext.master}\")\n",
    "print(f\"Application ID: {spark.sparkContext.applicationId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0dcd4",
   "metadata": {},
   "source": [
    "## 2. Load Vietnamese Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d2fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Äang táº£i model Vietnamese-Sentiment-visobert...\n",
      "âœ… Model Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!\n",
      "Device: cpu\n",
      "Labels: {0: 'NEG', 1: 'POS', 2: 'NEU'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ÄÆ°á»ng dáº«n Ä‘áº¿n model\n",
    "model_path = \"/opt/spark-apps/Vietnamese-Sentiment-visobert\"\n",
    "\n",
    "print(\"â³ Äang táº£i model Vietnamese-Sentiment-visobert...\")\n",
    "\n",
    "# Load tokenizer vÃ  model (use_fast=False Ä‘á»ƒ trÃ¡nh lá»—i tokenizer.json)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Kiá»ƒm tra vÃ  sá»­ dá»¥ng GPU náº¿u cÃ³\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"âœ… Model Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Labels: {model.config.id2label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce9fb8",
   "metadata": {},
   "source": [
    "## 3. Äá»‹nh nghÄ©a HÃ m Dá»± ÄoÃ¡n Cáº£m XÃºc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a430925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test text: TrÆ°á»ng nÃ y ráº¥t tá»‘t, giáº£ng viÃªn nhiá»‡t tÃ¬nh!\n",
      "Sentiment: POS\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    \"\"\"\n",
    "    Dá»± Ä‘oÃ¡n cáº£m xÃºc cá»§a vÄƒn báº£n\n",
    "    Returns: sentiment label (POS, NEG, NEU)\n",
    "    \"\"\"\n",
    "    if not text or text.strip() == \"\":\n",
    "        return \"NEU\"\n",
    "    \n",
    "    try:\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256, padding=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Dá»± Ä‘oÃ¡n\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = F.softmax(logits, dim=-1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "        \n",
    "        # Chuyá»ƒn Ä‘á»•i id sang label\n",
    "        sentiment = model.config.id2label[predicted_class]\n",
    "        return sentiment\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        return \"NEU\"\n",
    "\n",
    "# Test function\n",
    "test_text = \"TrÆ°á»ng nÃ y ráº¥t tá»‘t, giáº£ng viÃªn nhiá»‡t tÃ¬nh!\"\n",
    "print(f\"Test text: {test_text}\")\n",
    "print(f\"Sentiment: {predict_sentiment(test_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415b5862",
   "metadata": {},
   "source": [
    "## 4. Láº¥y Dá»¯ Liá»‡u Comment tá»« Báº£ng Silver (Batch Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c374296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Äang load batch comment chÆ°a xá»­ lÃ½ tá»« Silver...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:===================================================>(6667 + 4) / 6672]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Batch hiá»‡n táº¡i: 20,000 comment\n",
      "\n",
      "âœ… Sáºµn sÃ ng xá»­ lÃ½ 20,000 comment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Cáº¥u hÃ¬nh batch processing\n",
    "BATCH_SIZE = 20000  # Sá»‘ lÆ°á»£ng comment xá»­ lÃ½ má»—i batch\n",
    "\n",
    "print(\"ðŸ” Äang load batch comment chÆ°a xá»­ lÃ½ tá»« Silver...\")\n",
    "\n",
    "# ===== Tá»I Æ¯U: DÃ¹ng SQL vá»›i LEFT ANTI JOIN (SUBQUERY) =====\n",
    "# CÃ¡ch nÃ y NHANH NHáº¤T vÃ¬:\n",
    "# 1. Spark optimize toÃ n bá»™ query thÃ nh 1 execution plan\n",
    "# 2. Iceberg pruning: chá»‰ scan partition/file cáº§n thiáº¿t\n",
    "# 3. KHÃ”NG load toÃ n bá»™ Silver hay Gold vÃ o memory\n",
    "# 4. Push-down predicates xuá»‘ng storage layer\n",
    "\n",
    "try:\n",
    "    # Query vá»›i LEFT ANTI JOIN ngay trong SQL\n",
    "    # Spark sáº½ optimize vÃ  chá»‰ scan cáº§n thiáº¿t\n",
    "    df_comments = spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            s.articleID as postID,\n",
    "            s.commentID,\n",
    "            s.comment,\n",
    "            s.commentTime,\n",
    "            s.commentLike,\n",
    "            s.levelComment,\n",
    "            s.numberOfReply,\n",
    "            s.created_at,\n",
    "            s.updated_at\n",
    "        FROM nessie.silver_tables.comment s\n",
    "        LEFT ANTI JOIN nessie.gold_result_model_multi_task.Comment_Sentiment g\n",
    "            ON s.commentID = g.commentID\n",
    "        WHERE s.comment IS NOT NULL\n",
    "          AND TRIM(s.comment) != ''\n",
    "        LIMIT {BATCH_SIZE}\n",
    "    \"\"\")\n",
    "    \n",
    "    total_comments = df_comments.count()\n",
    "    \n",
    "    # # Äáº¿m sá»‘ comment Ä‘Ã£ xá»­ lÃ½ (náº¿u cáº§n thá»‘ng kÃª)\n",
    "    # try:\n",
    "    #     existing_count = spark.sql(\"\"\"\n",
    "    #         SELECT COUNT(DISTINCT commentID) as count\n",
    "    #         FROM nessie.gold_result_model_multi_task.Comment_Sentiment\n",
    "    #     \"\"\").collect()[0]['count']\n",
    "    #     print(f\"âœ… ÄÃ£ cÃ³ trong Gold: {existing_count:,} comment\")\n",
    "    # except:\n",
    "    #     print(\"âœ… Báº£ng Gold Ä‘ang trá»‘ng\")\n",
    "    \n",
    "    print(f\"ðŸ“¦ Batch hiá»‡n táº¡i: {total_comments:,} comment\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Báº£ng Gold chÆ°a tá»“n táº¡i: {str(e)}\")\n",
    "    print(\"ðŸ“ Load batch Ä‘áº§u tiÃªn tá»« Silver...\")\n",
    "    \n",
    "    # Náº¿u Gold chÆ°a cÃ³, láº¥y batch Ä‘áº§u tiÃªn\n",
    "    df_comments = spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            articleID as postID,\n",
    "            commentID,\n",
    "            comment,\n",
    "            commentTime,\n",
    "            commentLike,\n",
    "            levelComment,\n",
    "            numberOfReply,\n",
    "            created_at,\n",
    "            updated_at\n",
    "        FROM nessie.silver_tables.comment\n",
    "        WHERE comment IS NOT NULL\n",
    "          AND TRIM(comment) != ''\n",
    "        LIMIT {BATCH_SIZE}\n",
    "    \"\"\")\n",
    "    \n",
    "    total_comments = df_comments.count()\n",
    "    print(f\"ðŸ“¦ Batch Ä‘áº§u tiÃªn: {total_comments:,} comment\")\n",
    "\n",
    "if total_comments > 0:\n",
    "    print(f\"\\nâœ… Sáºµn sÃ ng xá»­ lÃ½ {total_comments:,} comment\")\n",
    "else:\n",
    "    print(\"\\nðŸŽ‰ Táº¥t cáº£ comment Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½!\")\n",
    "    print(\"ðŸ’¡ KhÃ´ng cÃ³ comment má»›i cáº§n phÃ¢n tÃ­ch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9e67d7",
   "metadata": {},
   "source": [
    "## 5. Ãp Dá»¥ng Model Sentiment cho Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0556f091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Äang Ã¡p dá»¥ng model sentiment...\n",
      "\n",
      "ðŸ“¥ BÆ°á»›c 1: Thu tháº­p dá»¯ liá»‡u vá» driver...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Thu tháº­p 20000 comment\n",
      "\n",
      "ðŸ“‹ BÆ°á»›c 2: Chuáº©n bá»‹ báº£ng Gold...\n",
      "âœ… Báº£ng Ä‘Ã£ tá»“n táº¡i hoáº·c Ä‘Æ°á»£c táº¡o má»›i.\n",
      "\n",
      "ðŸ”„ BÆ°á»›c 3: Xá»­ lÃ½ 20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 1000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 1500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 2000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 2500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 3000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 3500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 4000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 4500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 5000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 5500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 6000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 6500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 7000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 7500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 8000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 8500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 9000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 9500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 10000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 10500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 11000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 11500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 12000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 12500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 13000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 13500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 14000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 14500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 15000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 15500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 16000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 16500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 17000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 17500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 18000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 18500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 19000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 19500/20000 comment...\n",
      "   âœ“ ÄÃ£ xá»­ lÃ½ 20000/20000 comment...\n",
      "\n",
      "ðŸ’¾ LÆ°u batch 1000 vÃ o Gold...\n",
      "   â†’ ÄÃ£ lÆ°u xong batch\n",
      "\n",
      "ðŸŽ‰ HoÃ n táº¥t phÃ¢n tÃ­ch sentiment vÃ  lÆ°u Gold layer!\n",
      "\n",
      "ðŸ” VÃ­ dá»¥ 10 dÃ²ng má»›i nháº¥t tá»« Gold:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 100:====================================================>(208 + 4) / 212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+---------+-----------------------------------------+---------+-------------------+-----------+\n",
      "|                                        postID|commentID|                                  comment|sentiment|        commentTime|commentLike|\n",
      "+----------------------------------------------+---------+-----------------------------------------+---------+-------------------+-----------+\n",
      "|         @khoibeooto/video/7494220834781809928|    59337|                        Em muá»‘n há»c sao áº¡|      POS|2025-05-11 00:00:00|          1|\n",
      "|    @cepdgnlcand.cep/video/7458558566757059847|    59458|                              CÃ³ báº¡n nha!|      NEU|2025-01-23 00:00:00|          0|\n",
      "|@vococenter_official/video/6976630345588280578|    59285|                   Ä‘c. náº¿u e thÃ­ch & muá»‘n|      POS|2021-08-08 00:00:00|          0|\n",
      "|         @luatsubinh/video/6988687885616696602|    59852|              Ä‘áº¡i há»c luáº­t Huáº¿ á»•n khÃ´ng áº¡|      NEU|2021-08-22 00:00:00|          2|\n",
      "|         @luatsubinh/video/6988687885616696602|    59853|                                     Äc e|      POS|2021-08-22 00:00:00|          0|\n",
      "|         @luatsubinh/video/6988687885616696602|    59874|                             chÃ o luáº­t sÆ°|      NEU|2021-08-22 00:00:00|          1|\n",
      "|         @luatsubinh/video/6988687885616696602|    59854|dáº¡ em cáº£m Æ¡n áº¡. em gÃ¡i Ä‘ag há»c nÄƒm nháº¥t áº¡|      POS|2021-08-22 00:00:00|          0|\n",
      "|@vococenter_official/video/6976630345588280578|    59282|      QT nhÃ¢n lá»±c cáº§n cÃ³ kÄ© nÄƒng gÃ¬ v chá»‹|      POS|2021-07-14 00:00:00|          0|\n",
      "|          @duytanuni/video/7145403885388139803|    59048|                        duy tÃ¢n cÃ³ khÃ¡cðŸ˜³|      POS|2022-09-24 00:00:00|          0|\n",
      "|   @duhocvadaotaokep/video/7267921041773579526|    59572|                  nghá» logistic thÃ¬ sao áº¡|      NEU|2024-02-24 00:00:00|          1|\n",
      "+----------------------------------------------+---------+-----------------------------------------+---------+-------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, TimestampType\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ===== HÃ€M Xá»¬ LÃ GIÃ TRá»Š TIMESTAMP =====\n",
    "def safe_ts(v):\n",
    "    \"\"\"Chuyá»ƒn pandas NaT / NaN / None thÃ nh None hoáº·c datetime.\"\"\"\n",
    "    if v is None or pd.isna(v):\n",
    "        return None\n",
    "    if isinstance(v, pd.Timestamp):\n",
    "        return v.to_pydatetime()\n",
    "    return v\n",
    "\n",
    "print(\"â³ Äang Ã¡p dá»¥ng model sentiment...\")\n",
    "\n",
    "if total_comments > 0:\n",
    "    print(\"\\nðŸ“¥ BÆ°á»›c 1: Thu tháº­p dá»¯ liá»‡u vá» driver...\")\n",
    "    comments_pd = df_comments.toPandas()\n",
    "    print(f\"âœ… Thu tháº­p {len(comments_pd)} comment\")\n",
    "\n",
    "    batch_save_size = 1000\n",
    "    results = []\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"postID\", StringType(), True),\n",
    "        StructField(\"commentID\", LongType(), True),\n",
    "        StructField(\"comment\", StringType(), True),\n",
    "        StructField(\"sentiment\", StringType(), True),\n",
    "        StructField(\"commentTime\", TimestampType(), True),\n",
    "        StructField(\"commentLike\", IntegerType(), True),\n",
    "        StructField(\"levelComment\", IntegerType(), True),\n",
    "        StructField(\"numberOfReply\", IntegerType(), True),\n",
    "        StructField(\"created_at\", TimestampType(), True),\n",
    "        StructField(\"updated_at\", TimestampType(), True)\n",
    "    ])\n",
    "\n",
    "    print(\"\\nðŸ“‹ BÆ°á»›c 2: Chuáº©n bá»‹ báº£ng Gold...\")\n",
    "    spark.sql(\"CREATE DATABASE IF NOT EXISTS nessie.gold_result_model_multi_task\")\n",
    "\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS nessie.gold_result_model_multi_task.Comment_Sentiment (\n",
    "        postID STRING,\n",
    "        commentID BIGINT,\n",
    "        comment STRING,\n",
    "        sentiment STRING,\n",
    "        commentTime TIMESTAMP,\n",
    "        commentLike INT,\n",
    "        levelComment INT,\n",
    "        numberOfReply INT,\n",
    "        created_at TIMESTAMP,\n",
    "        updated_at TIMESTAMP\n",
    "    ) USING iceberg\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"âœ… Báº£ng Ä‘Ã£ tá»“n táº¡i hoáº·c Ä‘Æ°á»£c táº¡o má»›i.\")\n",
    "\n",
    "    print(f\"\\nðŸ”„ BÆ°á»›c 3: Xá»­ lÃ½ {len(comments_pd)} comment...\")\n",
    "\n",
    "    for idx, row in comments_pd.iterrows():\n",
    "\n",
    "        # ---- Predict sentiment ----\n",
    "        sentiment = predict_sentiment(row['comment'])\n",
    "\n",
    "        # ---- Append káº¿t quáº£ vÃ o list ----\n",
    "        results.append({\n",
    "            'postID': row['postID'],\n",
    "            'commentID': int(row['commentID']) if not pd.isna(row['commentID']) else None,\n",
    "            'comment': row['comment'],\n",
    "            'sentiment': sentiment,\n",
    "            'commentTime': safe_ts(row['commentTime']),\n",
    "            'commentLike': int(row['commentLike']) if not pd.isna(row['commentLike']) else 0,\n",
    "            'levelComment': int(row['levelComment']) if not pd.isna(row['levelComment']) else 0,\n",
    "            'numberOfReply': int(row['numberOfReply']) if not pd.isna(row['numberOfReply']) else 0,\n",
    "            'created_at': safe_ts(row['created_at']),\n",
    "            'updated_at': datetime.now()\n",
    "        })\n",
    "\n",
    "        if (idx + 1) % 500 == 0:\n",
    "            print(f\"   âœ“ ÄÃ£ xá»­ lÃ½ {idx+1}/{len(comments_pd)} comment...\")\n",
    "\n",
    "        # ---- LÆ°u batch ----\n",
    "        if len(results) >= batch_save_size:\n",
    "            print(f\"\\nðŸ’¾ LÆ°u batch {len(results)} vÃ o Gold...\")\n",
    "            df_batch = spark.createDataFrame(results, schema=schema)\n",
    "            df_batch.writeTo(\"nessie.gold_result_model_multi_task.Comment_Sentiment\") \\\n",
    "                .using(\"iceberg\") \\\n",
    "                .append()\n",
    "            print(\"   â†’ ÄÃ£ lÆ°u xong batch\")\n",
    "            results = []\n",
    "\n",
    "    # ---- LÆ°u batch cuá»‘i ----\n",
    "    if len(results) > 0:\n",
    "        print(f\"\\nðŸ’¾ LÆ°u batch cuá»‘i {len(results)} comment...\")\n",
    "        df_batch = spark.createDataFrame(results, schema=schema)\n",
    "        df_batch.writeTo(\"nessie.gold_result_model_multi_task.Comment_Sentiment\") \\\n",
    "            .using(\"iceberg\") \\\n",
    "            .append()\n",
    "        print(\"   â†’ ÄÃ£ lÆ°u xong batch cuá»‘i\")\n",
    "\n",
    "    print(\"\\nðŸŽ‰ HoÃ n táº¥t phÃ¢n tÃ­ch sentiment vÃ  lÆ°u Gold layer!\")\n",
    "\n",
    "    print(\"\\nðŸ” VÃ­ dá»¥ 10 dÃ²ng má»›i nháº¥t tá»« Gold:\")\n",
    "    df_gold_sample = spark.sql(\"\"\"\n",
    "        SELECT postID, commentID, comment, sentiment, commentTime, commentLike\n",
    "        FROM nessie.gold_result_model_multi_task.Comment_Sentiment\n",
    "        ORDER BY updated_at DESC\n",
    "        LIMIT 10\n",
    "    \"\"\")\n",
    "    df_gold_sample.show(10, truncate=50)\n",
    "\n",
    "    df_with_sentiment = spark.sql(\"\"\"\n",
    "        SELECT * FROM nessie.gold_result_model_multi_task.Comment_Sentiment\n",
    "        ORDER BY updated_at DESC\n",
    "        LIMIT {}\n",
    "    \"\"\".format(total_comments))\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ KhÃ´ng cÃ³ comment Ä‘á»ƒ xá»­ lÃ½!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb979cf0",
   "metadata": {},
   "source": [
    "## 6. Tá»•ng Há»£p CÃ¡c Chá»‰ Sá»‘ Sentiment (POS, NEG, NEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ec133a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if total_comments > 0:\n",
    "#     print(\"ðŸ“Š THá»NG KÃŠ Tá»”NG QUAN\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     # 1. Äáº¿m sá»‘ lÆ°á»£ng theo tá»«ng loáº¡i sentiment\n",
    "#     sentiment_counts = df_with_sentiment.groupBy(\"sentiment\").count().orderBy(\"count\", ascending=False)\n",
    "    \n",
    "#     print(\"\\n1ï¸âƒ£ PhÃ¢n bá»‘ Sentiment:\")\n",
    "#     sentiment_counts.show()\n",
    "    \n",
    "#     # 2. TÃ­nh pháº§n trÄƒm\n",
    "#     sentiment_stats = sentiment_counts.withColumn(\n",
    "#         \"percentage\",\n",
    "#         (col(\"count\") / total_comments * 100)\n",
    "#     )\n",
    "    \n",
    "#     print(\"\\n2ï¸âƒ£ PhÃ¢n bá»‘ Sentiment (%)\")\n",
    "#     sentiment_stats.show()\n",
    "    \n",
    "#     # 3. Tá»•ng há»£p chi tiáº¿t\n",
    "#     pos_count = df_with_sentiment.filter(col(\"sentiment\") == \"POS\").count()\n",
    "#     neg_count = df_with_sentiment.filter(col(\"sentiment\") == \"NEG\").count()\n",
    "#     neu_count = df_with_sentiment.filter(col(\"sentiment\") == \"NEU\").count()\n",
    "    \n",
    "#     pos_pct = (pos_count / total_comments * 100) if total_comments > 0 else 0\n",
    "#     neg_pct = (neg_count / total_comments * 100) if total_comments > 0 else 0\n",
    "#     neu_pct = (neu_count / total_comments * 100) if total_comments > 0 else 0\n",
    "    \n",
    "#     print(\"\\n3ï¸âƒ£ Tá»•ng Há»£p Chi Tiáº¿t:\")\n",
    "#     print(f\"   ðŸŸ¢ POSITIVE (POS): {pos_count:,} comment ({pos_pct:.2f}%)\")\n",
    "#     print(f\"   ðŸ”´ NEGATIVE (NEG): {neg_count:,} comment ({neg_pct:.2f}%)\")\n",
    "#     print(f\"   âšª NEUTRAL (NEU):  {neu_count:,} comment ({neu_pct:.2f}%)\")\n",
    "#     print(f\"   ðŸ“Š Tá»”NG Cá»˜NG:      {total_comments:,} comment\")\n",
    "    \n",
    "# else:\n",
    "#     print(\"âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ tá»•ng há»£p!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888d552",
   "metadata": {},
   "source": [
    "## 7. PhÃ¢n TÃ­ch Sentiment Theo Thá»i Gian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "218510bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if total_comments > 0:\n",
    "#     # PhÃ¢n tÃ­ch theo ngÃ y\n",
    "#     df_by_date = df_with_sentiment.withColumn(\"date\", to_date(col(\"commentTime\")))\n",
    "    \n",
    "#     sentiment_by_date = df_by_date.groupBy(\"date\", \"sentiment\").count() \\\n",
    "#         .orderBy(\"date\", ascending=False)\n",
    "    \n",
    "#     print(\"ðŸ“… PhÃ¢n bá»‘ Sentiment theo NgÃ y:\")\n",
    "#     sentiment_by_date.show(20)\n",
    "    \n",
    "#     # Pivot Ä‘á»ƒ dá»… nhÃ¬n hÆ¡n\n",
    "#     sentiment_pivot = df_by_date.groupBy(\"date\").pivot(\"sentiment\").count() \\\n",
    "#         .fillna(0) \\\n",
    "#         .orderBy(\"date\", ascending=False)\n",
    "    \n",
    "#     print(\"\\nðŸ“Š Báº£ng Pivot Sentiment theo NgÃ y:\")\n",
    "#     sentiment_pivot.show(20)\n",
    "# else:\n",
    "#     print(\"âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch theo thá»i gian!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf8bbe",
   "metadata": {},
   "source": [
    "## 8. PhÃ¢n TÃ­ch Sentiment Theo BÃ i Viáº¿t (Article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf7967b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if total_comments > 0:\n",
    "#     # Top bÃ i viáº¿t cÃ³ nhiá»u comment tÃ­ch cá»±c nháº¥t\n",
    "#     pos_by_article = df_with_sentiment.filter(col(\"sentiment\") == \"POS\") \\\n",
    "#         .groupBy(\"postID\") \\\n",
    "#         .agg(count(\"*\").alias(\"positive_count\")) \\\n",
    "#         .orderBy(\"positive_count\", ascending=False)\n",
    "    \n",
    "#     print(\"ðŸŸ¢ Top 10 BÃ i Viáº¿t cÃ³ nhiá»u Comment TÃCH Cá»°C nháº¥t:\")\n",
    "#     pos_by_article.show(10, truncate=False)\n",
    "    \n",
    "#     # Top bÃ i viáº¿t cÃ³ nhiá»u comment tiÃªu cá»±c nháº¥t\n",
    "#     neg_by_article = df_with_sentiment.filter(col(\"sentiment\") == \"NEG\") \\\n",
    "#         .groupBy(\"postID\") \\\n",
    "#         .agg(count(\"*\").alias(\"negative_count\")) \\\n",
    "#         .orderBy(\"negative_count\", ascending=False)\n",
    "    \n",
    "#     print(\"\\nðŸ”´ Top 10 BÃ i Viáº¿t cÃ³ nhiá»u Comment TIÃŠU Cá»°C nháº¥t:\")\n",
    "#     neg_by_article.show(10, truncate=False)\n",
    "    \n",
    "#     # Tá»•ng há»£p sentiment cho tá»«ng article\n",
    "#     sentiment_by_article = df_with_sentiment.groupBy(\"postID\").pivot(\"sentiment\").count() \\\n",
    "#         .fillna(0) \\\n",
    "#         .withColumn(\"total_comments\", col(\"POS\") + col(\"NEG\") + col(\"NEU\")) \\\n",
    "#         .orderBy(\"total_comments\", ascending=False)\n",
    "    \n",
    "#     print(\"\\nðŸ“Š Tá»•ng Há»£p Sentiment theo BÃ i Viáº¿t (Top 20):\")\n",
    "#     sentiment_by_article.show(20, truncate=False)\n",
    "# else:\n",
    "#     print(\"âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch theo bÃ i viáº¿t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b93797a",
   "metadata": {},
   "source": [
    "## 9. Visualization - Trá»±c Quan HÃ³a Káº¿t Quáº£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4efedc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if total_comments > 0:\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn as sns\n",
    "    \n",
    "#     # Set style\n",
    "#     sns.set_style(\"whitegrid\")\n",
    "    \n",
    "#     # Chuyá»ƒn Ä‘á»•i sang Pandas Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“\n",
    "#     sentiment_pd = sentiment_stats.toPandas()\n",
    "    \n",
    "#     # Táº¡o figure vá»›i 2 subplots\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "#     # 1. Bar chart\n",
    "#     colors = {'POS': '#4CAF50', 'NEG': '#F44336', 'NEU': '#9E9E9E'}\n",
    "#     bar_colors = [colors.get(s, '#9E9E9E') for s in sentiment_pd['sentiment']]\n",
    "    \n",
    "#     ax1.bar(sentiment_pd['sentiment'], sentiment_pd['count'], color=bar_colors)\n",
    "#     ax1.set_xlabel('Sentiment', fontsize=12)\n",
    "#     ax1.set_ylabel('Sá»‘ lÆ°á»£ng Comment', fontsize=12)\n",
    "#     ax1.set_title('PhÃ¢n Bá»‘ Sentiment - Bar Chart', fontsize=14, fontweight='bold')\n",
    "    \n",
    "#     # ThÃªm sá»‘ liá»‡u lÃªn cá»™t\n",
    "#     for i, (sent, cnt) in enumerate(zip(sentiment_pd['sentiment'], sentiment_pd['count'])):\n",
    "#         ax1.text(i, cnt, f'{int(cnt):,}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "#     # 2. Pie chart\n",
    "#     pie_colors = [colors.get(s, '#9E9E9E') for s in sentiment_pd['sentiment']]\n",
    "    \n",
    "#     ax2.pie(sentiment_pd['percentage'], \n",
    "#             labels=sentiment_pd['sentiment'], \n",
    "#             autopct='%1.1f%%',\n",
    "#             colors=pie_colors,\n",
    "#             startangle=90,\n",
    "#             textprops={'fontsize': 11})\n",
    "#     ax2.set_title('PhÃ¢n Bá»‘ Sentiment - Pie Chart', fontsize=14, fontweight='bold')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(\"\\nâœ… ÄÃ£ táº¡o biá»ƒu Ä‘á»“ trá»±c quan!\")\n",
    "# else:\n",
    "#     print(\"âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107709f6",
   "metadata": {},
   "source": [
    "## 10. LÆ°u Káº¿t Quáº£ vÃ o Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9deb3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "# # Tá»± Ä‘á»™ng lÆ°u káº¿t quáº£ vÃ o báº£ng Gold layer\n",
    "# save_results = True  # Tá»± Ä‘á»™ng lÆ°u sau khi phÃ¢n tÃ­ch\n",
    "\n",
    "# if save_results and total_comments > 0:\n",
    "#     print(\"ðŸ’¾ Äang lÆ°u káº¿t quáº£ vÃ o báº£ng Gold...\")\n",
    "    \n",
    "#     # Táº¡o database gold náº¿u chÆ°a cÃ³\n",
    "#     spark.sql(\"CREATE DATABASE IF NOT EXISTS nessie.gold_result_model_multi_task\")\n",
    "    \n",
    "#     # Táº¡o báº£ng Comment_Sentiment náº¿u chÆ°a cÃ³\n",
    "#     spark.sql(\"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS nessie.gold_result_model_multi_task.Comment_Sentiment (\n",
    "#         commentID BIGINT,\n",
    "#         postID STRING,\n",
    "#         comment STRING,\n",
    "#         sentiment STRING,\n",
    "#         commentTime TIMESTAMP,\n",
    "#         commentLike INT,\n",
    "#         levelComment INT,\n",
    "#         numberOfReply INT,\n",
    "#         created_at TIMESTAMP,\n",
    "#         updated_at TIMESTAMP\n",
    "#     ) USING iceberg\n",
    "#     TBLPROPERTIES (\n",
    "#         'write.format.default' = 'parquet',\n",
    "#         'write.metadata.compression-codec' = 'gzip'\n",
    "#     )\n",
    "#     \"\"\")\n",
    "    \n",
    "#     print(\"âœ… ÄÃ£ táº¡o/kiá»ƒm tra báº£ng: nessie.gold_result_model_multi_task.Comment_Sentiment\")\n",
    "    \n",
    "#     # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u\n",
    "#     df_to_save = df_with_sentiment.select(\n",
    "#         col(\"postID\"),\n",
    "#         col(\"commentID\"),\n",
    "#         col(\"comment\"),\n",
    "#         col(\"sentiment\"),\n",
    "#         col(\"commentTime\"),\n",
    "#         col(\"commentLike\"),\n",
    "#         col(\"levelComment\"),\n",
    "#         col(\"numberOfReply\"),\n",
    "#         col(\"created_at\"),\n",
    "#         current_timestamp().alias(\"updated_at\")  # Cáº­p nháº­t thá»i gian xá»­ lÃ½\n",
    "#     )\n",
    "    \n",
    "#     # LÆ°u káº¿t quáº£ vÃ o báº£ng Gold\n",
    "#     print(f\"ðŸ“¤ Äang lÆ°u {total_comments:,} báº£n ghi vÃ o báº£ng Gold...\")\n",
    "    \n",
    "#     df_to_save.writeTo(\"nessie.gold_result_model_multi_task.Comment_Sentiment\") \\\n",
    "#         .using(\"iceberg\") \\\n",
    "#         .tableProperty(\"write.format.default\", \"parquet\") \\\n",
    "#         .tableProperty(\"write.metadata.compression-codec\", \"gzip\") \\\n",
    "#         .append()\n",
    "    \n",
    "#     print(\"âœ… ÄÃ£ lÆ°u káº¿t quáº£ sentiment vÃ o báº£ng: nessie.gold_result_model_multi_task.Comment_Sentiment\")\n",
    "    \n",
    "#     # Kiá»ƒm tra sá»‘ lÆ°á»£ng báº£n ghi Ä‘Ã£ lÆ°u\n",
    "#     saved_count = spark.sql(\"SELECT COUNT(*) as count FROM nessie.gold_result_model_multi_task.Comment_Sentiment\").collect()[0]['count']\n",
    "#     print(f\"ðŸ“Š Tá»•ng sá»‘ báº£n ghi trong báº£ng Gold: {saved_count:,}\")\n",
    "    \n",
    "# elif total_comments > 0:\n",
    "#     print(\"â„¹ï¸ Bá» qua viá»‡c lÆ°u káº¿t quáº£. Äáº·t save_results=True náº¿u muá»‘n lÆ°u.\")\n",
    "# else:\n",
    "#     print(\"âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb5e79",
   "metadata": {},
   "source": [
    "## 11. Kiá»ƒm Tra Dá»¯ Liá»‡u ÄÃ£ LÆ°u trong Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65d48934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if save_results and total_comments > 0:\n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(\"ðŸ” KIá»‚M TRA Dá»® LIá»†U TRONG GOLD LAYER\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     # Äá»c dá»¯ liá»‡u tá»« báº£ng Gold\n",
    "#     df_gold = spark.sql(\"SELECT * FROM nessie.gold_result_model_multi_task.Comment_Sentiment\")\n",
    "    \n",
    "#     print(\"\\nðŸ“Š Thá»‘ng kÃª tá»•ng quan:\")\n",
    "#     total_in_gold = df_gold.count()\n",
    "#     print(f\"   Tá»•ng sá»‘ báº£n ghi: {total_in_gold:,}\")\n",
    "    \n",
    "#     # PhÃ¢n bá»‘ sentiment trong Gold\n",
    "#     print(\"\\nðŸ“ˆ PhÃ¢n bá»‘ Sentiment trong Gold Layer:\")\n",
    "#     df_gold.groupBy(\"sentiment\").count().orderBy(\"count\", ascending=False).show()\n",
    "    \n",
    "#     # Hiá»ƒn thá»‹ máº«u dá»¯ liá»‡u\n",
    "#     print(\"\\nðŸ“ Máº«u dá»¯ liá»‡u tá»« Gold Layer (10 báº£n ghi má»›i nháº¥t):\")\n",
    "#     df_gold.select(\"postID\", \"commentID\", \"comment\", \"sentiment\", \"commentTime\", \"commentLike\", \"updated_at\") \\\n",
    "#         .orderBy(\"updated_at\", ascending=False) \\\n",
    "#         .show(10, truncate=50)\n",
    "    \n",
    "#     # Thá»‘ng kÃª tiáº¿n Ä‘á»™\n",
    "#     print(f\"\\nðŸ“Š Tiáº¿n Ä‘á»™ xá»­ lÃ½:\")\n",
    "#     print(f\"   - ÄÃ£ xá»­ lÃ½: {total_in_gold:,} comment\")\n",
    "#     print(f\"   - CÃ²n láº¡i: {max(0, total_silver_comments - total_in_gold):,} comment\")\n",
    "#     progress_pct = (total_in_gold / total_silver_comments * 100) if total_silver_comments > 0 else 0\n",
    "#     print(f\"   - Tiáº¿n Ä‘á»™: {progress_pct:.2f}%\")\n",
    "    \n",
    "#     print(\"\\nâœ… Kiá»ƒm tra hoÃ n táº¥t!\")\n",
    "# else:\n",
    "#     print(\"\\nâ„¹ï¸ Bá» qua kiá»ƒm tra do khÃ´ng lÆ°u dá»¯ liá»‡u.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47fb8b5",
   "metadata": {},
   "source": [
    "## 12. Tá»•ng Káº¿t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec3dffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"ðŸ“‹ TÃ“M Táº®T Káº¾T QUáº¢ PHÃ‚N TÃCH SENTIMENT\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# if total_comments > 0:\n",
    "#     print(f\"\\nðŸ“¦ Batch Processing:\")\n",
    "#     print(f\"   - Tá»•ng comment trong Silver: {total_silver_comments:,}\")\n",
    "#     print(f\"   - Batch hiá»‡n táº¡i: {total_comments:,} comment\")\n",
    "#     print(f\"   - KÃ­ch thÆ°á»›c batch: {BATCH_SIZE:,} comment/batch\")\n",
    "    \n",
    "#     print(f\"\\nðŸ“Š Káº¿t quáº£ phÃ¢n tÃ­ch batch nÃ y:\")\n",
    "#     print(f\"   ðŸŸ¬ Comment TÃCH Cá»°C (POS): {pos_count:,} ({pos_pct:.2f}%)\")\n",
    "#     print(f\"   ðŸ”´ Comment TIÃŠU Cá»°C (NEG): {neg_count:,} ({neg_pct:.2f}%)\")\n",
    "#     print(f\"   âšª Comment TRUNG Láº¬P (NEU): {neu_count:,} ({neu_pct:.2f}%)\")\n",
    "    \n",
    "#     # ÄÃ¡nh giÃ¡ tá»•ng quan\n",
    "#     print(\"\\nðŸ“ˆ ÄÃ¡nh giÃ¡ batch hiá»‡n táº¡i:\")\n",
    "#     if pos_pct > 50:\n",
    "#         print(\"   âœ… TÃ¢m lÃ½ cá»™ng Ä‘á»“ng chá»§ yáº¿u TÃCH Cá»°C\")\n",
    "#     elif neg_pct > 50:\n",
    "#         print(\"   âš ï¸ TÃ¢m lÃ½ cá»™ng Ä‘á»“ng chá»§ yáº¿u TIÃŠU Cá»°C\")\n",
    "#     else:\n",
    "#         print(\"   â„¹ï¸ TÃ¢m lÃ½ cá»™ng Ä‘á»“ng TRUNG Láº¬P hoáº·c TRá»˜N LáºªN\")\n",
    "    \n",
    "#     # TÃ­nh toÃ¡n sá»‘ comment cÃ²n láº¡i\n",
    "#     try:\n",
    "#         processed_total = existing_comment_ids + total_comments\n",
    "#     except:\n",
    "#         processed_total = total_comments\n",
    "    \n",
    "#     remaining = total_silver_comments - processed_total\n",
    "    \n",
    "#     if remaining > 0:\n",
    "#         print(f\"\\nðŸ”„ Tiáº¿n Ä‘á»™:\")\n",
    "#         print(f\"   - ÄÃ£ xá»­ lÃ½: {processed_total:,} comment\")\n",
    "#         print(f\"   - CÃ²n láº¡i: {remaining:,} comment\")\n",
    "#         progress_pct = (processed_total / total_silver_comments * 100) if total_silver_comments > 0 else 0\n",
    "#         print(f\"   - HoÃ n thÃ nh: {progress_pct:.2f}%\")\n",
    "#         print(f\"\\nðŸ’¡ Cháº¡y láº¡i notebook Ä‘á»ƒ xá»­ lÃ½ batch tiáº¿p theo\")\n",
    "#     else:\n",
    "#         print(\"\\nâœ… ÄÃ£ xá»­ lÃ½ háº¿t táº¥t cáº£ comment má»›i!\")\n",
    "        \n",
    "# else:\n",
    "#     print(\"\\nâœ… Táº¥t cáº£ comment Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½!\")\n",
    "#     if total_silver_comments > 0:\n",
    "#         print(f\"ðŸ“Š Tá»•ng sá»‘ comment trong Silver: {total_silver_comments:,}\")\n",
    "#     print(\"ðŸ’¡ KhÃ´ng cÃ³ comment má»›i cáº§n phÃ¢n tÃ­ch.\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"âœ… HoÃ n thÃ nh phÃ¢n tÃ­ch!\")\n",
    "# print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b81f9",
   "metadata": {},
   "source": [
    "## 13. Dá»«ng Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddad9bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›‘ Spark Session Ä‘Ã£ Ä‘Æ°á»£c dá»«ng!\n",
      "âœ… HoÃ n táº¥t!\n"
     ]
    }
   ],
   "source": [
    "# Giáº£i phÃ³ng cache\n",
    "if total_comments > 0:\n",
    "    df_with_sentiment.unpersist()\n",
    "\n",
    "# Dá»«ng Spark Session\n",
    "spark.stop()\n",
    "print(\"ðŸ›‘ Spark Session Ä‘Ã£ Ä‘Æ°á»£c dá»«ng!\")\n",
    "print(\"âœ… HoÃ n táº¥t!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b9f9a-0657-48bc-a441-24aba93a9166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
