{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d139c45d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries và Khởi tạo Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59904f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/08 07:29:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session da duoc khoi tao voi Nessie catalog!\n",
      "Spark Master: spark://spark-master:7077\n",
      "Application ID: app-20251208072944-0002\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, udf, current_timestamp\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "from transformers import AutoTokenizer\n",
    "from vncorenlp import VnCoreNLP\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set AWS environment variables for MinIO\n",
    "os.environ['AWS_REGION'] = 'us-east-1'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'admin123'\n",
    "\n",
    "# Khởi tạo Spark Session với Iceberg và Nessie catalog\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Apply_Model_Multi_Task\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.executor.memory\", \"1536m\")  # 1.5GB - an toàn với worker 2GB\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    .config(\"spark.network.timeout\", \"600s\")\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\")\n",
    "    .config(\"spark.storage.blockManagerSlaveTimeoutMs\", \"600000\")\n",
    "    .config(\"spark.rpc.askTimeout\", \"600s\")\n",
    "    # ===== Iceberg Catalog qua Nessie =====\n",
    "    .config(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.uri\", \"http://nessie:19120/api/v2\")\n",
    "    .config(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "    .config(\"spark.sql.catalog.nessie.warehouse\", \"s3a://silver/\")\n",
    "    .config(\"spark.sql.catalog.nessie.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    # ===== Cấu hình MinIO (S3-compatible) =====\n",
    "    .config(\"spark.sql.catalog.nessie.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.access-key-id\", \"admin\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.secret-access-key\", \"admin123\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.path-style-access\", \"true\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.region\", \"us-east-1\")\n",
    "    # ===== Spark + Hadoop S3 connector =====\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin123\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .config(\"spark.hadoop.fs.s3a.region\", \"us-east-1\")\n",
    "    # Propagate environment variables to executors\n",
    "    .config(\"spark.executorEnv.AWS_REGION\", \"us-east-1\")\n",
    "    .config(\"spark.executorEnv.AWS_ACCESS_KEY_ID\", \"admin\")\n",
    "    .config(\"spark.executorEnv.AWS_SECRET_ACCESS_KEY\", \"admin123\")\n",
    "    # ===== Sử dụng JAR files local =====\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/hadoop-aws-3.3.4.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"Spark Session da duoc khoi tao voi Nessie catalog!\")\n",
    "print(f\"Spark Master: {spark.sparkContext.master}\")\n",
    "print(f\"Application ID: {spark.sparkContext.applicationId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc96d5",
   "metadata": {},
   "source": [
    "## 2. Đọc Dữ Liệu từ Bảng Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5f4f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số articles: 3295\n",
      "✓ Đã cache df_articles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu từ bảng article\n",
    "df_articles = spark.table(\"nessie.silver_tables.article\")\n",
    "print(f\"Tổng số articles: {df_articles.count()}\")\n",
    "\n",
    "# Cache để tránh đọc lại nhiều lần\n",
    "df_articles.cache()\n",
    "print(\"✓ Đã cache df_articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed41567",
   "metadata": {},
   "source": [
    "## 3. Load Model và Cấu Hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6483a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER labels: 25\n",
      "Topic labels: 10\n",
      "Intent labels: 7\n",
      "\n",
      "=== Kiểm tra VnCoreNLP JAR file ===\n",
      "Tìm thấy: /opt/spark-apps/VnCoreNLP-1.2/VnCoreNLP-1.2.jar\n",
      "\n",
      "Đang khởi tạo VnCoreNLP...\n",
      "VnCoreNLP loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn model local (đã mount vào container)\n",
    "local_model_path = '/opt/spark-apps/phobert_multitask_final'\n",
    "\n",
    "# Đọc JSON files từ local filesystem\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open(f'{local_model_path}/model_config.json', 'r') as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "with open(f'{local_model_path}/label_mappings.json', 'r') as f:\n",
    "    label_mappings = json.load(f)\n",
    "\n",
    "print(f\"NER labels: {model_config['num_ner_labels']}\")\n",
    "print(f\"Topic labels: {model_config['num_topic_labels']}\")\n",
    "print(f\"Intent labels: {model_config['num_intent_labels']}\")\n",
    "\n",
    "# Kiểm tra VnCoreNLP JAR file tại path đã mount\n",
    "print(\"\\n=== Kiểm tra VnCoreNLP JAR file ===\")\n",
    "vncorenlp_path = '/opt/spark-apps/VnCoreNLP-1.2/VnCoreNLP-1.2.jar'\n",
    "\n",
    "if os.path.exists(vncorenlp_path):\n",
    "    print(f\"Tìm thấy: {vncorenlp_path}\")\n",
    "    print(f\"\\nĐang khởi tạo VnCoreNLP...\")\n",
    "    try:\n",
    "        annotator = VnCoreNLP(vncorenlp_path, annotators=\"wseg\", max_heap_size='-Xmx2g')\n",
    "        print(\"VnCoreNLP loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khởi tạo VnCoreNLP: {e}\")\n",
    "        annotator = None\n",
    "else:\n",
    "    print(f\"Không tìm thấy VnCoreNLP JAR tại: {vncorenlp_path}\")\n",
    "    print(\"Kiểm tra lại volume mount trong docker-compose.yaml\")\n",
    "    annotator = None\n",
    "\n",
    "# Lưu model_path cho các cell sau\n",
    "model_path = local_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3bb58b",
   "metadata": {},
   "source": [
    "## 4. Định Nghĩa Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f8a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class defined!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import RobertaModel\n",
    "\n",
    "\n",
    "class MultiTaskPhoBERT_WithFusion(nn.Module):\n",
    "    \"\"\"Multi-Task PhoBERT với Feature Fusion\"\"\"\n",
    "    def __init__(self, phobert_path, num_ner_labels, num_topic_labels, num_intent_labels, dropout=0.2):\n",
    "        super(MultiTaskPhoBERT_WithFusion, self).__init__()\n",
    "        \n",
    "        self.phobert = RobertaModel.from_pretrained(phobert_path)\n",
    "        self.phobert.config.hidden_dropout_prob = 0.25\n",
    "        self.phobert.config.attention_probs_dropout_prob = 0.25\n",
    "        self.hidden_size = self.phobert.config.hidden_size\n",
    "        self.num_ner_labels = num_ner_labels\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dropout_heavy = nn.Dropout(dropout * 1.5)\n",
    "        \n",
    "        # NER head\n",
    "        self.ner_hidden = nn.Linear(self.hidden_size, self.hidden_size // 2)\n",
    "        self.ner_norm = nn.LayerNorm(self.hidden_size // 2)\n",
    "        self.ner_classifier = nn.Linear(self.hidden_size // 2, num_ner_labels)\n",
    "        \n",
    "        # Intent head\n",
    "        self.intent_hidden = nn.Linear(self.hidden_size, self.hidden_size // 2)\n",
    "        self.intent_norm = nn.LayerNorm(self.hidden_size // 2)\n",
    "        self.intent_classifier = nn.Linear(self.hidden_size // 2, num_intent_labels)\n",
    "        \n",
    "        # Topic Fusion Head\n",
    "        fusion_input_size = self.hidden_size + num_ner_labels\n",
    "        self.topic_input_proj = nn.Linear(fusion_input_size, self.hidden_size)\n",
    "        \n",
    "        self.topic_layer1 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        self.topic_layer2 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        self.topic_classifier = nn.Linear(self.hidden_size, num_topic_labels)\n",
    "        \n",
    "        # NER attention mechanism\n",
    "        self.ner_attention = nn.Sequential(\n",
    "            nn.Linear(num_ner_labels, num_ner_labels // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_ner_labels // 2, num_ner_labels),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        # Cross-Attention\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=self.hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.cross_attn_norm = nn.LayerNorm(self.hidden_size)\n",
    "        \n",
    "        # Auxiliary head\n",
    "        self.aux_topic_classifier = nn.Sequential(\n",
    "            nn.Linear(num_ner_labels, num_ner_labels // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_ner_labels // 2, num_topic_labels)\n",
    "        )\n",
    "    \n",
    "    def extract_ner_features(self, ner_logits, attention_mask):\n",
    "        \"\"\"Trích xuất NER features với MAX + AVG pooling\"\"\"\n",
    "        ner_probs = F.softmax(ner_logits, dim=-1)\n",
    "        \n",
    "        attention_mask_expanded = attention_mask.unsqueeze(-1).expand_as(ner_probs)\n",
    "        ner_probs_masked = ner_probs * attention_mask_expanded\n",
    "        \n",
    "        max_features, _ = ner_probs_masked.max(dim=1)\n",
    "        \n",
    "        seq_lengths = attention_mask.sum(dim=1, keepdim=True).clamp(min=1)\n",
    "        avg_features = ner_probs_masked.sum(dim=1) / seq_lengths\n",
    "        \n",
    "        ner_features = 0.5 * max_features + 0.5 * avg_features\n",
    "        \n",
    "        attention_weights = self.ner_attention(ner_features)\n",
    "        ner_features_weighted = ner_features * attention_weights\n",
    "        \n",
    "        return ner_features_weighted\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, ner_labels=None, topic_labels=None, intent_labels=None):\n",
    "        outputs = self.phobert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        cls_output = sequence_output[:, 0, :]\n",
    "        \n",
    "        cls_expanded = cls_output.unsqueeze(1)\n",
    "        attn_output, _ = self.cross_attention(\n",
    "            query=cls_expanded,\n",
    "            key=sequence_output,\n",
    "            value=sequence_output,\n",
    "            key_padding_mask=(attention_mask == 0) if attention_mask is not None else None\n",
    "        )\n",
    "        cls_output = self.cross_attn_norm(cls_output + attn_output.squeeze(1))\n",
    "        cls_output_dropped = self.dropout_heavy(cls_output)\n",
    "        \n",
    "        # NER predictions\n",
    "        ner_hidden = self.ner_hidden(sequence_output)\n",
    "        ner_hidden = self.ner_norm(ner_hidden)\n",
    "        ner_hidden = F.gelu(ner_hidden)\n",
    "        ner_hidden = self.dropout(ner_hidden)\n",
    "        ner_logits = self.ner_classifier(ner_hidden)\n",
    "        \n",
    "        ner_features = self.extract_ner_features(ner_logits, attention_mask)\n",
    "        \n",
    "        # Topic prediction\n",
    "        topic_input = torch.cat([cls_output_dropped, ner_features], dim=-1)\n",
    "        topic_hidden = self.topic_input_proj(topic_input)\n",
    "        topic_hidden = topic_hidden + self.topic_layer1(topic_hidden)\n",
    "        topic_hidden = topic_hidden + self.topic_layer2(topic_hidden)\n",
    "        topic_logits = self.topic_classifier(topic_hidden)\n",
    "        \n",
    "        # Intent prediction\n",
    "        intent_hidden = self.intent_hidden(cls_output_dropped)\n",
    "        intent_hidden = self.intent_norm(intent_hidden)\n",
    "        intent_hidden = F.gelu(intent_hidden)\n",
    "        intent_hidden = self.dropout(intent_hidden)\n",
    "        intent_logits = self.intent_classifier(intent_hidden)\n",
    "        \n",
    "        return {\n",
    "            'loss': None,\n",
    "            'ner_logits': ner_logits,\n",
    "            'topic_logits': topic_logits,\n",
    "            'intent_logits': intent_logits\n",
    "        }\n",
    "\n",
    "print(\"Model class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed000e",
   "metadata": {},
   "source": [
    "## 5. Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3097df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /opt/spark-apps/phobert_multitask_final\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3bab49a17b472680a8588abf283a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743e769d9382489eb5f4fb577fa28871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on cpu!\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn model local (đã mount vào container)\n",
    "local_model_path = '/opt/spark-apps/phobert_multitask_final'\n",
    "\n",
    "print(f\"Loading model from: {local_model_path}\")\n",
    "\n",
    "# Load tokenizer và model\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "model = MultiTaskPhoBERT_WithFusion(\n",
    "    phobert_path=model_config['phobert_base'],\n",
    "    num_ner_labels=model_config['num_ner_labels'],\n",
    "    num_topic_labels=model_config['num_topic_labels'],\n",
    "    num_intent_labels=model_config['num_intent_labels'],\n",
    "    dropout=model_config['dropout']\n",
    ")\n",
    "\n",
    "# Load trọng số đã train\n",
    "state_dict = torch.load(f'{local_model_path}/pytorch_model.bin', map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Chuyển model sang GPU nếu có\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded successfully on {device}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a120284",
   "metadata": {},
   "source": [
    "## 6. Định Nghĩa Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8209b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction functions defined!\n"
     ]
    }
   ],
   "source": [
    "def normalize_text_with_underscore(text, annotator):\n",
    "    \"\"\"Chuẩn hóa văn bản tiếng Việt bằng VnCoreNLP\"\"\"\n",
    "    try:\n",
    "        sentences = annotator.tokenize(text)\n",
    "        \n",
    "        normalized_sentences = []\n",
    "        for sentence in sentences:\n",
    "            words = []\n",
    "            for word in sentence:\n",
    "                if isinstance(word, list):\n",
    "                    words.append('_'.join(word))\n",
    "                else:\n",
    "                    words.append(word)\n",
    "            normalized_sentences.append(' '.join(words))\n",
    "        \n",
    "        normalized_text = ' '.join(normalized_sentences)\n",
    "        return normalized_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error normalizing text: {e}\")\n",
    "        return text\n",
    "\n",
    "\n",
    "def predict_labels(text, model, tokenizer, label_mappings, device, annotator, max_length=256):\n",
    "    \"\"\"Dự đoán NER, Topic, Intent cho văn bản đầu vào\"\"\"\n",
    "    if not text or text.strip() == '':\n",
    "        return {\n",
    "            'normalized_text': '',\n",
    "            'ner_labels': 'O',\n",
    "            'topic_label': 'None',\n",
    "            'intent_label': 'Unknown'\n",
    "        }\n",
    "    \n",
    "    # Chuẩn hóa text bằng VnCoreNLP\n",
    "    normalized_text = normalize_text_with_underscore(text, annotator)\n",
    "    normalized_tokens = normalized_text.split()\n",
    "    num_tokens = len(normalized_tokens)\n",
    "    \n",
    "    # Tokenize cho PhoBERT\n",
    "    inputs = tokenizer(\n",
    "        normalized_text,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    if 'token_type_ids' in inputs:\n",
    "        inputs.pop('token_type_ids')\n",
    "    \n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Dự đoán\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    ner_logits = outputs['ner_logits']\n",
    "    topic_logits = outputs['topic_logits']\n",
    "    intent_logits = outputs['intent_logits']\n",
    "    \n",
    "    # NER predictions\n",
    "    ner_preds = torch.argmax(ner_logits, dim=-1)[0]\n",
    "    phobert_tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    # Align labels với VnCoreNLP tokens\n",
    "    ner_labels = []\n",
    "    token_idx = 0\n",
    "    \n",
    "    for word in normalized_tokens:\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        \n",
    "        while token_idx < len(phobert_tokens) and phobert_tokens[token_idx] == '<s>':\n",
    "            token_idx += 1\n",
    "        \n",
    "        if token_idx < len(phobert_tokens) and phobert_tokens[token_idx] not in ['</s>', '<pad>']:\n",
    "            label = label_mappings['ner_id2label'][str(ner_preds[token_idx].item())]\n",
    "            ner_labels.append(label)\n",
    "            token_idx += len(word_tokens)\n",
    "        else:\n",
    "            ner_labels.append('O')\n",
    "            break\n",
    "    \n",
    "    # Topic predictions (multi-label, threshold=0.5)\n",
    "    topic_probs = torch.sigmoid(topic_logits)[0]\n",
    "    topic_preds = (topic_probs > 0.5).nonzero(as_tuple=True)[0].cpu().tolist()\n",
    "    \n",
    "    if len(topic_preds) > 0:\n",
    "        topic_labels = [label_mappings['topic_id2label'][str(idx)] for idx in topic_preds]\n",
    "        topic_label = '|'.join(topic_labels)\n",
    "    else:\n",
    "        topic_label = 'None'\n",
    "    \n",
    "    # Intent prediction (single-label)\n",
    "    intent_pred = torch.argmax(intent_logits, dim=-1).item()\n",
    "    intent_label = label_mappings['intent_id2label'][str(intent_pred)]\n",
    "    \n",
    "    return {\n",
    "        'normalized_text': normalized_text,\n",
    "        'ner_labels': ' '.join(ner_labels),\n",
    "        'topic_label': topic_label,\n",
    "        'intent_label': intent_label\n",
    "    }\n",
    "\n",
    "print(\"Prediction functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24a20d",
   "metadata": {},
   "source": [
    "## 7. Apply Model trên Toàn Bộ Dữ Liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272a9733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 0 articles đã được xử lý trước đó\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xử lý toàn bộ 3295 articles\n",
      "\n",
      "=== Collecting data to process ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã collect 3295 articles về driver\n",
      "✓ Đã giải phóng df_articles_new\n",
      "\n",
      "=== Processing articles with model ===\n",
      "[07:31:12] Processed 0/3295 | Elapsed: 0.0s | ETA: 0.0s\n",
      "[07:31:15] Processed 10/3295 | Elapsed: 2.7s | ETA: 818.8s\n",
      "[07:31:17] Processed 20/3295 | Elapsed: 5.1s | ETA: 789.7s\n",
      "[07:31:20] Processed 30/3295 | Elapsed: 7.9s | ETA: 835.4s\n",
      "[07:31:23] Processed 40/3295 | Elapsed: 10.4s | ETA: 825.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 50\n",
      "[07:33:26] Processed 50/3295 | Elapsed: 134.0s | ETA: 8525.5s\n",
      "[07:33:29] Processed 60/3295 | Elapsed: 136.2s | ETA: 7225.1s\n",
      "[07:33:31] Processed 70/3295 | Elapsed: 138.3s | ETA: 6280.9s\n",
      "[07:33:33] Processed 80/3295 | Elapsed: 140.4s | ETA: 5573.5s\n",
      "[07:33:35] Processed 90/3295 | Elapsed: 142.4s | ETA: 5016.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 100\n",
      "[07:33:38] Processed 100/3295 | Elapsed: 146.1s | ETA: 4621.9s\n",
      "[07:33:41] Processed 110/3295 | Elapsed: 148.2s | ETA: 4251.7s\n",
      "[07:33:43] Processed 120/3295 | Elapsed: 150.2s | ETA: 3940.7s\n",
      "[07:33:45] Processed 130/3295 | Elapsed: 152.2s | ETA: 3678.3s\n",
      "[07:33:47] Processed 140/3295 | Elapsed: 154.2s | ETA: 3450.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 150\n",
      "[07:33:50] Processed 150/3295 | Elapsed: 157.7s | ETA: 3285.0s\n",
      "[07:33:52] Processed 160/3295 | Elapsed: 159.7s | ETA: 3110.0s\n",
      "[07:33:54] Processed 170/3295 | Elapsed: 161.7s | ETA: 2955.0s\n",
      "[07:33:56] Processed 180/3295 | Elapsed: 163.7s | ETA: 2817.6s\n",
      "[07:33:58] Processed 190/3295 | Elapsed: 165.8s | ETA: 2695.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 200\n",
      "[07:34:02] Processed 200/3295 | Elapsed: 169.3s | ETA: 2606.2s\n",
      "[07:34:04] Processed 210/3295 | Elapsed: 171.2s | ETA: 2503.6s\n",
      "[07:34:06] Processed 220/3295 | Elapsed: 173.2s | ETA: 2410.5s\n",
      "[07:34:08] Processed 230/3295 | Elapsed: 175.2s | ETA: 2325.3s\n",
      "[07:34:10] Processed 240/3295 | Elapsed: 177.3s | ETA: 2247.5s\n",
      "✓ Saved batch: 50 records | Total processed: 250\n",
      "[07:34:13] Processed 250/3295 | Elapsed: 180.4s | ETA: 2189.0s\n",
      "[07:34:15] Processed 260/3295 | Elapsed: 182.5s | ETA: 2121.7s\n",
      "[07:34:17] Processed 270/3295 | Elapsed: 184.4s | ETA: 2058.6s\n",
      "[07:34:19] Processed 280/3295 | Elapsed: 186.5s | ETA: 2000.6s\n",
      "[07:34:21] Processed 290/3295 | Elapsed: 188.5s | ETA: 1947.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 300\n",
      "[07:34:24] Processed 300/3295 | Elapsed: 191.9s | ETA: 1909.2s\n",
      "[07:34:26] Processed 310/3295 | Elapsed: 193.9s | ETA: 1860.9s\n",
      "[07:34:29] Processed 320/3295 | Elapsed: 196.2s | ETA: 1818.6s\n",
      "[07:34:31] Processed 330/3295 | Elapsed: 198.4s | ETA: 1777.2s\n",
      "[07:34:33] Processed 340/3295 | Elapsed: 200.5s | ETA: 1737.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 350\n",
      "[07:34:36] Processed 350/3295 | Elapsed: 203.9s | ETA: 1711.1s\n",
      "[07:34:39] Processed 360/3295 | Elapsed: 206.2s | ETA: 1676.4s\n",
      "[07:34:41] Processed 370/3295 | Elapsed: 208.4s | ETA: 1643.3s\n",
      "[07:34:43] Processed 380/3295 | Elapsed: 210.6s | ETA: 1611.0s\n",
      "[07:34:45] Processed 390/3295 | Elapsed: 212.7s | ETA: 1579.9s\n",
      "✓ Saved batch: 50 records | Total processed: 400\n",
      "[07:34:48] Processed 400/3295 | Elapsed: 215.7s | ETA: 1557.5s\n",
      "[07:34:50] Processed 410/3295 | Elapsed: 217.8s | ETA: 1529.1s\n",
      "[07:34:52] Processed 420/3295 | Elapsed: 219.8s | ETA: 1501.3s\n",
      "[07:34:54] Processed 430/3295 | Elapsed: 221.9s | ETA: 1475.0s\n",
      "[07:34:56] Processed 440/3295 | Elapsed: 223.9s | ETA: 1449.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 450\n",
      "[07:35:00] Processed 450/3295 | Elapsed: 227.4s | ETA: 1434.5s\n",
      "[07:35:02] Processed 460/3295 | Elapsed: 229.4s | ETA: 1411.0s\n",
      "[07:35:04] Processed 470/3295 | Elapsed: 231.4s | ETA: 1388.0s\n",
      "[07:35:06] Processed 480/3295 | Elapsed: 233.5s | ETA: 1366.3s\n",
      "[07:35:08] Processed 490/3295 | Elapsed: 235.5s | ETA: 1345.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 500\n",
      "[07:35:11] Processed 500/3295 | Elapsed: 238.9s | ETA: 1333.0s\n",
      "[07:35:13] Processed 510/3295 | Elapsed: 240.9s | ETA: 1313.1s\n",
      "[07:35:15] Processed 520/3295 | Elapsed: 242.9s | ETA: 1293.9s\n",
      "[07:35:17] Processed 530/3295 | Elapsed: 245.0s | ETA: 1275.7s\n",
      "[07:35:19] Processed 540/3295 | Elapsed: 247.0s | ETA: 1258.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 550\n",
      "[07:35:23] Processed 550/3295 | Elapsed: 250.3s | ETA: 1247.1s\n",
      "[07:35:25] Processed 560/3295 | Elapsed: 252.3s | ETA: 1230.2s\n",
      "[07:35:27] Processed 570/3295 | Elapsed: 254.3s | ETA: 1213.7s\n",
      "[07:35:29] Processed 580/3295 | Elapsed: 256.4s | ETA: 1198.3s\n",
      "[07:35:31] Processed 590/3295 | Elapsed: 258.6s | ETA: 1183.5s\n",
      "✓ Saved batch: 50 records | Total processed: 600\n",
      "[07:35:34] Processed 600/3295 | Elapsed: 261.4s | ETA: 1172.2s\n",
      "[07:35:36] Processed 610/3295 | Elapsed: 263.4s | ETA: 1157.7s\n",
      "[07:35:38] Processed 620/3295 | Elapsed: 265.5s | ETA: 1143.6s\n",
      "[07:35:40] Processed 630/3295 | Elapsed: 267.5s | ETA: 1129.9s\n",
      "[07:35:42] Processed 640/3295 | Elapsed: 269.6s | ETA: 1116.7s\n",
      "✓ Saved batch: 50 records | Total processed: 650\n",
      "[07:35:45] Processed 650/3295 | Elapsed: 272.8s | ETA: 1108.4s\n",
      "[07:35:47] Processed 660/3295 | Elapsed: 275.1s | ETA: 1096.5s\n",
      "[07:35:50] Processed 670/3295 | Elapsed: 277.2s | ETA: 1084.3s\n",
      "[07:35:52] Processed 680/3295 | Elapsed: 279.3s | ETA: 1072.4s\n",
      "[07:35:54] Processed 690/3295 | Elapsed: 281.3s | ETA: 1060.5s\n",
      "✓ Saved batch: 50 records | Total processed: 700\n",
      "[07:35:57] Processed 700/3295 | Elapsed: 284.3s | ETA: 1052.6s\n",
      "[07:35:59] Processed 710/3295 | Elapsed: 286.4s | ETA: 1041.2s\n",
      "[07:36:01] Processed 720/3295 | Elapsed: 288.5s | ETA: 1030.2s\n",
      "[07:36:03] Processed 730/3295 | Elapsed: 290.5s | ETA: 1019.3s\n",
      "[07:36:05] Processed 740/3295 | Elapsed: 292.5s | ETA: 1008.7s\n",
      "✓ Saved batch: 50 records | Total processed: 750\n",
      "[07:36:08] Processed 750/3295 | Elapsed: 295.5s | ETA: 1001.4s\n",
      "[07:36:10] Processed 760/3295 | Elapsed: 297.6s | ETA: 991.3s\n",
      "[07:36:12] Processed 770/3295 | Elapsed: 299.6s | ETA: 981.2s\n",
      "[07:36:14] Processed 780/3295 | Elapsed: 301.6s | ETA: 971.2s\n",
      "[07:36:16] Processed 790/3295 | Elapsed: 303.6s | ETA: 961.5s\n",
      "✓ Saved batch: 50 records | Total processed: 800\n",
      "[07:36:19] Processed 800/3295 | Elapsed: 306.6s | ETA: 955.0s\n",
      "[07:36:21] Processed 810/3295 | Elapsed: 308.7s | ETA: 945.8s\n",
      "[07:36:23] Processed 820/3295 | Elapsed: 310.7s | ETA: 936.7s\n",
      "[07:36:25] Processed 830/3295 | Elapsed: 312.8s | ETA: 927.8s\n",
      "[07:36:27] Processed 840/3295 | Elapsed: 315.0s | ETA: 919.5s\n",
      "✓ Saved batch: 50 records | Total processed: 850\n",
      "[07:36:31] Processed 850/3295 | Elapsed: 318.2s | ETA: 914.2s\n",
      "[07:36:33] Processed 860/3295 | Elapsed: 320.4s | ETA: 906.0s\n",
      "[07:36:35] Processed 870/3295 | Elapsed: 322.4s | ETA: 897.7s\n",
      "[07:36:37] Processed 880/3295 | Elapsed: 324.5s | ETA: 889.5s\n",
      "[07:36:39] Processed 890/3295 | Elapsed: 326.6s | ETA: 881.5s\n",
      "✓ Saved batch: 50 records | Total processed: 900\n",
      "[07:36:42] Processed 900/3295 | Elapsed: 329.5s | ETA: 875.8s\n",
      "[07:36:44] Processed 910/3295 | Elapsed: 331.5s | ETA: 867.9s\n",
      "[07:36:46] Processed 920/3295 | Elapsed: 333.6s | ETA: 860.3s\n",
      "[07:36:48] Processed 930/3295 | Elapsed: 335.7s | ETA: 852.7s\n",
      "[07:36:50] Processed 940/3295 | Elapsed: 338.0s | ETA: 845.8s\n",
      "✓ Saved batch: 50 records | Total processed: 950\n",
      "[07:36:53] Processed 950/3295 | Elapsed: 341.1s | ETA: 841.0s\n",
      "[07:36:55] Processed 960/3295 | Elapsed: 343.1s | ETA: 833.6s\n",
      "[07:36:58] Processed 970/3295 | Elapsed: 345.1s | ETA: 826.4s\n",
      "[07:37:00] Processed 980/3295 | Elapsed: 347.3s | ETA: 819.5s\n",
      "[07:37:02] Processed 990/3295 | Elapsed: 349.3s | ETA: 812.4s\n",
      "✓ Saved batch: 50 records | Total processed: 1000\n",
      "[07:37:04] Processed 1000/3295 | Elapsed: 352.0s | ETA: 807.1s\n",
      "[07:37:06] Processed 1010/3295 | Elapsed: 354.0s | ETA: 800.2s\n",
      "[07:37:08] Processed 1020/3295 | Elapsed: 356.1s | ETA: 793.4s\n",
      "[07:37:11] Processed 1030/3295 | Elapsed: 358.1s | ETA: 786.7s\n",
      "[07:37:12] Processed 1040/3295 | Elapsed: 360.1s | ETA: 780.0s\n",
      "✓ Saved batch: 50 records | Total processed: 1050\n",
      "[07:37:15] Processed 1050/3295 | Elapsed: 362.9s | ETA: 775.2s\n",
      "[07:37:17] Processed 1060/3295 | Elapsed: 365.0s | ETA: 768.9s\n",
      "[07:37:20] Processed 1070/3295 | Elapsed: 367.1s | ETA: 762.7s\n",
      "[07:37:22] Processed 1080/3295 | Elapsed: 369.4s | ETA: 756.8s\n",
      "[07:37:24] Processed 1090/3295 | Elapsed: 371.7s | ETA: 751.2s\n",
      "✓ Saved batch: 50 records | Total processed: 1100\n",
      "[07:37:27] Processed 1100/3295 | Elapsed: 374.7s | ETA: 747.1s\n",
      "[07:37:29] Processed 1110/3295 | Elapsed: 376.9s | ETA: 741.2s\n",
      "[07:37:31] Processed 1120/3295 | Elapsed: 379.0s | ETA: 735.4s\n",
      "[07:37:34] Processed 1130/3295 | Elapsed: 381.1s | ETA: 729.6s\n",
      "[07:37:35] Processed 1140/3295 | Elapsed: 383.1s | ETA: 723.6s\n",
      "✓ Saved batch: 50 records | Total processed: 1150\n",
      "[07:37:38] Processed 1150/3295 | Elapsed: 386.0s | ETA: 719.3s\n",
      "[07:37:40] Processed 1160/3295 | Elapsed: 388.1s | ETA: 713.6s\n",
      "[07:37:43] Processed 1170/3295 | Elapsed: 390.1s | ETA: 707.9s\n",
      "[07:37:45] Processed 1180/3295 | Elapsed: 392.1s | ETA: 702.3s\n",
      "[07:37:47] Processed 1190/3295 | Elapsed: 394.2s | ETA: 696.7s\n",
      "✓ Saved batch: 50 records | Total processed: 1200\n",
      "[07:37:50] Processed 1200/3295 | Elapsed: 397.4s | ETA: 693.1s\n",
      "[07:37:52] Processed 1210/3295 | Elapsed: 399.4s | ETA: 687.6s\n",
      "[07:37:54] Processed 1220/3295 | Elapsed: 401.4s | ETA: 682.1s\n",
      "[07:37:56] Processed 1230/3295 | Elapsed: 403.5s | ETA: 676.8s\n",
      "[07:37:58] Processed 1240/3295 | Elapsed: 405.6s | ETA: 671.6s\n",
      "✓ Saved batch: 50 records | Total processed: 1250\n",
      "[07:38:01] Processed 1250/3295 | Elapsed: 408.8s | ETA: 668.2s\n",
      "[07:38:03] Processed 1260/3295 | Elapsed: 410.9s | ETA: 663.1s\n",
      "[07:38:05] Processed 1270/3295 | Elapsed: 413.0s | ETA: 658.0s\n",
      "[07:38:07] Processed 1280/3295 | Elapsed: 415.0s | ETA: 652.9s\n",
      "[07:38:10] Processed 1290/3295 | Elapsed: 417.1s | ETA: 647.8s\n",
      "✓ Saved batch: 50 records | Total processed: 1300\n",
      "[07:38:12] Processed 1300/3295 | Elapsed: 420.0s | ETA: 644.0s\n",
      "[07:38:14] Processed 1310/3295 | Elapsed: 422.0s | ETA: 639.0s\n",
      "[07:38:16] Processed 1320/3295 | Elapsed: 424.0s | ETA: 634.0s\n",
      "[07:38:18] Processed 1330/3295 | Elapsed: 426.1s | ETA: 629.1s\n",
      "[07:38:21] Processed 1340/3295 | Elapsed: 428.2s | ETA: 624.2s\n",
      "✓ Saved batch: 50 records | Total processed: 1350\n",
      "[07:38:24] Processed 1350/3295 | Elapsed: 431.2s | ETA: 620.8s\n",
      "[07:38:26] Processed 1360/3295 | Elapsed: 433.4s | ETA: 616.1s\n",
      "[07:38:28] Processed 1370/3295 | Elapsed: 435.5s | ETA: 611.5s\n",
      "[07:38:30] Processed 1380/3295 | Elapsed: 437.8s | ETA: 607.0s\n",
      "[07:38:32] Processed 1390/3295 | Elapsed: 439.8s | ETA: 602.3s\n",
      "✓ Saved batch: 50 records | Total processed: 1400\n",
      "[07:38:35] Processed 1400/3295 | Elapsed: 442.7s | ETA: 598.8s\n",
      "[07:38:37] Processed 1410/3295 | Elapsed: 444.7s | ETA: 594.0s\n",
      "[07:38:39] Processed 1420/3295 | Elapsed: 446.7s | ETA: 589.5s\n",
      "[07:38:41] Processed 1430/3295 | Elapsed: 448.9s | ETA: 585.0s\n",
      "[07:38:43] Processed 1440/3295 | Elapsed: 450.9s | ETA: 580.4s\n",
      "✓ Saved batch: 50 records | Total processed: 1450\n",
      "[07:38:46] Processed 1450/3295 | Elapsed: 453.6s | ETA: 576.8s\n",
      "[07:38:48] Processed 1460/3295 | Elapsed: 455.7s | ETA: 572.3s\n",
      "[07:38:50] Processed 1470/3295 | Elapsed: 457.9s | ETA: 568.1s\n",
      "[07:38:52] Processed 1480/3295 | Elapsed: 459.9s | ETA: 563.7s\n",
      "[07:38:54] Processed 1490/3295 | Elapsed: 462.0s | ETA: 559.3s\n",
      "✓ Saved batch: 50 records | Total processed: 1500\n",
      "[07:38:57] Processed 1500/3295 | Elapsed: 464.7s | ETA: 555.8s\n",
      "[07:38:59] Processed 1510/3295 | Elapsed: 466.8s | ETA: 551.4s\n",
      "[07:39:01] Processed 1520/3295 | Elapsed: 468.8s | ETA: 547.1s\n",
      "[07:39:03] Processed 1530/3295 | Elapsed: 470.9s | ETA: 542.8s\n",
      "[07:39:05] Processed 1540/3295 | Elapsed: 473.0s | ETA: 538.7s\n",
      "✓ Saved batch: 50 records | Total processed: 1550\n",
      "[07:39:08] Processed 1550/3295 | Elapsed: 475.8s | ETA: 535.4s\n",
      "[07:39:10] Processed 1560/3295 | Elapsed: 478.0s | ETA: 531.3s\n",
      "[07:39:12] Processed 1570/3295 | Elapsed: 480.1s | ETA: 527.2s\n",
      "[07:39:15] Processed 1580/3295 | Elapsed: 482.3s | ETA: 523.1s\n",
      "[07:39:17] Processed 1590/3295 | Elapsed: 484.3s | ETA: 519.0s\n",
      "✓ Saved batch: 50 records | Total processed: 1600\n",
      "[07:39:20] Processed 1600/3295 | Elapsed: 487.3s | ETA: 515.9s\n",
      "[07:39:22] Processed 1610/3295 | Elapsed: 489.3s | ETA: 511.8s\n",
      "[07:39:24] Processed 1620/3295 | Elapsed: 491.3s | ETA: 507.7s\n",
      "[07:39:26] Processed 1630/3295 | Elapsed: 493.4s | ETA: 503.7s\n",
      "[07:39:28] Processed 1640/3295 | Elapsed: 495.4s | ETA: 499.6s\n",
      "✓ Saved batch: 50 records | Total processed: 1650\n",
      "[07:39:31] Processed 1650/3295 | Elapsed: 498.4s | ETA: 496.6s\n",
      "[07:39:33] Processed 1660/3295 | Elapsed: 500.4s | ETA: 492.6s\n",
      "[07:39:35] Processed 1670/3295 | Elapsed: 502.5s | ETA: 488.6s\n",
      "[07:39:37] Processed 1680/3295 | Elapsed: 504.6s | ETA: 484.8s\n",
      "[07:39:39] Processed 1690/3295 | Elapsed: 506.7s | ETA: 480.9s\n",
      "✓ Saved batch: 50 records | Total processed: 1700\n",
      "[07:39:42] Processed 1700/3295 | Elapsed: 509.6s | ETA: 477.9s\n",
      "[07:39:44] Processed 1710/3295 | Elapsed: 511.6s | ETA: 474.0s\n",
      "[07:39:46] Processed 1720/3295 | Elapsed: 513.6s | ETA: 470.1s\n",
      "[07:39:48] Processed 1730/3295 | Elapsed: 515.7s | ETA: 466.3s\n",
      "[07:39:50] Processed 1740/3295 | Elapsed: 517.9s | ETA: 462.5s\n",
      "✓ Saved batch: 50 records | Total processed: 1750\n",
      "[07:39:53] Processed 1750/3295 | Elapsed: 520.7s | ETA: 459.5s\n",
      "[07:39:55] Processed 1760/3295 | Elapsed: 522.7s | ETA: 455.6s\n",
      "[07:39:57] Processed 1770/3295 | Elapsed: 524.8s | ETA: 451.9s\n",
      "[07:39:59] Processed 1780/3295 | Elapsed: 527.0s | ETA: 448.3s\n",
      "[07:40:01] Processed 1790/3295 | Elapsed: 529.0s | ETA: 444.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 1800\n",
      "[07:40:05] Processed 1800/3295 | Elapsed: 532.8s | ETA: 442.3s\n",
      "[07:40:10] Processed 1810/3295 | Elapsed: 537.5s | ETA: 440.7s\n",
      "[07:40:14] Processed 1820/3295 | Elapsed: 541.8s | ETA: 438.8s\n",
      "[07:40:18] Processed 1830/3295 | Elapsed: 546.0s | ETA: 436.9s\n",
      "[07:40:22] Processed 1840/3295 | Elapsed: 549.8s | ETA: 434.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 1850\n",
      "[07:40:29] Processed 1850/3295 | Elapsed: 556.7s | ETA: 434.6s\n",
      "[07:40:33] Processed 1860/3295 | Elapsed: 560.2s | ETA: 432.0s\n",
      "[07:40:35] Processed 1870/3295 | Elapsed: 562.9s | ETA: 428.7s\n",
      "[07:40:38] Processed 1880/3295 | Elapsed: 565.9s | ETA: 425.7s\n",
      "[07:40:41] Processed 1890/3295 | Elapsed: 568.8s | ETA: 422.6s\n",
      "✓ Saved batch: 50 records | Total processed: 1900\n",
      "[07:40:45] Processed 1900/3295 | Elapsed: 572.5s | ETA: 420.1s\n",
      "[07:40:48] Processed 1910/3295 | Elapsed: 575.3s | ETA: 416.9s\n",
      "[07:40:51] Processed 1920/3295 | Elapsed: 578.4s | ETA: 414.0s\n",
      "[07:40:53] Processed 1930/3295 | Elapsed: 581.1s | ETA: 410.7s\n",
      "[07:40:56] Processed 1940/3295 | Elapsed: 583.6s | ETA: 407.4s\n",
      "✓ Saved batch: 50 records | Total processed: 1950\n",
      "[07:41:00] Processed 1950/3295 | Elapsed: 587.3s | ETA: 404.9s\n",
      "[07:41:02] Processed 1960/3295 | Elapsed: 590.0s | ETA: 401.7s\n",
      "[07:41:05] Processed 1970/3295 | Elapsed: 592.7s | ETA: 398.5s\n",
      "[07:41:08] Processed 1980/3295 | Elapsed: 595.6s | ETA: 395.4s\n",
      "[07:41:11] Processed 1990/3295 | Elapsed: 598.6s | ETA: 392.4s\n",
      "✓ Saved batch: 50 records | Total processed: 2000\n",
      "[07:41:15] Processed 2000/3295 | Elapsed: 602.2s | ETA: 389.7s\n",
      "[07:41:17] Processed 2010/3295 | Elapsed: 604.9s | ETA: 386.5s\n",
      "[07:41:20] Processed 2020/3295 | Elapsed: 607.9s | ETA: 383.5s\n",
      "[07:41:23] Processed 2030/3295 | Elapsed: 610.9s | ETA: 380.5s\n",
      "[07:41:26] Processed 2040/3295 | Elapsed: 613.7s | ETA: 377.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2050\n",
      "[07:41:31] Processed 2050/3295 | Elapsed: 618.5s | ETA: 375.4s\n",
      "[07:41:34] Processed 2060/3295 | Elapsed: 621.3s | ETA: 372.3s\n",
      "[07:41:36] Processed 2070/3295 | Elapsed: 624.1s | ETA: 369.2s\n",
      "[07:41:39] Processed 2080/3295 | Elapsed: 627.0s | ETA: 366.1s\n",
      "[07:41:43] Processed 2090/3295 | Elapsed: 630.6s | ETA: 363.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2100\n",
      "[07:41:48] Processed 2100/3295 | Elapsed: 636.0s | ETA: 361.7s\n",
      "[07:41:52] Processed 2110/3295 | Elapsed: 639.2s | ETA: 358.8s\n",
      "[07:41:55] Processed 2120/3295 | Elapsed: 642.5s | ETA: 355.9s\n",
      "[07:41:58] Processed 2130/3295 | Elapsed: 645.5s | ETA: 352.9s\n",
      "[07:42:01] Processed 2140/3295 | Elapsed: 648.5s | ETA: 349.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2150\n",
      "[07:42:06] Processed 2150/3295 | Elapsed: 653.5s | ETA: 347.9s\n",
      "[07:42:09] Processed 2160/3295 | Elapsed: 656.4s | ETA: 344.7s\n",
      "[07:42:12] Processed 2170/3295 | Elapsed: 659.3s | ETA: 341.6s\n",
      "[07:42:14] Processed 2180/3295 | Elapsed: 662.0s | ETA: 338.4s\n",
      "[07:42:17] Processed 2190/3295 | Elapsed: 664.8s | ETA: 335.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2200\n",
      "[07:42:22] Processed 2200/3295 | Elapsed: 669.9s | ETA: 333.3s\n",
      "[07:42:25] Processed 2210/3295 | Elapsed: 672.7s | ETA: 330.1s\n",
      "[07:42:28] Processed 2220/3295 | Elapsed: 675.6s | ETA: 327.0s\n",
      "[07:42:31] Processed 2230/3295 | Elapsed: 678.4s | ETA: 323.8s\n",
      "[07:42:33] Processed 2240/3295 | Elapsed: 680.9s | ETA: 320.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2250\n",
      "[07:42:38] Processed 2250/3295 | Elapsed: 685.5s | ETA: 318.2s\n",
      "[07:42:41] Processed 2260/3295 | Elapsed: 688.3s | ETA: 315.1s\n",
      "[07:42:44] Processed 2270/3295 | Elapsed: 691.2s | ETA: 312.0s\n",
      "[07:42:46] Processed 2280/3295 | Elapsed: 694.1s | ETA: 308.9s\n",
      "[07:42:49] Processed 2290/3295 | Elapsed: 697.1s | ETA: 305.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2300\n",
      "[07:42:55] Processed 2300/3295 | Elapsed: 702.5s | ETA: 303.8s\n",
      "[07:42:58] Processed 2310/3295 | Elapsed: 705.7s | ETA: 300.8s\n",
      "[07:43:01] Processed 2320/3295 | Elapsed: 708.7s | ETA: 297.7s\n",
      "[07:43:04] Processed 2330/3295 | Elapsed: 711.1s | ETA: 294.4s\n",
      "[07:43:06] Processed 2340/3295 | Elapsed: 713.6s | ETA: 291.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2350\n",
      "[07:43:10] Processed 2350/3295 | Elapsed: 717.8s | ETA: 288.5s\n",
      "[07:43:13] Processed 2360/3295 | Elapsed: 720.2s | ETA: 285.2s\n",
      "[07:43:15] Processed 2370/3295 | Elapsed: 722.6s | ETA: 281.9s\n",
      "[07:43:17] Processed 2380/3295 | Elapsed: 725.0s | ETA: 278.6s\n",
      "[07:43:20] Processed 2390/3295 | Elapsed: 727.7s | ETA: 275.4s\n",
      "✓ Saved batch: 50 records | Total processed: 2400\n",
      "[07:43:23] Processed 2400/3295 | Elapsed: 731.1s | ETA: 272.5s\n",
      "[07:43:26] Processed 2410/3295 | Elapsed: 733.6s | ETA: 269.3s\n",
      "[07:43:29] Processed 2420/3295 | Elapsed: 736.3s | ETA: 266.1s\n",
      "[07:43:31] Processed 2430/3295 | Elapsed: 738.8s | ETA: 262.9s\n",
      "[07:43:34] Processed 2440/3295 | Elapsed: 741.3s | ETA: 259.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2450\n",
      "[07:43:38] Processed 2450/3295 | Elapsed: 745.4s | ETA: 257.0s\n",
      "[07:43:41] Processed 2460/3295 | Elapsed: 748.1s | ETA: 253.8s\n",
      "[07:43:43] Processed 2470/3295 | Elapsed: 750.6s | ETA: 250.6s\n",
      "[07:43:45] Processed 2480/3295 | Elapsed: 753.0s | ETA: 247.4s\n",
      "[07:43:48] Processed 2490/3295 | Elapsed: 755.6s | ETA: 244.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2500\n",
      "[07:43:52] Processed 2500/3295 | Elapsed: 760.0s | ETA: 241.6s\n",
      "[07:43:55] Processed 2510/3295 | Elapsed: 762.8s | ETA: 238.5s\n",
      "[07:43:58] Processed 2520/3295 | Elapsed: 765.5s | ETA: 235.3s\n",
      "[07:44:01] Processed 2530/3295 | Elapsed: 768.1s | ETA: 232.2s\n",
      "[07:44:03] Processed 2540/3295 | Elapsed: 770.7s | ETA: 229.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2550\n",
      "[07:44:07] Processed 2550/3295 | Elapsed: 774.5s | ETA: 226.2s\n",
      "[07:44:10] Processed 2560/3295 | Elapsed: 777.2s | ETA: 223.0s\n",
      "[07:44:12] Processed 2570/3295 | Elapsed: 779.7s | ETA: 219.9s\n",
      "[07:44:15] Processed 2580/3295 | Elapsed: 782.2s | ETA: 216.7s\n",
      "[07:44:17] Processed 2590/3295 | Elapsed: 784.8s | ETA: 213.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2600\n",
      "[07:44:22] Processed 2600/3295 | Elapsed: 789.9s | ETA: 211.1s\n",
      "[07:44:25] Processed 2610/3295 | Elapsed: 792.6s | ETA: 207.9s\n",
      "[07:44:28] Processed 2620/3295 | Elapsed: 795.3s | ETA: 204.8s\n",
      "[07:44:31] Processed 2630/3295 | Elapsed: 798.3s | ETA: 201.8s\n",
      "[07:44:33] Processed 2640/3295 | Elapsed: 800.8s | ETA: 198.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2650\n",
      "[07:44:38] Processed 2650/3295 | Elapsed: 805.2s | ETA: 195.9s\n",
      "[07:44:40] Processed 2660/3295 | Elapsed: 807.8s | ETA: 192.8s\n",
      "[07:44:43] Processed 2670/3295 | Elapsed: 810.4s | ETA: 189.6s\n",
      "[07:44:45] Processed 2680/3295 | Elapsed: 813.0s | ETA: 186.5s\n",
      "[07:44:48] Processed 2690/3295 | Elapsed: 815.6s | ETA: 183.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2700\n",
      "[07:44:52] Processed 2700/3295 | Elapsed: 820.0s | ETA: 180.6s\n",
      "[07:44:55] Processed 2710/3295 | Elapsed: 822.5s | ETA: 177.5s\n",
      "[07:44:57] Processed 2720/3295 | Elapsed: 824.9s | ETA: 174.3s\n",
      "[07:45:00] Processed 2730/3295 | Elapsed: 827.5s | ETA: 171.2s\n",
      "[07:45:02] Processed 2740/3295 | Elapsed: 830.0s | ETA: 168.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2750\n",
      "[07:45:06] Processed 2750/3295 | Elapsed: 833.9s | ETA: 165.2s\n",
      "[07:45:09] Processed 2760/3295 | Elapsed: 836.4s | ETA: 162.1s\n",
      "[07:45:11] Processed 2770/3295 | Elapsed: 839.1s | ETA: 159.0s\n",
      "[07:45:14] Processed 2780/3295 | Elapsed: 841.7s | ETA: 155.9s\n",
      "[07:45:17] Processed 2790/3295 | Elapsed: 844.2s | ETA: 152.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2800\n",
      "[07:45:21] Processed 2800/3295 | Elapsed: 848.2s | ETA: 149.9s\n",
      "[07:45:23] Processed 2810/3295 | Elapsed: 850.8s | ETA: 146.8s\n",
      "[07:45:26] Processed 2820/3295 | Elapsed: 853.4s | ETA: 143.7s\n",
      "[07:45:28] Processed 2830/3295 | Elapsed: 855.9s | ETA: 140.6s\n",
      "[07:45:31] Processed 2840/3295 | Elapsed: 858.4s | ETA: 137.5s\n",
      "✓ Saved batch: 50 records | Total processed: 2850\n",
      "[07:45:34] Processed 2850/3295 | Elapsed: 862.0s | ETA: 134.6s\n",
      "[07:45:37] Processed 2860/3295 | Elapsed: 864.4s | ETA: 131.4s\n",
      "[07:45:39] Processed 2870/3295 | Elapsed: 867.0s | ETA: 128.3s\n",
      "[07:45:42] Processed 2880/3295 | Elapsed: 869.6s | ETA: 125.3s\n",
      "[07:45:44] Processed 2890/3295 | Elapsed: 872.1s | ETA: 122.2s\n",
      "✓ Saved batch: 50 records | Total processed: 2900\n",
      "[07:45:48] Processed 2900/3295 | Elapsed: 875.4s | ETA: 119.2s\n",
      "[07:45:51] Processed 2910/3295 | Elapsed: 878.4s | ETA: 116.2s\n",
      "[07:45:53] Processed 2920/3295 | Elapsed: 881.1s | ETA: 113.1s\n",
      "[07:45:56] Processed 2930/3295 | Elapsed: 883.7s | ETA: 110.0s\n",
      "[07:45:59] Processed 2940/3295 | Elapsed: 886.5s | ETA: 107.0s\n",
      "✓ Saved batch: 50 records | Total processed: 2950\n",
      "[07:46:02] Processed 2950/3295 | Elapsed: 890.1s | ETA: 104.1s\n",
      "[07:46:05] Processed 2960/3295 | Elapsed: 892.6s | ETA: 101.0s\n",
      "[07:46:07] Processed 2970/3295 | Elapsed: 895.1s | ETA: 97.9s\n",
      "[07:46:10] Processed 2980/3295 | Elapsed: 897.8s | ETA: 94.9s\n",
      "[07:46:13] Processed 2990/3295 | Elapsed: 900.3s | ETA: 91.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 3000\n",
      "[07:46:17] Processed 3000/3295 | Elapsed: 904.8s | ETA: 88.9s\n",
      "[07:46:20] Processed 3010/3295 | Elapsed: 907.8s | ETA: 85.9s\n",
      "[07:46:23] Processed 3020/3295 | Elapsed: 910.6s | ETA: 82.9s\n",
      "[07:46:26] Processed 3030/3295 | Elapsed: 913.4s | ETA: 79.9s\n",
      "[07:46:28] Processed 3040/3295 | Elapsed: 916.0s | ETA: 76.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 3050\n",
      "[07:46:33] Processed 3050/3295 | Elapsed: 920.8s | ETA: 73.9s\n",
      "[07:46:36] Processed 3060/3295 | Elapsed: 923.3s | ETA: 70.9s\n",
      "[07:46:38] Processed 3070/3295 | Elapsed: 925.8s | ETA: 67.8s\n",
      "[07:46:41] Processed 3080/3295 | Elapsed: 928.4s | ETA: 64.8s\n",
      "[07:46:43] Processed 3090/3295 | Elapsed: 930.8s | ETA: 61.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 3100\n",
      "[07:46:48] Processed 3100/3295 | Elapsed: 935.7s | ETA: 58.8s\n",
      "[07:46:51] Processed 3110/3295 | Elapsed: 938.4s | ETA: 55.8s\n",
      "[07:46:53] Processed 3120/3295 | Elapsed: 940.9s | ETA: 52.8s\n",
      "[07:46:56] Processed 3130/3295 | Elapsed: 943.5s | ETA: 49.7s\n",
      "[07:46:59] Processed 3140/3295 | Elapsed: 946.1s | ETA: 46.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 3150\n",
      "[07:47:04] Processed 3150/3295 | Elapsed: 951.3s | ETA: 43.8s\n",
      "[07:47:06] Processed 3160/3295 | Elapsed: 953.8s | ETA: 40.7s\n",
      "[07:47:09] Processed 3170/3295 | Elapsed: 956.3s | ETA: 37.7s\n",
      "[07:47:11] Processed 3180/3295 | Elapsed: 958.8s | ETA: 34.7s\n",
      "[07:47:14] Processed 3190/3295 | Elapsed: 961.2s | ETA: 31.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 3200\n",
      "[07:47:18] Processed 3200/3295 | Elapsed: 965.4s | ETA: 28.7s\n",
      "[07:47:21] Processed 3210/3295 | Elapsed: 968.2s | ETA: 25.6s\n",
      "[07:47:23] Processed 3220/3295 | Elapsed: 970.7s | ETA: 22.6s\n",
      "[07:47:26] Processed 3230/3295 | Elapsed: 973.3s | ETA: 19.6s\n",
      "[07:47:28] Processed 3240/3295 | Elapsed: 976.1s | ETA: 16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 3250\n",
      "[07:47:33] Processed 3250/3295 | Elapsed: 980.5s | ETA: 13.6s\n",
      "[07:47:36] Processed 3260/3295 | Elapsed: 983.3s | ETA: 10.6s\n",
      "[07:47:38] Processed 3270/3295 | Elapsed: 985.9s | ETA: 7.5s\n",
      "[07:47:41] Processed 3280/3295 | Elapsed: 988.4s | ETA: 4.5s\n",
      "[07:47:43] Processed 3290/3295 | Elapsed: 990.9s | ETA: 1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved final batch: 45 records\n",
      "✓ Đã giải phóng bộ nhớ processing\n",
      "\n",
      "=== Completed processing in 993.8s ===\n",
      "\n",
      "=== Checking saved results ===\n",
      "Total records in table: 3295\n",
      "\n",
      "Recent 5 records:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+-------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+-------------------+------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "|                                             postID|        timePublish|                                                          description_Normalized|                                                                       Label_NER|        Label_Topic|Label_Intent|likeCount|commentCount|shareCount|  type|                created_at|                updated_at|\n",
      "+---------------------------------------------------+-------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+-------------------+------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "|        @tuyensinh.hcmcou/video/7485349492972162311|2025-03-24 00:00:00|Trường Đại_học Mở TP. Hồ_Chí_Minh công_bố mức học_phí dự_kiến của chương_trìn...|B-ORG I-ORG I-ORG I-ORG I-ORG O O B-FEE O O B-PRO I-PRO I-PRO I-PRO O O B-FEE...| TUITION|UNIVERSITY|  share_info|     1133|          54|         0|TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "|           @eduquiz.study/video/7492421328327183634|2025-04-12 00:00:00|                                                     Thi A01 tham_khảo thử nhé .|                                                                O B-TERM O O O O|SUBJECT_COMBINATION|  share_info|     2285|          40|         0|TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "|@cdhanghaiduongthuy2_mic2/video/7491314629390486802|2025-04-09 00:00:00|                                                                               #|                                                                               O|              OTHER|       other|       71|          10|         0|TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "| @daihocfpthanoi_official/video/7494485375826660615|2025-04-18 00:00:00|Tác_động của AI - Cơ_hội cho ai ? 41% doanh_nghiệp giảm nhân_sự , 92 triệu ng...|        O O B-MAJ O O O O O O B-MISC O O O O O O O O O O B-DATE I-DATE O B-MAJ O|              MAJOR|  share_info|      447|           8|         0|TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "|        @thanhdong.edu.vn/video/7489833452250991890|2025-04-05 00:00:00|Tuyển_sinh ngành Ngôn_ngữ Trung_Quốc – 18 điểm , xét học_bạ THPT . Đại_học Th...|O B-MAJ I-MAJ I-MAJ O B-SCO I-SCO O B-MISC I-MISC I-MISC O B-ORG I-ORG I-ORG ...|   MAJOR|UNIVERSITY|  share_info|      390|          82|        83|TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "+---------------------------------------------------+-------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+-------------------+------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa schema cho DataFrame kết quả\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.functions import days\n",
    "import gc\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"postID\", StringType(), False),\n",
    "    StructField(\"timePublish\", TimestampType(), False),\n",
    "    StructField(\"description_Normalized\", StringType(), True),\n",
    "    StructField(\"Label_NER\", StringType(), True),\n",
    "    StructField(\"Label_Topic\", StringType(), True),\n",
    "    StructField(\"Label_Intent\", StringType(), True),\n",
    "    StructField(\"likeCount\", IntegerType(), True),\n",
    "    StructField(\"commentCount\", IntegerType(), True),\n",
    "    StructField(\"shareCount\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Kiểm tra xem table result_multi_model đã tồn tại chưa\n",
    "try:\n",
    "    df_existing = spark.table(\"nessie.silver_tables.result_multi_model\")\n",
    "    existing_post_ids = [row.postID for row in df_existing.select(\"postID\").distinct().collect()]\n",
    "    print(f\"Tìm thấy {len(existing_post_ids)} articles đã được xử lý trước đó\")\n",
    "    \n",
    "    # Giải phóng df_existing\n",
    "    df_existing.unpersist()\n",
    "    del df_existing\n",
    "except Exception as e:\n",
    "    print(f\"Table result_multi_model chưa tồn tại hoặc rỗng: {e}\")\n",
    "    existing_post_ids = []\n",
    "\n",
    "# Lọc ra các articles chưa được xử lý\n",
    "if existing_post_ids:\n",
    "    df_articles_new = df_articles.filter(~col(\"articleID\").isin(existing_post_ids))\n",
    "    print(f\"Tổng số articles mới cần xử lý: {df_articles_new.count()}\")\n",
    "else:\n",
    "    df_articles_new = df_articles\n",
    "    print(f\"Xử lý toàn bộ {df_articles.count()} articles\")\n",
    "\n",
    "print(\"\\n=== Collecting data to process ===\")\n",
    "# Collect data về driver để xử lý (phù hợp với dataset nhỏ)\n",
    "articles_to_process = df_articles_new.select(\"articleID\", \"description\", \"timePublish\", \n",
    "                                              \"likeCount\", \"commentCount\", \"shareCount\", \"type\").collect()\n",
    "print(f\"Đã collect {len(articles_to_process)} articles về driver\")\n",
    "\n",
    "# Giải phóng df_articles_new sau khi collect\n",
    "df_articles_new.unpersist()\n",
    "del df_articles_new\n",
    "gc.collect()\n",
    "print(\"✓ Đã giải phóng df_articles_new\")\n",
    "\n",
    "# Xử lý từng article bằng model đã load sẵn trên driver\n",
    "results = []\n",
    "batch_size = 50  # Xử lý và lưu mỗi 50 records\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"\\n=== Processing articles with model ===\")\n",
    "for idx, row in enumerate(articles_to_process):\n",
    "    if idx % 10 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        avg_time = elapsed / (idx + 1) if idx > 0 else 0\n",
    "        remaining = avg_time * (len(articles_to_process) - idx)\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] Processed {idx}/{len(articles_to_process)} | \"\n",
    "              f\"Elapsed: {elapsed:.1f}s | ETA: {remaining:.1f}s\")\n",
    "    \n",
    "    article_id = row['articleID']\n",
    "    description = row['description']\n",
    "    \n",
    "    if not description or description.strip() == '':\n",
    "        results.append({\n",
    "            'postID': article_id,\n",
    "            'timePublish': row['timePublish'],\n",
    "            'description_Normalized': '',\n",
    "            'Label_NER': 'O',\n",
    "            'Label_Topic': 'None',\n",
    "            'Label_Intent': 'Unknown',\n",
    "            'likeCount': int(row['likeCount']) if row['likeCount'] else 0,\n",
    "            'commentCount': int(row['commentCount']) if row['commentCount'] else 0,\n",
    "            'shareCount': int(row['shareCount']) if row['shareCount'] else 0,\n",
    "            'type': row['type']\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Sử dụng hàm predict_labels đã định nghĩa ở cell 6\n",
    "        predictions = predict_labels(description, model, tokenizer, label_mappings, device, annotator)\n",
    "        \n",
    "        results.append({\n",
    "            'postID': article_id,\n",
    "            'timePublish': row['timePublish'],\n",
    "            'description_Normalized': predictions['normalized_text'],\n",
    "            'Label_NER': predictions['ner_labels'],\n",
    "            'Label_Topic': predictions['topic_label'],\n",
    "            'Label_Intent': predictions['intent_label'],\n",
    "            'likeCount': int(row['likeCount']) if row['likeCount'] else 0,\n",
    "            'commentCount': int(row['commentCount']) if row['commentCount'] else 0,\n",
    "            'shareCount': int(row['shareCount']) if row['shareCount'] else 0,\n",
    "            'type': row['type']\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article {article_id}: {e}\")\n",
    "        results.append({\n",
    "            'postID': article_id,\n",
    "            'timePublish': row['timePublish'],\n",
    "            'description_Normalized': description,\n",
    "            'Label_NER': 'O',\n",
    "            'Label_Topic': 'None',\n",
    "            'Label_Intent': 'Unknown',\n",
    "            'likeCount': int(row['likeCount']) if row['likeCount'] else 0,\n",
    "            'commentCount': int(row['commentCount']) if row['commentCount'] else 0,\n",
    "            'shareCount': int(row['shareCount']) if row['shareCount'] else 0,\n",
    "            'type': row['type']\n",
    "        })\n",
    "    \n",
    "    # Lưu batch và reset results để giải phóng memory\n",
    "    if (idx + 1) % batch_size == 0 and len(results) > 0:\n",
    "        try:\n",
    "            batch_df = spark.createDataFrame(results, schema=schema)\n",
    "            batch_df = batch_df.withColumn(\"created_at\", current_timestamp()) \\\n",
    "                               .withColumn(\"updated_at\", current_timestamp())\n",
    "            \n",
    "            # Append batch vào table\n",
    "            batch_df.writeTo(\"nessie.silver_tables.result_multi_model\") \\\n",
    "                .using(\"iceberg\") \\\n",
    "                .tableProperty(\"write.format.default\", \"parquet\") \\\n",
    "                .tableProperty(\"write.metadata.compression-codec\", \"gzip\") \\\n",
    "                .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n",
    "                .append()\n",
    "            \n",
    "            print(f\"✓ Saved batch: {len(results)} records | Total processed: {idx + 1}\")\n",
    "            \n",
    "            # Giải phóng batch_df\n",
    "            batch_df.unpersist()\n",
    "            del batch_df\n",
    "            \n",
    "            results = []  # Reset\n",
    "            gc.collect()  # Thu gom rác\n",
    "            \n",
    "        except Exception as batch_err:\n",
    "            # Nếu table chưa tồn tại, tạo mới\n",
    "            if \"table does not exist\" in str(batch_err).lower() or \"not found\" in str(batch_err).lower():\n",
    "                print(\"Creating table for first batch...\")\n",
    "                batch_df.writeTo(\"nessie.silver_tables.result_multi_model\") \\\n",
    "                    .using(\"iceberg\") \\\n",
    "                    .tableProperty(\"write.format.default\", \"parquet\") \\\n",
    "                    .tableProperty(\"write.metadata.compression-codec\", \"gzip\") \\\n",
    "                    .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n",
    "                    .partitionedBy(days(col(\"timePublish\"))) \\\n",
    "                    .create()\n",
    "                print(f\"✓ Table created with {len(results)} records\")\n",
    "                \n",
    "                # Giải phóng\n",
    "                batch_df.unpersist()\n",
    "                del batch_df\n",
    "                results = []\n",
    "                gc.collect()\n",
    "            else:\n",
    "                print(f\"✗ Error saving batch: {batch_err}\")\n",
    "\n",
    "# Lưu records còn lại (nếu có)\n",
    "if len(results) > 0:\n",
    "    try:\n",
    "        final_df = spark.createDataFrame(results, schema=schema)\n",
    "        final_df = final_df.withColumn(\"created_at\", current_timestamp()) \\\n",
    "                           .withColumn(\"updated_at\", current_timestamp())\n",
    "        \n",
    "        final_df.writeTo(\"nessie.silver_tables.result_multi_model\") \\\n",
    "            .using(\"iceberg\") \\\n",
    "            .tableProperty(\"write.format.default\", \"parquet\") \\\n",
    "            .tableProperty(\"write.metadata.compression-codec\", \"gzip\") \\\n",
    "            .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n",
    "            .append()\n",
    "        \n",
    "        print(f\"✓ Saved final batch: {len(results)} records\")\n",
    "        \n",
    "        # Giải phóng\n",
    "        final_df.unpersist()\n",
    "        del final_df\n",
    "        \n",
    "    except Exception as final_err:\n",
    "        if \"table does not exist\" in str(final_err).lower():\n",
    "            final_df.writeTo(\"nessie.silver_tables.result_multi_model\") \\\n",
    "                .using(\"iceberg\") \\\n",
    "                .tableProperty(\"write.format.default\", \"parquet\") \\\n",
    "                .tableProperty(\"write.metadata.compression-codec\", \"gzip\") \\\n",
    "                .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n",
    "                .partitionedBy(days(col(\"timePublish\"))) \\\n",
    "                .create()\n",
    "            print(f\"✓ Table created with {len(results)} records\")\n",
    "            \n",
    "            # Giải phóng\n",
    "            final_df.unpersist()\n",
    "            del final_df\n",
    "\n",
    "# Giải phóng bộ nhớ cuối cùng\n",
    "del results, articles_to_process\n",
    "gc.collect()\n",
    "print(\"✓ Đã giải phóng bộ nhớ processing\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n=== Completed processing in {total_time:.1f}s ===\")\n",
    "\n",
    "# Kiểm tra kết quả đã lưu\n",
    "print(\"\\n=== Checking saved results ===\")\n",
    "try:\n",
    "    df_check = spark.table(\"nessie.silver_tables.result_multi_model\")\n",
    "    print(f\"Total records in table: {df_check.count()}\")\n",
    "    print(\"\\nRecent 5 records:\")\n",
    "    df_check.orderBy(col(\"created_at\").desc()).show(5, truncate=80)\n",
    "    \n",
    "    # Giải phóng df_check\n",
    "    df_check.unpersist()\n",
    "    del df_check\n",
    "    gc.collect()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not read table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74e20ed",
   "metadata": {},
   "source": [
    "## 8. Verify Dữ Liệu Đã Lưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "084e1459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Total records in table: 3295\n",
      "\n",
      "Recent saved records:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+--------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "|postID                                            |timePublish        |description_Normalized                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |Label_NER                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |Label_Topic        |Label_Intent  |likeCount|commentCount|shareCount|type  |created_at                |updated_at                |\n",
      "+--------------------------------------------------+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+--------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "|@tuyensinh.hcmcou/video/7485349492972162311       |2025-03-24 00:00:00|Trường Đại_học Mở TP. Hồ_Chí_Minh công_bố mức học_phí dự_kiến của chương_trình đào_tạo Đại_học chính_quy . Mức học_phí áp_dụng cho khoá 2025 .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |B-ORG I-ORG I-ORG I-ORG I-ORG O O B-FEE O O B-PRO I-PRO I-PRO I-PRO O O B-FEE O O B-DATE I-DATE O                                                                                                                                                                                                                                                                                                                                                                                                  |TUITION|UNIVERSITY |share_info    |1133     |54          |0         |TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "|@eduquiz.study/video/7492421328327183634          |2025-04-12 00:00:00|Thi A01 tham_khảo thử nhé .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |O B-TERM O O O O                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |SUBJECT_COMBINATION|share_info    |2285     |40          |0         |TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "|@khoibeooto/video/7494220834781809928             |2025-04-17 00:00:00|Ngành ô_tô hiện_tại có_dễ xin việc không ? Sinh_viên ô_tô ra trường liệu có thất_nghiệp ? Bạn nào là sinh_viên ô_tô ra trường thì sợ thất_nghiệp ? Mình chia_sẻ thật , nếu_mà học ô_tô đúng cách á thì không phải lo . Mình là Kho_Béo đang thi_công ngành ô_tô . Cái hồi lúc mình mới đi thực_tập á , mình không ngại bẩn . Mình luôn hỏi việc như là rửa xe nè , thay nhớt nè , thay lọc nhớt nè , kể_cả vệ_sinh xưởng luôn . Việc nào mình cũng làm . Chỉ sau một tháng thôi , anh kia thành_viên chính vừa hỏi mình là mình có phải là chịu làm với anh_em không thì mình thấy rất là vui khi anh_em được đề_xuất như_vậy . Lúc đó mình chợt nhận rằng không phải học trường tốt mới có việc mà là ai chịu_khó , chịu ham học_hỏi , không ngại bẩn , không ngại sai thì luôn có chỗ . Nếu ra học nghề thì hãy học nghề để làm được , học vì cái bằng . Nếu_mà anh_em có nghề á thì sẽ có việc , đơn_giản là vậy thôi . Bạn đã học nghề ở đâu , có cùng gặp nỗi lo này ? Bình_luận cho tụi mình biết để tụi mình cùng chia_sẻ với các bạn .|B-MAJ I-MAJ O O O O O O B-MISC I-MISC O O O O O O O O O B-MISC I-MISC O O O O O O O O O O O O O O O O O O O O O O O O O O B-MAJ I-MAJ O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O|CAREER|MAJOR       |ask_experience|2441     |48          |121       |TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "|@daihocfpthanoi_official/video/7494485375826660615|2025-04-18 00:00:00|Tác_động của AI - Cơ_hội cho ai ? 41% doanh_nghiệp giảm nhân_sự , 92 triệu người có_thể mất việc vào năm 2025 do AI .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |O O B-MAJ O O O O O O B-MISC O O O O O O O O O O B-DATE I-DATE O B-MAJ O                                                                                                                                                                                                                                                                                                                                                                                                                           |MAJOR              |share_info    |447      |8           |0         |TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "|@chinguyenduhocdieuhien/video/7493481031668976914 |2025-04-15 00:00:00|Đại_học Long_Hoa ( Đài_Loan ) tuyển_sinh kỳ 9/2025. Hệ vừa học vừa làm ( Du_lịch , Điện_cơ ) . Hệ 1+4 ( Bán_dẫn , Quản_trị công_nghiệp , Marketing kỹ_thuật_số , TMĐT , Kỹ_thuật mạng ) .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |B-ORG I-ORG O B-LOC O O B-DATE I-DATE B-PRO I-PRO I-PRO I-PRO I-PRO O B-MAJ O B-MAJ O O B-PRO I-PRO O B-MAJ O B-MAJ I-MAJ O B-MAJ I-MAJ O B-MAJ O B-MAJ I-MAJ O O                                                                                                                                                                                                                                                                                                                                  |MAJOR|UNIVERSITY   |share_info    |86       |2           |0         |TikTok|2025-12-08 07:47:45.029136|2025-12-08 07:47:45.029136|\n",
      "+--------------------------------------------------+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+--------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "=== Records saved by time ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 214:==================================================>  (229 + 6) / 239]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----+\n",
      "|created_at                |count|\n",
      "+--------------------------+-----+\n",
      "|2025-12-08 07:47:45.029136|45   |\n",
      "|2025-12-08 07:47:31.628683|50   |\n",
      "|2025-12-08 07:47:16.518126|50   |\n",
      "|2025-12-08 07:47:01.794822|50   |\n",
      "|2025-12-08 07:46:46.360117|50   |\n",
      "|2025-12-08 07:46:31.537678|50   |\n",
      "|2025-12-08 07:46:15.775398|50   |\n",
      "|2025-12-08 07:46:02.075139|50   |\n",
      "|2025-12-08 07:45:47.403404|50   |\n",
      "|2025-12-08 07:45:33.892038|50   |\n",
      "|2025-12-08 07:45:19.640926|50   |\n",
      "|2025-12-08 07:45:05.340584|50   |\n",
      "|2025-12-08 07:44:51.582258|50   |\n",
      "|2025-12-08 07:44:36.319707|50   |\n",
      "|2025-12-08 07:44:21.17089 |50   |\n",
      "|2025-12-08 07:44:05.996317|50   |\n",
      "|2025-12-08 07:43:51.324001|50   |\n",
      "|2025-12-08 07:43:36.614141|50   |\n",
      "|2025-12-08 07:43:23.056378|50   |\n",
      "|2025-12-08 07:43:09.115966|50   |\n",
      "+--------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "✓ Đã giải phóng bộ nhớ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Verify dữ liệu đã lưu (Cell 7 đã tự động lưu theo batch)\n",
    "import gc\n",
    "\n",
    "try:\n",
    "    df_verify = spark.table(\"nessie.silver_tables.result_multi_model\")\n",
    "    total_count = df_verify.count()\n",
    "    \n",
    "    print(f\"✓ Total records in table: {total_count}\")\n",
    "    print(\"\\nRecent saved records:\")\n",
    "    df_verify.orderBy(col(\"created_at\").desc()).show(5, truncate=False)\n",
    "    \n",
    "    # Thống kê số lượng records theo thời gian tạo\n",
    "    print(\"\\n=== Records saved by time ===\")\n",
    "    df_verify.groupBy(\"created_at\").count() \\\n",
    "        .orderBy(col(\"created_at\").desc()) \\\n",
    "        .show(20, truncate=False)\n",
    "    \n",
    "    # Giải phóng bộ nhớ\n",
    "    df_verify.unpersist()\n",
    "    del df_verify\n",
    "    gc.collect()\n",
    "    print(\"\\n✓ Đã giải phóng bộ nhớ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error reading table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684149c",
   "metadata": {},
   "source": [
    "## 9. Thống kê kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fec9f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in result_multi_model: 3295\n",
      "\n",
      "Sample records:\n",
      "+--------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------+----------------+--------------+---------+------------+----------+--------+--------------------------+--------------------------+\n",
      "|postID                                      |timePublish        |description_Normalized                                                                                                                                                                                                                                        |Label_NER                                                                                                                              |Label_Topic     |Label_Intent  |likeCount|commentCount|shareCount|type    |created_at                |updated_at                |\n",
      "+--------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------+----------------+--------------+---------+------------+----------+--------+--------------------------+--------------------------+\n",
      "|@kpt.education/video/7555418377129315605    |2025-09-29 00:00:00|Top 7 ngành có điểm_chuẩn cao nhất năm 2025 .                                                                                                                                                                                                                 |O O O O B-MISC O O B-DATE I-DATE O                                                                                                     |OTHER           |share_info    |11       |0           |0         |TikTok  |2025-12-08 07:40:04.187195|2025-12-08 07:40:04.187195|\n",
      "|@giang345661/video/7525756282557517073      |2025-07-11 00:00:00|Sư_phạm Mầm_non .                                                                                                                                                                                                                                             |B-MAJ I-MAJ O                                                                                                                          |MAJOR           |other         |264      |24          |42        |TikTok  |2025-12-08 07:35:44.565447|2025-12-08 07:35:44.565447|\n",
      "|@dinhatcungmia/video/7525682910767189255    |2025-07-11 00:00:00|TOP 5 ngành khó tìm việc khi đi theo diện kỹ_sư Nhật_Bản : 1 . Kinh_tế . 2 . IT ( chưa có kinh_nghiệm , chưa có tiếng Nhật ) . 3 . Công_nghệ_Sinh_học , Hoá_học . 4 . Nông_nghiệp . 5 . Môi_trường và Trắc_địa .                                              |O O O O O O O O O O O B-LOC O O O B-MAJ O O O B-MAJ O O O O O O O B-SUBJ I-SUBJ O O O O B-MAJ O B-MAJ O O O B-MAJ O O O B-MAJ O B-MAJ O|MAJOR           |share_info    |17       |1           |5         |TikTok  |2025-12-08 07:35:44.565447|2025-12-08 07:35:44.565447|\n",
      "|@trannguyen200odn/video/7525739292774173960 |2025-07-11 00:00:00|Ngành Kỹ_thuật tại Đại_học VinUni .                                                                                                                                                                                                                           |B-MAJ I-MAJ O B-ORG I-ORG O                                                                                                            |MAJOR|UNIVERSITY|ask_info      |14       |0           |0         |TikTok  |2025-12-08 07:35:44.565447|2025-12-08 07:35:44.565447|\n",
      "|@tinnonggiaoduc247/video/7525708465117859079|2025-07-11 00:00:00|Điểm_chuẩn ĐH Công_nghệ_Thông_tin ( UIT ) 2025 dự_kiến giảm nhẹ hoặc ổn_định . Ngành Thiết_kế vi_mạch có điểm_sàn lên tới 24 .                                                                                                                                |B-MISC B-ORG I-ORG I-ORG B-ORG O B-DATE O O O O O O B-MAJ I-MAJ I-MAJ O B-MISC O O B-SCO O                                             |MAJOR|UNIVERSITY|share_info    |95       |18          |0         |TikTok  |2025-12-08 07:35:44.565447|2025-12-08 07:35:44.565447|\n",
      "|@ruby.chuyenanh/video/7525754337289571592   |2025-07-11 00:00:00|Chọn ngành theo điểm thi : Dưới 19 ( chọn ngành ít cạnh_tranh ) . 19-22 ( chọn ngành vừa sức trường top giữa ) . 22-25 + ( trường hot ) . So_sánh điểm_chuẩn 3 năm gần nhất . Ví_dụ : Mơ_Bác_sĩ - > An_toàn là Điều_dưỡng - > Dự_phòng là Công_nghệ_sinh_học .|O O O O O O O B-SCO O O O O O O O B-SCO O O O O O O O O O O B-SCO O O O O O O O B-MISC O O O O O O O O O O O O B-MAJ O O O O B-MAJ O   |MAJOR           |share_info    |2748     |80          |0         |TikTok  |2025-12-08 07:35:44.565447|2025-12-08 07:35:44.565447|\n",
      "|2099749010882204                            |2025-11-06 19:35:00|\" Sinh_viên sau khi được yêu_cầu \" \" Nghỉ học phải viết email trình_bày lý_do rõ_ràng \" \" . Cre : tangthongnhan . \"                                                                                                                                           |O B-MISC O O O O O O O O O O O O O O O O O O O O O O                                                                                   |None            |other         |19000    |403         |184       |facebook|2025-12-08 07:38:45.896241|2025-12-08 07:38:45.896241|\n",
      "|2099566174233821                            |2025-11-06 14:51:00|Các đồng kiến_trúc vào cứu em 1 mạng với ạ . Em muốn tạo con rùa này thành các hình_khối giống như hình bên . Em vắt_óc cả ngày này mà nghĩ kh ra . Học sư_phạm mà riết thành dân kiến_trúc . Em khóc tiếng mán luôn r mọi ng ơi .                            |O O B-MAJ O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-MAJ O O O O B-MAJ O O O O O O O O O O O                  |MAJOR           |ask_advice    |1600     |103         |70        |facebook|2025-12-08 07:38:45.896241|2025-12-08 07:38:45.896241|\n",
      "|2099422570914848                            |2025-11-06 14:52:00|Những sinh_viên đã từng bảo_lưu , ý do và hoàn_cảnh dẫn đến lựa_chọn của các bạn là gì ? Và trong suốt quá_trình bảo_lưu các bạn đã làm gì để đạt được mục_đích mình đặt ra từ đầu ? Mình rất muốn nghe kinh_nghiệm từ các bạn .                              |O B-MISC O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O                                   |STUDY           |ask_experience|496      |123         |68        |facebook|2025-12-08 07:38:45.896241|2025-12-08 07:38:45.896241|\n",
      "|2099476937576078                            |2025-11-06 14:52:00|Mn có_thể chỉ cho em cách học ở đh được không ạ ? Chứ em cũng học kĩ lắm mà điểm toàn ở đáy . Phỏng_vấn câu_lạc_bộ cũng toàn trượt .                                                                                                                          |O O O O O O O O B-MISC O O O O O O O O O O O O O O O O O B-MISC O O O O                                                                |STUDY|UNIVERSITY|ask_advice    |464      |111         |54        |facebook|2025-12-08 07:38:45.896241|2025-12-08 07:38:45.896241|\n",
      "+--------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------+----------------+--------------+---------+------------+----------+--------+--------------------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "=== Label Statistics ===\n",
      "\n",
      "Topic distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+\n",
      "|Label_Topic              |count|\n",
      "+-------------------------+-----+\n",
      "|MAJOR                    |651  |\n",
      "|UNIVERSITY               |561  |\n",
      "|MAJOR|UNIVERSITY         |326  |\n",
      "|CAREER|MAJOR             |321  |\n",
      "|OTHER                    |206  |\n",
      "|STUDY                    |155  |\n",
      "|TUITION|UNIVERSITY       |129  |\n",
      "|MAJOR|TUITION|UNIVERSITY |103  |\n",
      "|MAJOR|SUBJECT_COMBINATION|82   |\n",
      "|None                     |82   |\n",
      "+-------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "Intent distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|Label_Intent    |count|\n",
      "+----------------+-----+\n",
      "|share_info      |1553 |\n",
      "|ask_info        |890  |\n",
      "|ask_advice      |403  |\n",
      "|other           |191  |\n",
      "|ask_confirmation|108  |\n",
      "|ask_experience  |76   |\n",
      "|ask_comparison  |74   |\n",
      "+----------------+-----+\n",
      "\n",
      "\n",
      "✓ Đã giải phóng bộ nhớ\n"
     ]
    }
   ],
   "source": [
    "# Đọc lại dữ liệu từ table\n",
    "import gc\n",
    "\n",
    "df_verify = spark.table(\"nessie.silver_tables.result_multi_model\")\n",
    "\n",
    "print(f\"Total records in result_multi_model: {df_verify.count()}\")\n",
    "print(\"\\nSample records:\")\n",
    "df_verify.show(10, truncate=False)\n",
    "\n",
    "print(\"\\n=== Label Statistics ===\")\n",
    "print(\"\\nTopic distribution:\")\n",
    "df_topic = df_verify.groupBy(\"Label_Topic\").count().orderBy(col(\"count\").desc())\n",
    "df_topic.show(10, truncate=False)\n",
    "del df_topic\n",
    "\n",
    "print(\"\\nIntent distribution:\")\n",
    "df_intent = df_verify.groupBy(\"Label_Intent\").count().orderBy(col(\"count\").desc())\n",
    "df_intent.show(truncate=False)\n",
    "del df_intent\n",
    "\n",
    "# Giải phóng bộ nhớ\n",
    "df_verify.unpersist()\n",
    "del df_verify\n",
    "gc.collect()\n",
    "print(\"\\n✓ Đã giải phóng bộ nhớ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba3479",
   "metadata": {},
   "source": [
    "## 10. Dừng Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74aa7a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã giải phóng tất cả bộ nhớ\n",
      "✓ Spark Session đã được dừng!\n"
     ]
    }
   ],
   "source": [
    "# Giải phóng bộ nhớ trước khi dừng Spark\n",
    "import gc\n",
    "\n",
    "# Unpersist df_articles nếu còn cache\n",
    "try:\n",
    "    df_articles.unpersist()\n",
    "    del df_articles\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Giải phóng model và tokenizer\n",
    "try:\n",
    "    del model, tokenizer, label_mappings\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Giải phóng VnCoreNLP\n",
    "try:\n",
    "    if annotator is not None:\n",
    "        del annotator\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Thu gom rác Python\n",
    "gc.collect()\n",
    "print(\"✓ Đã giải phóng tất cả bộ nhớ\")\n",
    "\n",
    "# Dừng Spark Session\n",
    "spark.stop()\n",
    "print(\"✓ Spark Session đã được dừng!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
