{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d139c45d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries và Khởi tạo Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59904f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/06 15:14:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session da duoc khoi tao voi Nessie catalog!\n",
      "Spark Master: spark://spark-master:7077\n",
      "Application ID: app-20251206151427-0000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, udf, current_timestamp\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "from transformers import AutoTokenizer\n",
    "from vncorenlp import VnCoreNLP\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set AWS environment variables for MinIO\n",
    "os.environ['AWS_REGION'] = 'us-east-1'\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'admin123'\n",
    "\n",
    "# Khởi tạo Spark Session với Iceberg và Nessie catalog\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Apply_Model_Multi_Task\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.executor.memory\", \"1536m\")  # 1.5GB - an toàn với worker 2GB\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    .config(\"spark.network.timeout\", \"600s\")\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\")\n",
    "    .config(\"spark.storage.blockManagerSlaveTimeoutMs\", \"600000\")\n",
    "    .config(\"spark.rpc.askTimeout\", \"600s\")\n",
    "    # ===== Iceberg Catalog qua Nessie =====\n",
    "    .config(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.uri\", \"http://nessie:19120/api/v2\")\n",
    "    .config(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "    .config(\"spark.sql.catalog.nessie.warehouse\", \"s3a://silver/\")\n",
    "    .config(\"spark.sql.catalog.nessie.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    # ===== Cấu hình MinIO (S3-compatible) =====\n",
    "    .config(\"spark.sql.catalog.nessie.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.access-key-id\", \"admin\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.secret-access-key\", \"admin123\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.path-style-access\", \"true\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.region\", \"us-east-1\")\n",
    "    # ===== Spark + Hadoop S3 connector =====\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin123\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .config(\"spark.hadoop.fs.s3a.region\", \"us-east-1\")\n",
    "    # Propagate environment variables to executors\n",
    "    .config(\"spark.executorEnv.AWS_REGION\", \"us-east-1\")\n",
    "    .config(\"spark.executorEnv.AWS_ACCESS_KEY_ID\", \"admin\")\n",
    "    .config(\"spark.executorEnv.AWS_SECRET_ACCESS_KEY\", \"admin123\")\n",
    "    # ===== Sử dụng JAR files local =====\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/hadoop-aws-3.3.4.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"Spark Session da duoc khoi tao voi Nessie catalog!\")\n",
    "print(f\"Spark Master: {spark.sparkContext.master}\")\n",
    "print(f\"Application ID: {spark.sparkContext.applicationId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc96d5",
   "metadata": {},
   "source": [
    "## 2. Đọc Dữ Liệu từ Bảng Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5f4f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số articles: 3295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu từ bảng article\n",
    "df_articles = spark.table(\"nessie.silver_tables.article\")\n",
    "print(f\"Tổng số articles: {df_articles.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed41567",
   "metadata": {},
   "source": [
    "## 3. Load Model và Cấu Hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6483a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER labels: 25\n",
      "Topic labels: 10\n",
      "Intent labels: 7\n",
      "\n",
      "=== Kiểm tra VnCoreNLP JAR file ===\n",
      "Tìm thấy: /opt/spark-apps/VnCoreNLP-1.2/VnCoreNLP-1.2.jar\n",
      "\n",
      "Đang khởi tạo VnCoreNLP...\n",
      "VnCoreNLP loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn model local (đã mount vào container)\n",
    "local_model_path = '/opt/spark-apps/phobert_multitask_final'\n",
    "\n",
    "# Đọc JSON files từ local filesystem\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open(f'{local_model_path}/model_config.json', 'r') as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "with open(f'{local_model_path}/label_mappings.json', 'r') as f:\n",
    "    label_mappings = json.load(f)\n",
    "\n",
    "print(f\"NER labels: {model_config['num_ner_labels']}\")\n",
    "print(f\"Topic labels: {model_config['num_topic_labels']}\")\n",
    "print(f\"Intent labels: {model_config['num_intent_labels']}\")\n",
    "\n",
    "# Kiểm tra VnCoreNLP JAR file tại path đã mount\n",
    "print(\"\\n=== Kiểm tra VnCoreNLP JAR file ===\")\n",
    "vncorenlp_path = '/opt/spark-apps/VnCoreNLP-1.2/VnCoreNLP-1.2.jar'\n",
    "\n",
    "if os.path.exists(vncorenlp_path):\n",
    "    print(f\"Tìm thấy: {vncorenlp_path}\")\n",
    "    print(f\"\\nĐang khởi tạo VnCoreNLP...\")\n",
    "    try:\n",
    "        annotator = VnCoreNLP(vncorenlp_path, annotators=\"wseg\", max_heap_size='-Xmx2g')\n",
    "        print(\"VnCoreNLP loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khởi tạo VnCoreNLP: {e}\")\n",
    "        annotator = None\n",
    "else:\n",
    "    print(f\"Không tìm thấy VnCoreNLP JAR tại: {vncorenlp_path}\")\n",
    "    print(\"Kiểm tra lại volume mount trong docker-compose.yaml\")\n",
    "    annotator = None\n",
    "\n",
    "# Lưu model_path cho các cell sau\n",
    "model_path = local_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3bb58b",
   "metadata": {},
   "source": [
    "## 4. Định Nghĩa Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f8a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model class defined!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import RobertaModel\n",
    "\n",
    "\n",
    "class MultiTaskPhoBERT_WithFusion(nn.Module):\n",
    "    \"\"\"Multi-Task PhoBERT với Feature Fusion\"\"\"\n",
    "    def __init__(self, phobert_path, num_ner_labels, num_topic_labels, num_intent_labels, dropout=0.2):\n",
    "        super(MultiTaskPhoBERT_WithFusion, self).__init__()\n",
    "        \n",
    "        self.phobert = RobertaModel.from_pretrained(phobert_path)\n",
    "        self.phobert.config.hidden_dropout_prob = 0.25\n",
    "        self.phobert.config.attention_probs_dropout_prob = 0.25\n",
    "        self.hidden_size = self.phobert.config.hidden_size\n",
    "        self.num_ner_labels = num_ner_labels\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dropout_heavy = nn.Dropout(dropout * 1.5)\n",
    "        \n",
    "        # NER head\n",
    "        self.ner_hidden = nn.Linear(self.hidden_size, self.hidden_size // 2)\n",
    "        self.ner_norm = nn.LayerNorm(self.hidden_size // 2)\n",
    "        self.ner_classifier = nn.Linear(self.hidden_size // 2, num_ner_labels)\n",
    "        \n",
    "        # Intent head\n",
    "        self.intent_hidden = nn.Linear(self.hidden_size, self.hidden_size // 2)\n",
    "        self.intent_norm = nn.LayerNorm(self.hidden_size // 2)\n",
    "        self.intent_classifier = nn.Linear(self.hidden_size // 2, num_intent_labels)\n",
    "        \n",
    "        # Topic Fusion Head\n",
    "        fusion_input_size = self.hidden_size + num_ner_labels\n",
    "        self.topic_input_proj = nn.Linear(fusion_input_size, self.hidden_size)\n",
    "        \n",
    "        self.topic_layer1 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        self.topic_layer2 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout * 0.5)\n",
    "        )\n",
    "        \n",
    "        self.topic_classifier = nn.Linear(self.hidden_size, num_topic_labels)\n",
    "        \n",
    "        # NER attention mechanism\n",
    "        self.ner_attention = nn.Sequential(\n",
    "            nn.Linear(num_ner_labels, num_ner_labels // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(num_ner_labels // 2, num_ner_labels),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        # Cross-Attention\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=self.hidden_size,\n",
    "            num_heads=8,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.cross_attn_norm = nn.LayerNorm(self.hidden_size)\n",
    "        \n",
    "        # Auxiliary head\n",
    "        self.aux_topic_classifier = nn.Sequential(\n",
    "            nn.Linear(num_ner_labels, num_ner_labels // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_ner_labels // 2, num_topic_labels)\n",
    "        )\n",
    "    \n",
    "    def extract_ner_features(self, ner_logits, attention_mask):\n",
    "        \"\"\"Trích xuất NER features với MAX + AVG pooling\"\"\"\n",
    "        ner_probs = F.softmax(ner_logits, dim=-1)\n",
    "        \n",
    "        attention_mask_expanded = attention_mask.unsqueeze(-1).expand_as(ner_probs)\n",
    "        ner_probs_masked = ner_probs * attention_mask_expanded\n",
    "        \n",
    "        max_features, _ = ner_probs_masked.max(dim=1)\n",
    "        \n",
    "        seq_lengths = attention_mask.sum(dim=1, keepdim=True).clamp(min=1)\n",
    "        avg_features = ner_probs_masked.sum(dim=1) / seq_lengths\n",
    "        \n",
    "        ner_features = 0.5 * max_features + 0.5 * avg_features\n",
    "        \n",
    "        attention_weights = self.ner_attention(ner_features)\n",
    "        ner_features_weighted = ner_features * attention_weights\n",
    "        \n",
    "        return ner_features_weighted\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, ner_labels=None, topic_labels=None, intent_labels=None):\n",
    "        outputs = self.phobert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        cls_output = sequence_output[:, 0, :]\n",
    "        \n",
    "        cls_expanded = cls_output.unsqueeze(1)\n",
    "        attn_output, _ = self.cross_attention(\n",
    "            query=cls_expanded,\n",
    "            key=sequence_output,\n",
    "            value=sequence_output,\n",
    "            key_padding_mask=(attention_mask == 0) if attention_mask is not None else None\n",
    "        )\n",
    "        cls_output = self.cross_attn_norm(cls_output + attn_output.squeeze(1))\n",
    "        cls_output_dropped = self.dropout_heavy(cls_output)\n",
    "        \n",
    "        # NER predictions\n",
    "        ner_hidden = self.ner_hidden(sequence_output)\n",
    "        ner_hidden = self.ner_norm(ner_hidden)\n",
    "        ner_hidden = F.gelu(ner_hidden)\n",
    "        ner_hidden = self.dropout(ner_hidden)\n",
    "        ner_logits = self.ner_classifier(ner_hidden)\n",
    "        \n",
    "        ner_features = self.extract_ner_features(ner_logits, attention_mask)\n",
    "        \n",
    "        # Topic prediction\n",
    "        topic_input = torch.cat([cls_output_dropped, ner_features], dim=-1)\n",
    "        topic_hidden = self.topic_input_proj(topic_input)\n",
    "        topic_hidden = topic_hidden + self.topic_layer1(topic_hidden)\n",
    "        topic_hidden = topic_hidden + self.topic_layer2(topic_hidden)\n",
    "        topic_logits = self.topic_classifier(topic_hidden)\n",
    "        \n",
    "        # Intent prediction\n",
    "        intent_hidden = self.intent_hidden(cls_output_dropped)\n",
    "        intent_hidden = self.intent_norm(intent_hidden)\n",
    "        intent_hidden = F.gelu(intent_hidden)\n",
    "        intent_hidden = self.dropout(intent_hidden)\n",
    "        intent_logits = self.intent_classifier(intent_hidden)\n",
    "        \n",
    "        return {\n",
    "            'loss': None,\n",
    "            'ner_logits': ner_logits,\n",
    "            'topic_logits': topic_logits,\n",
    "            'intent_logits': intent_logits\n",
    "        }\n",
    "\n",
    "print(\"Model class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed000e",
   "metadata": {},
   "source": [
    "## 5. Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3097df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /opt/spark-apps/phobert_multitask_final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on cpu!\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn model local (đã mount vào container)\n",
    "local_model_path = '/opt/spark-apps/phobert_multitask_final'\n",
    "\n",
    "print(f\"Loading model from: {local_model_path}\")\n",
    "\n",
    "# Load tokenizer và model\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "model = MultiTaskPhoBERT_WithFusion(\n",
    "    phobert_path=model_config['phobert_base'],\n",
    "    num_ner_labels=model_config['num_ner_labels'],\n",
    "    num_topic_labels=model_config['num_topic_labels'],\n",
    "    num_intent_labels=model_config['num_intent_labels'],\n",
    "    dropout=model_config['dropout']\n",
    ")\n",
    "\n",
    "# Load trọng số đã train\n",
    "state_dict = torch.load(f'{local_model_path}/pytorch_model.bin', map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Chuyển model sang GPU nếu có\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded successfully on {device}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a120284",
   "metadata": {},
   "source": [
    "## 6. Định Nghĩa Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8209b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction functions defined!\n"
     ]
    }
   ],
   "source": [
    "def normalize_text_with_underscore(text, annotator):\n",
    "    \"\"\"Chuẩn hóa văn bản tiếng Việt bằng VnCoreNLP\"\"\"\n",
    "    try:\n",
    "        sentences = annotator.tokenize(text)\n",
    "        \n",
    "        normalized_sentences = []\n",
    "        for sentence in sentences:\n",
    "            words = []\n",
    "            for word in sentence:\n",
    "                if isinstance(word, list):\n",
    "                    words.append('_'.join(word))\n",
    "                else:\n",
    "                    words.append(word)\n",
    "            normalized_sentences.append(' '.join(words))\n",
    "        \n",
    "        normalized_text = ' '.join(normalized_sentences)\n",
    "        return normalized_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error normalizing text: {e}\")\n",
    "        return text\n",
    "\n",
    "\n",
    "def predict_labels(text, model, tokenizer, label_mappings, device, annotator, max_length=256):\n",
    "    \"\"\"Dự đoán NER, Topic, Intent cho văn bản đầu vào\"\"\"\n",
    "    if not text or text.strip() == '':\n",
    "        return {\n",
    "            'normalized_text': '',\n",
    "            'ner_labels': 'O',\n",
    "            'topic_label': 'None',\n",
    "            'intent_label': 'Unknown'\n",
    "        }\n",
    "    \n",
    "    # Chuẩn hóa text bằng VnCoreNLP\n",
    "    normalized_text = normalize_text_with_underscore(text, annotator)\n",
    "    normalized_tokens = normalized_text.split()\n",
    "    num_tokens = len(normalized_tokens)\n",
    "    \n",
    "    # Tokenize cho PhoBERT\n",
    "    inputs = tokenizer(\n",
    "        normalized_text,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    if 'token_type_ids' in inputs:\n",
    "        inputs.pop('token_type_ids')\n",
    "    \n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Dự đoán\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    ner_logits = outputs['ner_logits']\n",
    "    topic_logits = outputs['topic_logits']\n",
    "    intent_logits = outputs['intent_logits']\n",
    "    \n",
    "    # NER predictions\n",
    "    ner_preds = torch.argmax(ner_logits, dim=-1)[0]\n",
    "    phobert_tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    # Align labels với VnCoreNLP tokens\n",
    "    ner_labels = []\n",
    "    token_idx = 0\n",
    "    \n",
    "    for word in normalized_tokens:\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        \n",
    "        while token_idx < len(phobert_tokens) and phobert_tokens[token_idx] == '<s>':\n",
    "            token_idx += 1\n",
    "        \n",
    "        if token_idx < len(phobert_tokens) and phobert_tokens[token_idx] not in ['</s>', '<pad>']:\n",
    "            label = label_mappings['ner_id2label'][str(ner_preds[token_idx].item())]\n",
    "            ner_labels.append(label)\n",
    "            token_idx += len(word_tokens)\n",
    "        else:\n",
    "            ner_labels.append('O')\n",
    "            break\n",
    "    \n",
    "    # Topic predictions (multi-label, threshold=0.5)\n",
    "    topic_probs = torch.sigmoid(topic_logits)[0]\n",
    "    topic_preds = (topic_probs > 0.5).nonzero(as_tuple=True)[0].cpu().tolist()\n",
    "    \n",
    "    if len(topic_preds) > 0:\n",
    "        topic_labels = [label_mappings['topic_id2label'][str(idx)] for idx in topic_preds]\n",
    "        topic_label = '|'.join(topic_labels)\n",
    "    else:\n",
    "        topic_label = 'None'\n",
    "    \n",
    "    # Intent prediction (single-label)\n",
    "    intent_pred = torch.argmax(intent_logits, dim=-1).item()\n",
    "    intent_label = label_mappings['intent_id2label'][str(intent_pred)]\n",
    "    \n",
    "    return {\n",
    "        'normalized_text': normalized_text,\n",
    "        'ner_labels': ' '.join(ner_labels),\n",
    "        'topic_label': topic_label,\n",
    "        'intent_label': intent_label\n",
    "    }\n",
    "\n",
    "print(\"Prediction functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24a20d",
   "metadata": {},
   "source": [
    "## 7. Apply Model trên Toàn Bộ Dữ Liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272a9733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 0 articles đã được xử lý trước đó\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xử lý toàn bộ 3295 articles\n",
      "\n",
      "=== Collecting data to process ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã collect 3295 articles về driver\n",
      "\n",
      "=== Processing articles with model ===\n",
      "[15:15:54] Processed 0/3295 | Elapsed: 0.0s | ETA: 0.0s\n",
      "[15:15:57] Processed 10/3295 | Elapsed: 2.6s | ETA: 790.1s\n",
      "[15:15:59] Processed 20/3295 | Elapsed: 4.7s | ETA: 734.7s\n",
      "[15:16:01] Processed 30/3295 | Elapsed: 6.8s | ETA: 712.8s\n",
      "[15:16:03] Processed 40/3295 | Elapsed: 8.9s | ETA: 704.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 50\n",
      "[15:16:09] Processed 50/3295 | Elapsed: 14.7s | ETA: 938.3s\n",
      "[15:16:11] Processed 60/3295 | Elapsed: 16.8s | ETA: 890.6s\n",
      "[15:16:13] Processed 70/3295 | Elapsed: 18.9s | ETA: 858.9s\n",
      "[15:16:15] Processed 80/3295 | Elapsed: 21.1s | ETA: 838.0s\n",
      "[15:16:17] Processed 90/3295 | Elapsed: 23.2s | ETA: 818.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 100\n",
      "[15:16:21] Processed 100/3295 | Elapsed: 26.8s | ETA: 847.6s\n",
      "[15:16:23] Processed 110/3295 | Elapsed: 28.9s | ETA: 829.3s\n",
      "[15:16:25] Processed 120/3295 | Elapsed: 31.0s | ETA: 813.5s\n",
      "[15:16:27] Processed 130/3295 | Elapsed: 33.0s | ETA: 797.8s\n",
      "[15:16:29] Processed 140/3295 | Elapsed: 35.0s | ETA: 783.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 150\n",
      "[15:16:33] Processed 150/3295 | Elapsed: 38.7s | ETA: 805.4s\n",
      "[15:16:35] Processed 160/3295 | Elapsed: 40.7s | ETA: 792.4s\n",
      "[15:16:37] Processed 170/3295 | Elapsed: 42.7s | ETA: 780.2s\n",
      "[15:16:39] Processed 180/3295 | Elapsed: 44.8s | ETA: 770.9s\n",
      "[15:16:41] Processed 190/3295 | Elapsed: 46.9s | ETA: 761.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 200\n",
      "[15:16:44] Processed 200/3295 | Elapsed: 50.2s | ETA: 772.9s\n",
      "[15:16:46] Processed 210/3295 | Elapsed: 52.3s | ETA: 765.1s\n",
      "[15:16:48] Processed 220/3295 | Elapsed: 54.5s | ETA: 758.0s\n",
      "[15:16:50] Processed 230/3295 | Elapsed: 56.5s | ETA: 749.9s\n",
      "[15:16:52] Processed 240/3295 | Elapsed: 58.6s | ETA: 742.8s\n",
      "✓ Saved batch: 50 records | Total processed: 250\n",
      "[15:16:56] Processed 250/3295 | Elapsed: 61.7s | ETA: 748.5s\n",
      "[15:16:58] Processed 260/3295 | Elapsed: 63.7s | ETA: 741.1s\n",
      "[15:17:00] Processed 270/3295 | Elapsed: 65.8s | ETA: 733.9s\n",
      "[15:17:02] Processed 280/3295 | Elapsed: 67.8s | ETA: 727.1s\n",
      "[15:17:04] Processed 290/3295 | Elapsed: 69.8s | ETA: 720.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 300\n",
      "[15:17:07] Processed 300/3295 | Elapsed: 73.0s | ETA: 725.9s\n",
      "[15:17:09] Processed 310/3295 | Elapsed: 75.0s | ETA: 719.6s\n",
      "[15:17:11] Processed 320/3295 | Elapsed: 76.9s | ETA: 713.1s\n",
      "[15:17:13] Processed 330/3295 | Elapsed: 78.9s | ETA: 706.7s\n",
      "[15:17:15] Processed 340/3295 | Elapsed: 81.0s | ETA: 701.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 350\n",
      "[15:17:18] Processed 350/3295 | Elapsed: 84.0s | ETA: 705.0s\n",
      "[15:17:20] Processed 360/3295 | Elapsed: 86.1s | ETA: 700.4s\n",
      "[15:17:22] Processed 370/3295 | Elapsed: 88.3s | ETA: 696.0s\n",
      "[15:17:24] Processed 380/3295 | Elapsed: 90.4s | ETA: 691.6s\n",
      "[15:17:26] Processed 390/3295 | Elapsed: 92.5s | ETA: 687.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 400\n",
      "[15:17:30] Processed 400/3295 | Elapsed: 95.7s | ETA: 690.7s\n",
      "[15:17:32] Processed 410/3295 | Elapsed: 97.7s | ETA: 685.5s\n",
      "[15:17:34] Processed 420/3295 | Elapsed: 99.9s | ETA: 682.1s\n",
      "[15:17:36] Processed 430/3295 | Elapsed: 101.9s | ETA: 677.2s\n",
      "[15:17:38] Processed 440/3295 | Elapsed: 103.8s | ETA: 672.3s\n",
      "✓ Saved batch: 50 records | Total processed: 450\n",
      "[15:17:41] Processed 450/3295 | Elapsed: 106.8s | ETA: 674.0s\n",
      "[15:17:43] Processed 460/3295 | Elapsed: 108.9s | ETA: 669.7s\n",
      "[15:17:45] Processed 470/3295 | Elapsed: 111.0s | ETA: 665.8s\n",
      "[15:17:47] Processed 480/3295 | Elapsed: 113.0s | ETA: 661.5s\n",
      "[15:17:49] Processed 490/3295 | Elapsed: 115.2s | ETA: 658.1s\n",
      "✓ Saved batch: 50 records | Total processed: 500\n",
      "[15:17:52] Processed 500/3295 | Elapsed: 118.4s | ETA: 660.4s\n",
      "[15:17:54] Processed 510/3295 | Elapsed: 120.4s | ETA: 656.4s\n",
      "[15:17:56] Processed 520/3295 | Elapsed: 122.5s | ETA: 652.5s\n",
      "[15:17:58] Processed 530/3295 | Elapsed: 124.6s | ETA: 648.6s\n",
      "[15:18:00] Processed 540/3295 | Elapsed: 126.6s | ETA: 644.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 550\n",
      "[15:18:04] Processed 550/3295 | Elapsed: 129.8s | ETA: 646.8s\n",
      "[15:18:06] Processed 560/3295 | Elapsed: 131.8s | ETA: 642.3s\n",
      "[15:18:08] Processed 570/3295 | Elapsed: 133.7s | ETA: 638.3s\n",
      "[15:18:10] Processed 580/3295 | Elapsed: 135.8s | ETA: 634.4s\n",
      "[15:18:12] Processed 590/3295 | Elapsed: 137.7s | ETA: 630.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 600\n",
      "[15:18:15] Processed 600/3295 | Elapsed: 140.9s | ETA: 632.0s\n",
      "[15:18:17] Processed 610/3295 | Elapsed: 143.0s | ETA: 628.2s\n",
      "[15:18:19] Processed 620/3295 | Elapsed: 145.1s | ETA: 624.8s\n",
      "[15:18:21] Processed 630/3295 | Elapsed: 147.1s | ETA: 621.1s\n",
      "[15:18:23] Processed 640/3295 | Elapsed: 149.1s | ETA: 617.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 650\n",
      "[15:18:26] Processed 650/3295 | Elapsed: 152.3s | ETA: 618.8s\n",
      "[15:18:28] Processed 660/3295 | Elapsed: 154.4s | ETA: 615.4s\n",
      "[15:18:30] Processed 670/3295 | Elapsed: 156.5s | ETA: 612.0s\n",
      "[15:18:32] Processed 680/3295 | Elapsed: 158.6s | ETA: 608.8s\n",
      "[15:18:35] Processed 690/3295 | Elapsed: 160.6s | ETA: 605.6s\n",
      "✓ Saved batch: 50 records | Total processed: 700\n",
      "[15:18:37] Processed 700/3295 | Elapsed: 163.4s | ETA: 604.8s\n",
      "[15:18:39] Processed 710/3295 | Elapsed: 165.4s | ETA: 601.3s\n",
      "[15:18:41] Processed 720/3295 | Elapsed: 167.4s | ETA: 597.9s\n",
      "[15:18:43] Processed 730/3295 | Elapsed: 169.5s | ETA: 594.6s\n",
      "[15:18:45] Processed 740/3295 | Elapsed: 171.6s | ETA: 591.7s\n",
      "✓ Saved batch: 50 records | Total processed: 750\n",
      "[15:18:48] Processed 750/3295 | Elapsed: 174.4s | ETA: 591.1s\n",
      "[15:18:50] Processed 760/3295 | Elapsed: 176.5s | ETA: 587.9s\n",
      "[15:18:53] Processed 770/3295 | Elapsed: 178.6s | ETA: 585.1s\n",
      "[15:18:55] Processed 780/3295 | Elapsed: 180.7s | ETA: 582.0s\n",
      "[15:18:57] Processed 790/3295 | Elapsed: 182.8s | ETA: 578.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 800\n",
      "[15:19:00] Processed 800/3295 | Elapsed: 185.9s | ETA: 579.0s\n",
      "[15:19:02] Processed 810/3295 | Elapsed: 188.0s | ETA: 576.1s\n",
      "[15:19:04] Processed 820/3295 | Elapsed: 190.1s | ETA: 573.1s\n",
      "[15:19:06] Processed 830/3295 | Elapsed: 192.2s | ETA: 570.1s\n",
      "[15:19:08] Processed 840/3295 | Elapsed: 194.2s | ETA: 566.9s\n",
      "✓ Saved batch: 50 records | Total processed: 850\n",
      "[15:19:11] Processed 850/3295 | Elapsed: 197.2s | ETA: 566.6s\n",
      "[15:19:13] Processed 860/3295 | Elapsed: 199.2s | ETA: 563.4s\n",
      "[15:19:15] Processed 870/3295 | Elapsed: 201.3s | ETA: 560.5s\n",
      "[15:19:17] Processed 880/3295 | Elapsed: 203.3s | ETA: 557.4s\n",
      "[15:19:19] Processed 890/3295 | Elapsed: 205.4s | ETA: 554.4s\n",
      "✓ Saved batch: 50 records | Total processed: 900\n",
      "[15:19:22] Processed 900/3295 | Elapsed: 208.4s | ETA: 554.0s\n",
      "[15:19:24] Processed 910/3295 | Elapsed: 210.5s | ETA: 551.0s\n",
      "[15:19:26] Processed 920/3295 | Elapsed: 212.5s | ETA: 548.0s\n",
      "[15:19:28] Processed 930/3295 | Elapsed: 214.5s | ETA: 544.9s\n",
      "[15:19:30] Processed 940/3295 | Elapsed: 216.6s | ETA: 542.0s\n",
      "✓ Saved batch: 50 records | Total processed: 950\n",
      "[15:19:33] Processed 950/3295 | Elapsed: 219.5s | ETA: 541.3s\n",
      "[15:19:35] Processed 960/3295 | Elapsed: 221.6s | ETA: 538.5s\n",
      "[15:19:38] Processed 970/3295 | Elapsed: 223.7s | ETA: 535.6s\n",
      "[15:19:40] Processed 980/3295 | Elapsed: 225.7s | ETA: 532.7s\n",
      "[15:19:42] Processed 990/3295 | Elapsed: 227.7s | ETA: 529.7s\n",
      "✓ Saved batch: 50 records | Total processed: 1000\n",
      "[15:19:44] Processed 1000/3295 | Elapsed: 230.6s | ETA: 528.7s\n",
      "[15:19:46] Processed 1010/3295 | Elapsed: 232.6s | ETA: 525.7s\n",
      "[15:19:48] Processed 1020/3295 | Elapsed: 234.6s | ETA: 522.7s\n",
      "[15:19:51] Processed 1030/3295 | Elapsed: 236.7s | ETA: 519.9s\n",
      "[15:19:53] Processed 1040/3295 | Elapsed: 238.8s | ETA: 517.3s\n",
      "✓ Saved batch: 50 records | Total processed: 1050\n",
      "[15:19:55] Processed 1050/3295 | Elapsed: 241.6s | ETA: 516.1s\n",
      "[15:19:57] Processed 1060/3295 | Elapsed: 243.6s | ETA: 513.2s\n",
      "[15:19:59] Processed 1070/3295 | Elapsed: 245.6s | ETA: 510.3s\n",
      "[15:20:02] Processed 1080/3295 | Elapsed: 247.7s | ETA: 507.5s\n",
      "[15:20:04] Processed 1090/3295 | Elapsed: 249.7s | ETA: 504.7s\n",
      "✓ Saved batch: 50 records | Total processed: 1100\n",
      "[15:20:06] Processed 1100/3295 | Elapsed: 252.4s | ETA: 503.2s\n",
      "[15:20:08] Processed 1110/3295 | Elapsed: 254.4s | ETA: 500.3s\n",
      "[15:20:10] Processed 1120/3295 | Elapsed: 256.4s | ETA: 497.5s\n",
      "[15:20:12] Processed 1130/3295 | Elapsed: 258.5s | ETA: 494.7s\n",
      "[15:20:14] Processed 1140/3295 | Elapsed: 260.5s | ETA: 492.1s\n",
      "✓ Saved batch: 50 records | Total processed: 1150\n",
      "[15:20:17] Processed 1150/3295 | Elapsed: 263.1s | ETA: 490.4s\n",
      "[15:20:19] Processed 1160/3295 | Elapsed: 265.2s | ETA: 487.6s\n",
      "[15:20:21] Processed 1170/3295 | Elapsed: 267.2s | ETA: 484.8s\n",
      "[15:20:23] Processed 1180/3295 | Elapsed: 269.2s | ETA: 482.2s\n",
      "[15:20:25] Processed 1190/3295 | Elapsed: 271.3s | ETA: 479.5s\n",
      "✓ Saved batch: 50 records | Total processed: 1200\n",
      "[15:20:28] Processed 1200/3295 | Elapsed: 273.8s | ETA: 477.7s\n",
      "[15:20:30] Processed 1210/3295 | Elapsed: 275.9s | ETA: 474.9s\n",
      "[15:20:32] Processed 1220/3295 | Elapsed: 277.9s | ETA: 472.3s\n",
      "[15:20:34] Processed 1230/3295 | Elapsed: 279.9s | ETA: 469.6s\n",
      "[15:20:36] Processed 1240/3295 | Elapsed: 282.0s | ETA: 466.9s\n",
      "✓ Saved batch: 50 records | Total processed: 1250\n",
      "[15:20:39] Processed 1250/3295 | Elapsed: 284.8s | ETA: 465.5s\n",
      "[15:20:41] Processed 1260/3295 | Elapsed: 286.8s | ETA: 462.9s\n",
      "[15:20:43] Processed 1270/3295 | Elapsed: 289.0s | ETA: 460.4s\n",
      "[15:20:45] Processed 1280/3295 | Elapsed: 291.1s | ETA: 457.9s\n",
      "[15:20:47] Processed 1290/3295 | Elapsed: 293.3s | ETA: 455.5s\n",
      "✓ Saved batch: 50 records | Total processed: 1300\n",
      "[15:20:50] Processed 1300/3295 | Elapsed: 296.2s | ETA: 454.2s\n",
      "[15:20:52] Processed 1310/3295 | Elapsed: 298.2s | ETA: 451.5s\n",
      "[15:20:54] Processed 1320/3295 | Elapsed: 300.3s | ETA: 448.9s\n",
      "[15:20:56] Processed 1330/3295 | Elapsed: 302.3s | ETA: 446.4s\n",
      "[15:20:58] Processed 1340/3295 | Elapsed: 304.3s | ETA: 443.7s\n",
      "✓ Saved batch: 50 records | Total processed: 1350\n",
      "[15:21:01] Processed 1350/3295 | Elapsed: 307.2s | ETA: 442.3s\n",
      "[15:21:03] Processed 1360/3295 | Elapsed: 309.3s | ETA: 439.7s\n",
      "[15:21:05] Processed 1370/3295 | Elapsed: 311.3s | ETA: 437.1s\n",
      "[15:21:07] Processed 1380/3295 | Elapsed: 313.4s | ETA: 434.5s\n",
      "[15:21:09] Processed 1390/3295 | Elapsed: 315.4s | ETA: 431.9s\n",
      "✓ Saved batch: 50 records | Total processed: 1400\n",
      "[15:21:12] Processed 1400/3295 | Elapsed: 318.2s | ETA: 430.5s\n",
      "[15:21:14] Processed 1410/3295 | Elapsed: 320.2s | ETA: 427.8s\n",
      "[15:21:16] Processed 1420/3295 | Elapsed: 322.3s | ETA: 425.3s\n",
      "[15:21:18] Processed 1430/3295 | Elapsed: 324.3s | ETA: 422.7s\n",
      "[15:21:20] Processed 1440/3295 | Elapsed: 326.3s | ETA: 420.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 1450\n",
      "[15:21:23] Processed 1450/3295 | Elapsed: 329.5s | ETA: 418.9s\n",
      "[15:21:25] Processed 1460/3295 | Elapsed: 331.5s | ETA: 416.4s\n",
      "[15:21:27] Processed 1470/3295 | Elapsed: 333.6s | ETA: 413.9s\n",
      "[15:21:29] Processed 1480/3295 | Elapsed: 335.6s | ETA: 411.2s\n",
      "[15:21:31] Processed 1490/3295 | Elapsed: 337.6s | ETA: 408.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 1500\n",
      "[15:21:35] Processed 1500/3295 | Elapsed: 340.8s | ETA: 407.6s\n",
      "[15:21:37] Processed 1510/3295 | Elapsed: 342.8s | ETA: 405.0s\n",
      "[15:21:39] Processed 1520/3295 | Elapsed: 344.9s | ETA: 402.5s\n",
      "[15:21:41] Processed 1530/3295 | Elapsed: 346.9s | ETA: 399.9s\n",
      "[15:21:43] Processed 1540/3295 | Elapsed: 349.0s | ETA: 397.5s\n",
      "✓ Saved batch: 50 records | Total processed: 1550\n",
      "[15:21:46] Processed 1550/3295 | Elapsed: 352.1s | ETA: 396.2s\n",
      "[15:21:48] Processed 1560/3295 | Elapsed: 354.2s | ETA: 393.7s\n",
      "[15:21:50] Processed 1570/3295 | Elapsed: 356.2s | ETA: 391.1s\n",
      "[15:21:52] Processed 1580/3295 | Elapsed: 358.4s | ETA: 388.7s\n",
      "[15:21:54] Processed 1590/3295 | Elapsed: 360.5s | ETA: 386.3s\n",
      "✓ Saved batch: 50 records | Total processed: 1600\n",
      "[15:21:57] Processed 1600/3295 | Elapsed: 363.1s | ETA: 384.5s\n",
      "[15:21:59] Processed 1610/3295 | Elapsed: 365.2s | ETA: 382.0s\n",
      "[15:22:01] Processed 1620/3295 | Elapsed: 367.3s | ETA: 379.5s\n",
      "[15:22:03] Processed 1630/3295 | Elapsed: 369.3s | ETA: 377.0s\n",
      "[15:22:05] Processed 1640/3295 | Elapsed: 371.4s | ETA: 374.5s\n",
      "✓ Saved batch: 50 records | Total processed: 1650\n",
      "[15:22:08] Processed 1650/3295 | Elapsed: 374.0s | ETA: 372.6s\n",
      "[15:22:10] Processed 1660/3295 | Elapsed: 376.0s | ETA: 370.1s\n",
      "[15:22:12] Processed 1670/3295 | Elapsed: 378.2s | ETA: 367.8s\n",
      "[15:22:14] Processed 1680/3295 | Elapsed: 380.4s | ETA: 365.5s\n",
      "[15:22:16] Processed 1690/3295 | Elapsed: 382.4s | ETA: 363.0s\n",
      "✓ Saved batch: 50 records | Total processed: 1700\n",
      "[15:22:19] Processed 1700/3295 | Elapsed: 385.0s | ETA: 361.0s\n",
      "[15:22:21] Processed 1710/3295 | Elapsed: 387.0s | ETA: 358.5s\n",
      "[15:22:23] Processed 1720/3295 | Elapsed: 389.1s | ETA: 356.0s\n",
      "[15:22:25] Processed 1730/3295 | Elapsed: 391.2s | ETA: 353.7s\n",
      "[15:22:27] Processed 1740/3295 | Elapsed: 393.3s | ETA: 351.3s\n",
      "✓ Saved batch: 50 records | Total processed: 1750\n",
      "[15:22:30] Processed 1750/3295 | Elapsed: 395.9s | ETA: 349.3s\n",
      "[15:22:32] Processed 1760/3295 | Elapsed: 398.0s | ETA: 346.9s\n",
      "[15:22:34] Processed 1770/3295 | Elapsed: 400.0s | ETA: 344.4s\n",
      "[15:22:36] Processed 1780/3295 | Elapsed: 402.0s | ETA: 342.0s\n",
      "[15:22:38] Processed 1790/3295 | Elapsed: 404.0s | ETA: 339.5s\n",
      "✓ Saved batch: 50 records | Total processed: 1800\n",
      "[15:22:41] Processed 1800/3295 | Elapsed: 406.9s | ETA: 337.7s\n",
      "[15:22:43] Processed 1810/3295 | Elapsed: 409.0s | ETA: 335.4s\n",
      "[15:22:45] Processed 1820/3295 | Elapsed: 411.0s | ETA: 332.9s\n",
      "[15:22:47] Processed 1830/3295 | Elapsed: 413.0s | ETA: 330.5s\n",
      "[15:22:49] Processed 1840/3295 | Elapsed: 415.0s | ETA: 328.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 1850\n",
      "[15:22:52] Processed 1850/3295 | Elapsed: 418.5s | ETA: 326.7s\n",
      "[15:22:54] Processed 1860/3295 | Elapsed: 420.6s | ETA: 324.3s\n",
      "[15:22:56] Processed 1870/3295 | Elapsed: 422.6s | ETA: 321.9s\n",
      "[15:22:59] Processed 1880/3295 | Elapsed: 424.8s | ETA: 319.5s\n",
      "[15:23:01] Processed 1890/3295 | Elapsed: 426.8s | ETA: 317.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 1900\n",
      "[15:23:04] Processed 1900/3295 | Elapsed: 430.1s | ETA: 315.6s\n",
      "[15:23:06] Processed 1910/3295 | Elapsed: 432.1s | ETA: 313.1s\n",
      "[15:23:08] Processed 1920/3295 | Elapsed: 434.1s | ETA: 310.7s\n",
      "[15:23:10] Processed 1930/3295 | Elapsed: 436.1s | ETA: 308.3s\n",
      "[15:23:12] Processed 1940/3295 | Elapsed: 438.2s | ETA: 305.9s\n",
      "✓ Saved batch: 50 records | Total processed: 1950\n",
      "[15:23:15] Processed 1950/3295 | Elapsed: 441.2s | ETA: 304.1s\n",
      "[15:23:17] Processed 1960/3295 | Elapsed: 443.2s | ETA: 301.7s\n",
      "[15:23:19] Processed 1970/3295 | Elapsed: 445.2s | ETA: 299.3s\n",
      "[15:23:21] Processed 1980/3295 | Elapsed: 447.3s | ETA: 296.9s\n",
      "[15:23:23] Processed 1990/3295 | Elapsed: 449.4s | ETA: 294.5s\n",
      "✓ Saved batch: 50 records | Total processed: 2000\n",
      "[15:23:26] Processed 2000/3295 | Elapsed: 452.1s | ETA: 292.6s\n",
      "[15:23:28] Processed 2010/3295 | Elapsed: 454.1s | ETA: 290.2s\n",
      "[15:23:30] Processed 2020/3295 | Elapsed: 456.1s | ETA: 287.7s\n",
      "[15:23:32] Processed 2030/3295 | Elapsed: 458.1s | ETA: 285.3s\n",
      "[15:23:34] Processed 2040/3295 | Elapsed: 460.2s | ETA: 283.0s\n",
      "✓ Saved batch: 50 records | Total processed: 2050\n",
      "[15:23:37] Processed 2050/3295 | Elapsed: 462.9s | ETA: 281.0s\n",
      "[15:23:39] Processed 2060/3295 | Elapsed: 465.0s | ETA: 278.6s\n",
      "[15:23:41] Processed 2070/3295 | Elapsed: 467.0s | ETA: 276.2s\n",
      "[15:23:43] Processed 2080/3295 | Elapsed: 469.0s | ETA: 273.8s\n",
      "[15:23:45] Processed 2090/3295 | Elapsed: 471.2s | ETA: 271.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2100\n",
      "[15:23:48] Processed 2100/3295 | Elapsed: 474.4s | ETA: 269.8s\n",
      "[15:23:50] Processed 2110/3295 | Elapsed: 476.4s | ETA: 267.4s\n",
      "[15:23:52] Processed 2120/3295 | Elapsed: 478.5s | ETA: 265.1s\n",
      "[15:23:54] Processed 2130/3295 | Elapsed: 480.6s | ETA: 262.8s\n",
      "[15:23:57] Processed 2140/3295 | Elapsed: 482.6s | ETA: 260.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2150\n",
      "[15:24:01] Processed 2150/3295 | Elapsed: 486.7s | ETA: 259.1s\n",
      "[15:24:03] Processed 2160/3295 | Elapsed: 488.9s | ETA: 256.8s\n",
      "[15:24:05] Processed 2170/3295 | Elapsed: 491.0s | ETA: 254.5s\n",
      "[15:24:07] Processed 2180/3295 | Elapsed: 493.1s | ETA: 252.1s\n",
      "[15:24:09] Processed 2190/3295 | Elapsed: 495.1s | ETA: 249.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2200\n",
      "[15:24:13] Processed 2200/3295 | Elapsed: 498.8s | ETA: 248.2s\n",
      "[15:24:15] Processed 2210/3295 | Elapsed: 500.9s | ETA: 245.8s\n",
      "[15:24:17] Processed 2220/3295 | Elapsed: 502.8s | ETA: 243.4s\n",
      "[15:24:19] Processed 2230/3295 | Elapsed: 504.9s | ETA: 241.0s\n",
      "[15:24:21] Processed 2240/3295 | Elapsed: 506.9s | ETA: 238.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2250\n",
      "[15:24:25] Processed 2250/3295 | Elapsed: 510.7s | ETA: 237.1s\n",
      "[15:24:27] Processed 2260/3295 | Elapsed: 512.7s | ETA: 234.7s\n",
      "[15:24:29] Processed 2270/3295 | Elapsed: 514.7s | ETA: 232.3s\n",
      "[15:24:31] Processed 2280/3295 | Elapsed: 516.7s | ETA: 229.9s\n",
      "[15:24:33] Processed 2290/3295 | Elapsed: 518.7s | ETA: 227.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2300\n",
      "[15:24:36] Processed 2300/3295 | Elapsed: 521.9s | ETA: 225.7s\n",
      "[15:24:38] Processed 2310/3295 | Elapsed: 524.0s | ETA: 223.3s\n",
      "[15:24:40] Processed 2320/3295 | Elapsed: 526.1s | ETA: 221.0s\n",
      "[15:24:42] Processed 2330/3295 | Elapsed: 528.1s | ETA: 218.6s\n",
      "[15:24:44] Processed 2340/3295 | Elapsed: 530.4s | ETA: 216.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2350\n",
      "[15:24:47] Processed 2350/3295 | Elapsed: 533.5s | ETA: 214.5s\n",
      "[15:24:49] Processed 2360/3295 | Elapsed: 535.5s | ETA: 212.1s\n",
      "[15:24:51] Processed 2370/3295 | Elapsed: 537.6s | ETA: 209.7s\n",
      "[15:24:54] Processed 2380/3295 | Elapsed: 539.7s | ETA: 207.4s\n",
      "[15:24:56] Processed 2390/3295 | Elapsed: 541.7s | ETA: 205.0s\n",
      "✓ Saved batch: 50 records | Total processed: 2400\n",
      "[15:24:59] Processed 2400/3295 | Elapsed: 544.8s | ETA: 203.1s\n",
      "[15:25:01] Processed 2410/3295 | Elapsed: 546.8s | ETA: 200.7s\n",
      "[15:25:03] Processed 2420/3295 | Elapsed: 548.9s | ETA: 198.4s\n",
      "[15:25:05] Processed 2430/3295 | Elapsed: 551.0s | ETA: 196.0s\n",
      "[15:25:07] Processed 2440/3295 | Elapsed: 553.0s | ETA: 193.7s\n",
      "✓ Saved batch: 50 records | Total processed: 2450\n",
      "[15:25:10] Processed 2450/3295 | Elapsed: 555.8s | ETA: 191.6s\n",
      "[15:25:12] Processed 2460/3295 | Elapsed: 557.9s | ETA: 189.3s\n",
      "[15:25:14] Processed 2470/3295 | Elapsed: 560.0s | ETA: 187.0s\n",
      "[15:25:16] Processed 2480/3295 | Elapsed: 562.1s | ETA: 184.7s\n",
      "[15:25:18] Processed 2490/3295 | Elapsed: 564.1s | ETA: 182.3s\n",
      "✓ Saved batch: 50 records | Total processed: 2500\n",
      "[15:25:21] Processed 2500/3295 | Elapsed: 566.7s | ETA: 180.1s\n",
      "[15:25:23] Processed 2510/3295 | Elapsed: 568.8s | ETA: 177.8s\n",
      "[15:25:25] Processed 2520/3295 | Elapsed: 570.8s | ETA: 175.5s\n",
      "[15:25:27] Processed 2530/3295 | Elapsed: 572.9s | ETA: 173.1s\n",
      "[15:25:29] Processed 2540/3295 | Elapsed: 574.9s | ETA: 170.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2550\n",
      "[15:25:32] Processed 2550/3295 | Elapsed: 577.9s | ETA: 168.8s\n",
      "[15:25:34] Processed 2560/3295 | Elapsed: 580.0s | ETA: 166.5s\n",
      "[15:25:36] Processed 2570/3295 | Elapsed: 582.1s | ETA: 164.1s\n",
      "[15:25:38] Processed 2580/3295 | Elapsed: 584.2s | ETA: 161.8s\n",
      "[15:25:40] Processed 2590/3295 | Elapsed: 586.2s | ETA: 159.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2600\n",
      "[15:25:43] Processed 2600/3295 | Elapsed: 589.4s | ETA: 157.5s\n",
      "[15:25:45] Processed 2610/3295 | Elapsed: 591.6s | ETA: 155.2s\n",
      "[15:25:47] Processed 2620/3295 | Elapsed: 593.6s | ETA: 152.9s\n",
      "[15:25:50] Processed 2630/3295 | Elapsed: 595.7s | ETA: 150.6s\n",
      "[15:25:52] Processed 2640/3295 | Elapsed: 597.7s | ETA: 148.2s\n",
      "✓ Saved batch: 50 records | Total processed: 2650\n",
      "[15:25:55] Processed 2650/3295 | Elapsed: 600.6s | ETA: 146.1s\n",
      "[15:25:57] Processed 2660/3295 | Elapsed: 602.7s | ETA: 143.8s\n",
      "[15:25:59] Processed 2670/3295 | Elapsed: 604.7s | ETA: 141.5s\n",
      "[15:26:01] Processed 2680/3295 | Elapsed: 606.7s | ETA: 139.2s\n",
      "[15:26:03] Processed 2690/3295 | Elapsed: 608.7s | ETA: 136.9s\n",
      "✓ Saved batch: 50 records | Total processed: 2700\n",
      "[15:26:06] Processed 2700/3295 | Elapsed: 611.7s | ETA: 134.7s\n",
      "[15:26:08] Processed 2710/3295 | Elapsed: 613.7s | ETA: 132.4s\n",
      "[15:26:10] Processed 2720/3295 | Elapsed: 615.7s | ETA: 130.1s\n",
      "[15:26:12] Processed 2730/3295 | Elapsed: 617.7s | ETA: 127.8s\n",
      "[15:26:14] Processed 2740/3295 | Elapsed: 619.8s | ETA: 125.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2750\n",
      "[15:26:17] Processed 2750/3295 | Elapsed: 623.4s | ETA: 123.5s\n",
      "[15:26:19] Processed 2760/3295 | Elapsed: 625.5s | ETA: 121.2s\n",
      "[15:26:21] Processed 2770/3295 | Elapsed: 627.5s | ETA: 118.9s\n",
      "[15:26:24] Processed 2780/3295 | Elapsed: 629.7s | ETA: 116.6s\n",
      "[15:26:26] Processed 2790/3295 | Elapsed: 631.7s | ETA: 114.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 2800\n",
      "[15:26:29] Processed 2800/3295 | Elapsed: 635.4s | ETA: 112.3s\n",
      "[15:26:31] Processed 2810/3295 | Elapsed: 637.3s | ETA: 110.0s\n",
      "[15:26:33] Processed 2820/3295 | Elapsed: 639.3s | ETA: 107.6s\n",
      "[15:26:35] Processed 2830/3295 | Elapsed: 641.3s | ETA: 105.3s\n",
      "[15:26:37] Processed 2840/3295 | Elapsed: 643.4s | ETA: 103.0s\n",
      "✓ Saved batch: 50 records | Total processed: 2850\n",
      "[15:26:40] Processed 2850/3295 | Elapsed: 646.3s | ETA: 100.9s\n",
      "[15:26:42] Processed 2860/3295 | Elapsed: 648.3s | ETA: 98.6s\n",
      "[15:26:44] Processed 2870/3295 | Elapsed: 650.5s | ETA: 96.3s\n",
      "[15:26:46] Processed 2880/3295 | Elapsed: 652.5s | ETA: 94.0s\n",
      "[15:26:48] Processed 2890/3295 | Elapsed: 654.5s | ETA: 91.7s\n",
      "✓ Saved batch: 50 records | Total processed: 2900\n",
      "[15:26:51] Processed 2900/3295 | Elapsed: 657.5s | ETA: 89.5s\n",
      "[15:26:54] Processed 2910/3295 | Elapsed: 659.7s | ETA: 87.2s\n",
      "[15:26:56] Processed 2920/3295 | Elapsed: 661.7s | ETA: 85.0s\n",
      "[15:26:58] Processed 2930/3295 | Elapsed: 663.8s | ETA: 82.7s\n",
      "[15:27:00] Processed 2940/3295 | Elapsed: 665.8s | ETA: 80.4s\n",
      "✓ Saved batch: 50 records | Total processed: 2950\n",
      "[15:27:02] Processed 2950/3295 | Elapsed: 668.6s | ETA: 78.2s\n",
      "[15:27:05] Processed 2960/3295 | Elapsed: 670.7s | ETA: 75.9s\n",
      "[15:27:07] Processed 2970/3295 | Elapsed: 672.7s | ETA: 73.6s\n",
      "[15:27:09] Processed 2980/3295 | Elapsed: 674.8s | ETA: 71.3s\n",
      "[15:27:11] Processed 2990/3295 | Elapsed: 676.8s | ETA: 69.0s\n",
      "✓ Saved batch: 50 records | Total processed: 3000\n",
      "[15:27:13] Processed 3000/3295 | Elapsed: 679.4s | ETA: 66.8s\n",
      "[15:27:15] Processed 3010/3295 | Elapsed: 681.5s | ETA: 64.5s\n",
      "[15:27:17] Processed 3020/3295 | Elapsed: 683.4s | ETA: 62.2s\n",
      "[15:27:19] Processed 3030/3295 | Elapsed: 685.5s | ETA: 59.9s\n",
      "[15:27:21] Processed 3040/3295 | Elapsed: 687.4s | ETA: 57.6s\n",
      "✓ Saved batch: 50 records | Total processed: 3050\n",
      "[15:27:24] Processed 3050/3295 | Elapsed: 690.1s | ETA: 55.4s\n",
      "[15:27:26] Processed 3060/3295 | Elapsed: 692.2s | ETA: 53.1s\n",
      "[15:27:28] Processed 3070/3295 | Elapsed: 694.3s | ETA: 50.9s\n",
      "[15:27:30] Processed 3080/3295 | Elapsed: 696.2s | ETA: 48.6s\n",
      "[15:27:32] Processed 3090/3295 | Elapsed: 698.2s | ETA: 46.3s\n",
      "✓ Saved batch: 50 records | Total processed: 3100\n",
      "[15:27:35] Processed 3100/3295 | Elapsed: 700.8s | ETA: 44.1s\n",
      "[15:27:37] Processed 3110/3295 | Elapsed: 702.8s | ETA: 41.8s\n",
      "[15:27:39] Processed 3120/3295 | Elapsed: 704.7s | ETA: 39.5s\n",
      "[15:27:41] Processed 3130/3295 | Elapsed: 706.7s | ETA: 37.2s\n",
      "[15:27:43] Processed 3140/3295 | Elapsed: 708.8s | ETA: 35.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 3150\n",
      "[15:27:46] Processed 3150/3295 | Elapsed: 712.1s | ETA: 32.8s\n",
      "[15:27:48] Processed 3160/3295 | Elapsed: 714.1s | ETA: 30.5s\n",
      "[15:27:50] Processed 3170/3295 | Elapsed: 716.1s | ETA: 28.2s\n",
      "[15:27:52] Processed 3180/3295 | Elapsed: 718.1s | ETA: 26.0s\n",
      "[15:27:54] Processed 3190/3295 | Elapsed: 720.1s | ETA: 23.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 3200\n",
      "[15:27:57] Processed 3200/3295 | Elapsed: 723.6s | ETA: 21.5s\n",
      "[15:27:59] Processed 3210/3295 | Elapsed: 725.6s | ETA: 19.2s\n",
      "[15:28:01] Processed 3220/3295 | Elapsed: 727.6s | ETA: 16.9s\n",
      "[15:28:04] Processed 3230/3295 | Elapsed: 729.7s | ETA: 14.7s\n",
      "[15:28:06] Processed 3240/3295 | Elapsed: 731.8s | ETA: 12.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved batch: 50 records | Total processed: 3250\n",
      "[15:28:09] Processed 3250/3295 | Elapsed: 735.0s | ETA: 10.2s\n",
      "[15:28:11] Processed 3260/3295 | Elapsed: 737.0s | ETA: 7.9s\n",
      "[15:28:13] Processed 3270/3295 | Elapsed: 739.1s | ETA: 5.6s\n",
      "[15:28:15] Processed 3280/3295 | Elapsed: 741.2s | ETA: 3.4s\n",
      "[15:28:17] Processed 3290/3295 | Elapsed: 743.2s | ETA: 1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved final batch: 45 records\n",
      "\n",
      "=== Completed processing 3295 articles in 745.5s ===\n",
      "\n",
      "=== Checking saved results ===\n",
      "Total records in table: 3295\n",
      "\n",
      "Recent 5 records:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+-------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+-----------+------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "|                                             postID|        timePublish|                                                          description_Normalized|                                                                       Label_NER|Label_Topic|Label_Intent|likeCount|commentCount|shareCount|  type|                created_at|                updated_at|\n",
      "+---------------------------------------------------+-------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+-----------+------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "|       @qandastudyvietnam/video/7487615498935454984|2025-03-30 00:00:00|                                       Đề thi ĐGNL khó gấp 2-3 lần đề minh_hoạ .|                                                  O I-EX I-EX O O O O O I-MISC O|OTHER|STUDY|  share_info|     5653|         264|         0|TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "| @daihocfpthanoi_official/video/7494485375826660615|2025-04-18 00:00:00|Tác_động của AI - Cơ_hội cho ai ? 41% doanh_nghiệp giảm nhân_sự , 92 triệu ng...|        O O B-MAJ O O O O O O B-MISC O O O O O O O O O O B-DATE I-DATE O B-MAJ O|      MAJOR|  share_info|      447|           8|         0|TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "|@cdhanghaiduongthuy2_mic2/video/7491314629390486802|2025-04-09 00:00:00|                                                                               #|                                                                               O|      OTHER|       other|       71|          10|         0|TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "|              @khoibeooto/video/7494549595821837586|2025-04-18 00:00:00|                                           Có nên học nghề ô_tô trong năm 2025 ?|                                             O O O B-MAJ I-MAJ O B-DATE I-DATE O|      MAJOR|  ask_advice|      264|          23|         0|TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "|              @dangthuhaf/video/7109852909499682075|2022-06-16 00:00:00|Học_phí các trường đại_học tại / quanh Hà_Nội p . 1 . # MuaTotNghiep . # scha...|B-FEE O B-MISC I-MISC O O O B-LOC O O O O O O O O B-MISC O O O O O B-MISC O O...|    TUITION|  share_info|   692900|        1751|     10000|TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "+---------------------------------------------------+-------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+-----------+------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa schema cho DataFrame kết quả\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.functions import days\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"postID\", StringType(), False),\n",
    "    StructField(\"timePublish\", TimestampType(), False),\n",
    "    StructField(\"description_Normalized\", StringType(), True),\n",
    "    StructField(\"Label_NER\", StringType(), True),\n",
    "    StructField(\"Label_Topic\", StringType(), True),\n",
    "    StructField(\"Label_Intent\", StringType(), True),\n",
    "    StructField(\"likeCount\", IntegerType(), True),\n",
    "    StructField(\"commentCount\", IntegerType(), True),\n",
    "    StructField(\"shareCount\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Kiểm tra xem table result_multi_model đã tồn tại chưa\n",
    "try:\n",
    "    df_existing = spark.table(\"nessie.silver_tables.result_multi_model\")\n",
    "    existing_post_ids = [row.postID for row in df_existing.select(\"postID\").distinct().collect()]\n",
    "    print(f\"Tìm thấy {len(existing_post_ids)} articles đã được xử lý trước đó\")\n",
    "except Exception as e:\n",
    "    print(f\"Table result_multi_model chưa tồn tại hoặc rỗng: {e}\")\n",
    "    existing_post_ids = []\n",
    "\n",
    "# Lọc ra các articles chưa được xử lý\n",
    "if existing_post_ids:\n",
    "    df_articles_new = df_articles.filter(~col(\"articleID\").isin(existing_post_ids))\n",
    "    print(f\"Tổng số articles mới cần xử lý: {df_articles_new.count()}\")\n",
    "else:\n",
    "    df_articles_new = df_articles\n",
    "    print(f\"Xử lý toàn bộ {df_articles.count()} articles\")\n",
    "\n",
    "print(\"\\n=== Collecting data to process ===\")\n",
    "# Collect data về driver để xử lý (phù hợp với dataset nhỏ)\n",
    "articles_to_process = df_articles_new.select(\"articleID\", \"description\", \"timePublish\", \n",
    "                                              \"likeCount\", \"commentCount\", \"shareCount\", \"type\").collect()\n",
    "print(f\"Đã collect {len(articles_to_process)} articles về driver\")\n",
    "\n",
    "# Xử lý từng article bằng model đã load sẵn trên driver\n",
    "results = []\n",
    "batch_size = 50  # Xử lý và lưu mỗi 50 records\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"\\n=== Processing articles with model ===\")\n",
    "for idx, row in enumerate(articles_to_process):\n",
    "    if idx % 10 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        avg_time = elapsed / (idx + 1) if idx > 0 else 0\n",
    "        remaining = avg_time * (len(articles_to_process) - idx)\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] Processed {idx}/{len(articles_to_process)} | \"\n",
    "              f\"Elapsed: {elapsed:.1f}s | ETA: {remaining:.1f}s\")\n",
    "    \n",
    "    article_id = row['articleID']\n",
    "    description = row['description']\n",
    "    \n",
    "    if not description or description.strip() == '':\n",
    "        results.append({\n",
    "            'postID': article_id,\n",
    "            'timePublish': row['timePublish'],\n",
    "            'description_Normalized': '',\n",
    "            'Label_NER': 'O',\n",
    "            'Label_Topic': 'None',\n",
    "            'Label_Intent': 'Unknown',\n",
    "            'likeCount': int(row['likeCount']) if row['likeCount'] else 0,\n",
    "            'commentCount': int(row['commentCount']) if row['commentCount'] else 0,\n",
    "            'shareCount': int(row['shareCount']) if row['shareCount'] else 0,\n",
    "            'type': row['type']\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Sử dụng hàm predict_labels đã định nghĩa ở cell 6\n",
    "        predictions = predict_labels(description, model, tokenizer, label_mappings, device, annotator)\n",
    "        \n",
    "        results.append({\n",
    "            'postID': article_id,\n",
    "            'timePublish': row['timePublish'],\n",
    "            'description_Normalized': predictions['normalized_text'],\n",
    "            'Label_NER': predictions['ner_labels'],\n",
    "            'Label_Topic': predictions['topic_label'],\n",
    "            'Label_Intent': predictions['intent_label'],\n",
    "            'likeCount': int(row['likeCount']) if row['likeCount'] else 0,\n",
    "            'commentCount': int(row['commentCount']) if row['commentCount'] else 0,\n",
    "            'shareCount': int(row['shareCount']) if row['shareCount'] else 0,\n",
    "            'type': row['type']\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article {article_id}: {e}\")\n",
    "        results.append({\n",
    "            'postID': article_id,\n",
    "            'timePublish': row['timePublish'],\n",
    "            'description_Normalized': description,\n",
    "            'Label_NER': 'O',\n",
    "            'Label_Topic': 'None',\n",
    "            'Label_Intent': 'Unknown',\n",
    "            'likeCount': int(row['likeCount']) if row['likeCount'] else 0,\n",
    "            'commentCount': int(row['commentCount']) if row['commentCount'] else 0,\n",
    "            'shareCount': int(row['shareCount']) if row['shareCount'] else 0,\n",
    "            'type': row['type']\n",
    "        })\n",
    "    \n",
    "    # Lưu batch và reset results để giải phóng memory\n",
    "    if (idx + 1) % batch_size == 0 and len(results) > 0:\n",
    "        try:\n",
    "            batch_df = spark.createDataFrame(results, schema=schema)\n",
    "            batch_df = batch_df.withColumn(\"created_at\", current_timestamp()) \\\n",
    "                               .withColumn(\"updated_at\", current_timestamp())\n",
    "            \n",
    "            # Append batch vào table\n",
    "            batch_df.writeTo(\"nessie.silver_tables.result_multi_model\") \\\n",
    "                .using(\"iceberg\") \\\n",
    "                .tableProperty(\"write.format.default\", \"parquet\") \\\n",
    "                .tableProperty(\"write.metadata.compression-codec\", \"gzip\") \\\n",
    "                .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n",
    "                .append()\n",
    "            \n",
    "            print(f\"✓ Saved batch: {len(results)} records | Total processed: {idx + 1}\")\n",
    "            results = []  # Reset\n",
    "        except Exception as batch_err:\n",
    "            # Nếu table chưa tồn tại, tạo mới\n",
    "            if \"table does not exist\" in str(batch_err).lower() or \"not found\" in str(batch_err).lower():\n",
    "                print(\"Creating table for first batch...\")\n",
    "                batch_df.writeTo(\"nessie.silver_tables.result_multi_model\") \\\n",
    "                    .using(\"iceberg\") \\\n",
    "                    .tableProperty(\"write.format.default\", \"parquet\") \\\n",
    "                    .tableProperty(\"write.metadata.compression-codec\", \"gzip\") \\\n",
    "                    .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n",
    "                    .partitionedBy(days(col(\"timePublish\"))) \\\n",
    "                    .create()\n",
    "                print(f\"✓ Table created with {len(results)} records\")\n",
    "                results = []\n",
    "            else:\n",
    "                print(f\"✗ Error saving batch: {batch_err}\")\n",
    "\n",
    "# Lưu records còn lại (nếu có)\n",
    "if len(results) > 0:\n",
    "    try:\n",
    "        final_df = spark.createDataFrame(results, schema=schema)\n",
    "        final_df = final_df.withColumn(\"created_at\", current_timestamp()) \\\n",
    "                           .withColumn(\"updated_at\", current_timestamp())\n",
    "        \n",
    "        final_df.writeTo(\"nessie.silver_tables.result_multi_model\") \\\n",
    "            .using(\"iceberg\") \\\n",
    "            .tableProperty(\"write.format.default\", \"parquet\") \\\n",
    "            .tableProperty(\"write.metadata.compression-codec\", \"gzip\") \\\n",
    "            .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n",
    "            .append()\n",
    "        \n",
    "        print(f\"✓ Saved final batch: {len(results)} records\")\n",
    "    except Exception as final_err:\n",
    "        if \"table does not exist\" in str(final_err).lower():\n",
    "            final_df.writeTo(\"nessie.silver_tables.result_multi_model\") \\\n",
    "                .using(\"iceberg\") \\\n",
    "                .tableProperty(\"write.format.default\", \"parquet\") \\\n",
    "                .tableProperty(\"write.metadata.compression-codec\", \"gzip\") \\\n",
    "                .tableProperty(\"write.parquet.compression-codec\", \"gzip\") \\\n",
    "                .partitionedBy(days(col(\"timePublish\"))) \\\n",
    "                .create()\n",
    "            print(f\"✓ Table created with {len(results)} records\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n=== Completed processing {len(articles_to_process)} articles in {total_time:.1f}s ===\")\n",
    "\n",
    "# Kiểm tra kết quả đã lưu\n",
    "print(\"\\n=== Checking saved results ===\")\n",
    "try:\n",
    "    df_check = spark.table(\"nessie.silver_tables.result_multi_model\")\n",
    "    print(f\"Total records in table: {df_check.count()}\")\n",
    "    print(\"\\nRecent 5 records:\")\n",
    "    df_check.orderBy(col(\"created_at\").desc()).show(5, truncate=80)\n",
    "except Exception as e:\n",
    "    print(f\"Could not read table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74e20ed",
   "metadata": {},
   "source": [
    "## 8. Verify Dữ Liệu Đã Lưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "084e1459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Total records in table: 3295\n",
      "\n",
      "Recent saved records:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "|postID                                            |timePublish        |description_Normalized                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |Label_NER                                                                                                                                                                                                                                               |Label_Topic      |Label_Intent|likeCount|commentCount|shareCount|type  |created_at                |updated_at                |\n",
      "+--------------------------------------------------+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "|@caithiengionghat/video/7110162407120588034       |2022-06-17 00:00:00|8 công_việc ngành_nghề sau khi tốt_nghiệp trường Nghệ_thuật : 1 . Ca_sĩ ( biểu_diễn sự_kiện , phòng tiệc , phòng trà , khai_trương ) 2 . Giáo_viên Âm_nhạc ( dạy thanh_nhạc , piano , guitar , vân_vân ) 3 . Nhạc_sĩ 4 . Producer ( nhà_sản_xuất âm_nhạc ) 5 . Làm_việc tại các nhà_hát , đài_truyền_hình , các ban_ngành đoàn_thể về văn_hoá văn_nghệ 6 . Mở các trung_tâm đào_tạo về âm_nhạc 7 . Mở cửa_hàng kinh_doanh các nhạc_cụ 8 . Thu âm , mix , master nhạc # nhachaymoingay # onthidaihoc|O O O O O O B-ORG I-ORG O O O B-MAJ O O O O O O O O O O O O O O B-MAJ I-MAJ O O I-PRO O I-PRO O I-PRO O O O O O B-MAJ O O B-MAJ O B-MAJ I-MAJ O O O O O O B-MISC O B-MISC O O O O O O O O O O O B-MISC O O B-MAJ O O O O O O O O O O O O O O O O O O O O|CAREER|UNIVERSITY|share_info  |1758     |19          |83100     |TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "|@daihocfpthanoi_official/video/7494485375826660615|2025-04-18 00:00:00|Tác_động của AI - Cơ_hội cho ai ? 41% doanh_nghiệp giảm nhân_sự , 92 triệu người có_thể mất việc vào năm 2025 do AI .                                                                                                                                                                                                                                                                                                                                                                              |O O B-MAJ O O O O O O B-MISC O O O O O O O O O O B-DATE I-DATE O B-MAJ O                                                                                                                                                                                |MAJOR            |share_info  |447      |8           |0         |TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "|@chinguyenduhocdieuhien/video/7493481031668976914 |2025-04-15 00:00:00|Đại_học Long_Hoa ( Đài_Loan ) tuyển_sinh kỳ 9/2025. Hệ vừa học vừa làm ( Du_lịch , Điện_cơ ) . Hệ 1+4 ( Bán_dẫn , Quản_trị công_nghiệp , Marketing kỹ_thuật_số , TMĐT , Kỹ_thuật mạng ) .                                                                                                                                                                                                                                                                                                          |B-ORG I-ORG O B-LOC O O B-DATE I-DATE B-PRO I-PRO I-PRO I-PRO I-PRO O B-MAJ O B-MAJ O O B-PRO I-PRO O B-MAJ O B-MAJ I-MAJ O B-MAJ I-MAJ O B-MAJ O B-MAJ I-MAJ O O                                                                                       |MAJOR|UNIVERSITY |share_info  |86       |2           |0         |TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "|@khoibeooto/video/7494549595821837586             |2025-04-18 00:00:00|Có nên học nghề ô_tô trong năm 2025 ?                                                                                                                                                                                                                                                                                                                                                                                                                                                              |O O O B-MAJ I-MAJ O B-DATE I-DATE O                                                                                                                                                                                                                     |MAJOR            |ask_advice  |264      |23          |0         |TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "|@anhphodoan/video/7490482226354818359             |2025-04-07 00:00:00|Trả_lời @ Hướng_Xuân_Tiến : Ngành đường_sắt hơi khó nhưng_mà có ảnh ngay # chatgpt # ai # láitauhoa . Xin chào quý hành_khách thân_mến , chuyến tàu mang số_hiệu 2025 đi từ ga 2024 sắp bắt_đầu .                                                                                                                                                                                                                                                                                                  |O O O O B-MAJ I-MAJ O O O O O O O O O O O O O O O O O O O O O O O B-DATE O O B-MISC I-DATE O O O                                                                                                                                                        |MAJOR            |share_info  |40       |12          |5         |TikTok|2025-12-06 15:28:18.630403|2025-12-06 15:28:18.630403|\n",
      "+--------------------------------------------------+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+------------+---------+------------+----------+------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "=== Records saved by time ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 213:=================================================>   (221 + 6) / 235]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----+\n",
      "|created_at                |count|\n",
      "+--------------------------+-----+\n",
      "|2025-12-06 15:28:18.630403|45   |\n",
      "|2025-12-06 15:28:08.21911 |50   |\n",
      "|2025-12-06 15:27:56.539175|50   |\n",
      "|2025-12-06 15:27:45.384132|50   |\n",
      "|2025-12-06 15:27:34.661695|50   |\n",
      "|2025-12-06 15:27:23.890264|50   |\n",
      "|2025-12-06 15:27:13.172456|50   |\n",
      "|2025-12-06 15:27:02.232199|50   |\n",
      "|2025-12-06 15:26:50.862312|50   |\n",
      "|2025-12-06 15:26:39.822783|50   |\n",
      "|2025-12-06 15:26:28.087923|50   |\n",
      "|2025-12-06 15:26:16.231217|50   |\n",
      "|2025-12-06 15:26:05.181591|50   |\n",
      "|2025-12-06 15:25:54.054918|50   |\n",
      "|2025-12-06 15:25:42.645255|50   |\n",
      "|2025-12-06 15:25:31.266543|50   |\n",
      "|2025-12-06 15:25:20.530875|50   |\n",
      "|2025-12-06 15:25:09.393024|50   |\n",
      "|2025-12-06 15:24:58.097393|50   |\n",
      "|2025-12-06 15:24:46.750668|50   |\n",
      "+--------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Verify dữ liệu đã lưu (Cell 7 đã tự động lưu theo batch)\n",
    "try:\n",
    "    df_verify = spark.table(\"nessie.silver_tables.result_multi_model\")\n",
    "    total_count = df_verify.count()\n",
    "    \n",
    "    print(f\"✓ Total records in table: {total_count}\")\n",
    "    print(\"\\nRecent saved records:\")\n",
    "    df_verify.orderBy(col(\"created_at\").desc()).show(5, truncate=False)\n",
    "    \n",
    "    # Thống kê số lượng records theo thời gian tạo\n",
    "    print(\"\\n=== Records saved by time ===\")\n",
    "    df_verify.groupBy(\"created_at\").count() \\\n",
    "        .orderBy(col(\"created_at\").desc()) \\\n",
    "        .show(20, truncate=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error reading table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684149c",
   "metadata": {},
   "source": [
    "## 9. Thống kê kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fec9f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in result_multi_model: 3295\n",
      "\n",
      "Sample records:\n",
      "+-----------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------+----------------+---------+------------+----------+--------+--------------------------+--------------------------+\n",
      "|postID                                   |timePublish        |description_Normalized                                                                                                                                                                                                                                                                                                                      |Label_NER                                                                                                                                                                                                                    |Label_Topic                   |Label_Intent    |likeCount|commentCount|shareCount|type    |created_at                |updated_at                |\n",
      "+-----------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------+----------------+---------+------------+----------+--------+--------------------------+--------------------------+\n",
      "|1875735026616938                         |2025-02-25 18:12:00|Topic : Ngôn_ngữ Nhật                                                                                                                                                                                                                                                                                                                       |O O B-SUBJ I-MAJ                                                                                                                                                                                                             |LANGUAGE|MAJOR                |ask_info        |1800     |1200        |249       |facebook|2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "|1875795486610892                         |2025-02-25 18:44:00|Topic : Điều_dưỡng ạ                                                                                                                                                                                                                                                                                                                        |O O B-MAJ O                                                                                                                                                                                                                  |MAJOR                         |ask_info        |257      |235         |18        |facebook|2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "|1875617629962011                         |2025-02-25 12:57:00|Năm 2025 , Trường Đại_học Thương_Mại tăng 370 chỉ_tiêu và xét tuyển thêm 4 tổ_hợp mới : Toán - Anh - ( Sử / Địa / Tin / Giáo_dục Kinh_tế và Pháp_luật )                                                                                                                                                                                     |B-DATE I-DATE O B-ORG I-ORG I-ORG O O O O O O O O B-MISC O O B-SUBJ O B-SUBJ O O B-SUBJ O B-SUBJ O B-SUBJ O B-SUBJ I-SUBJ O B-SUBJ O                                                                                         |SUBJECT_COMBINATION|UNIVERSITY|ask_confirmation|135      |5           |2         |facebook|2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "|1875070923350015                         |2025-02-25 07:57:00|Em thi khối C00 mà khả_năng của em chỉ tầm 24 điểm thôi em có ước_muốn theo Tổ_chức sự_kiện và Quản_trị văn_phòng không biết có trường nào phù_hợp không ạ ?                                                                                                                                                                                |O O B-TERM I-TERM O O O O O O B-SCO I-SCO O O O O O B-MAJ I-MAJ O B-MAJ I-MAJ O O O O O O O O O                                                                                                                              |MAJOR|SUBJECT_COMBINATION     |ask_info        |27       |11          |2         |facebook|2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "|1875046623352445                         |2025-02-25 07:56:00|Năm nay em chuẩn_bị thi tốt_nghiệp , em muốn hỏi các anh_chị đi trước rằng nếu học Hướng_dẫn_viên du_lịch thì em nên đi theo hướng cao_đẳng hay đại_học ạ . Năng_lực của em thì ở Giỏi ạ nhưng em thấy người khác bảo học du_lịch thì nên đi theo cao_đẳng để xin việc cho dễ bởi có kinh_nghiệm sớm hơn đại_học ... Mong bài được duyệt ạ .|O O O O B-EX I-EX O O O O O O O O O O O B-MAJ I-MAJ O O O O O O B-MISC O B-MISC O O O O O O O O O O O O O O O O B-MAJ O O O O B-MISC O O O O O O O O O O B-MISC O O O O O O O                                                |CAREER|MAJOR                  |ask_advice      |16       |14          |1         |facebook|2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "|1875773079946466                         |2025-02-25 18:11:00|Mình xin review về USTH và Phenikaa ạ . Xin cảm_ơn , mong ad duyệt ạ !                                                                                                                                                                                                                                                                      |O O O O B-ORG O B-ORG O O O O O O O O O O                                                                                                                                                                                    |UNIVERSITY                    |ask_info        |13       |11          |2         |facebook|2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "|1875124773344630                         |2025-02-25 07:56:00|Anh_chị cho em hỏi nên học Quản_trị kinh_doanh không ạ ?                                                                                                                                                                                                                                                                                    |O O O O O O B-MAJ I-MAJ O O O                                                                                                                                                                                                |MAJOR                         |ask_advice      |3        |3           |0         |facebook|2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "|@vatlyysinhnttu/video/7392617192224738576|2024-07-17 00:00:00|Ngành Kỹ_thuật Y_sinh đào_tạo kỹ_sư về thiết_bị y_tế : vận_hành , lắp_đặt , bảo_trì , quản_lý và chế_tạo thiết_bị y_tế . Sinh_viên có_thể làm_việc tại bệnh_viện , công_ty thiết_bị y_tế , viện nghiên_cứu hoặc cơ_sở đào_tạo . Nhu_cầu tuyển_dụng cao , thu_nhập hấp_dẫn . # kythuatysinh # daihocnguyentatthanh                           |B-MAJ I-MAJ I-MAJ O B-MAJ I-MAJ I-MAJ I-MAJ O I-PRO I-PRO I-PRO I-PRO I-PRO I-PRO I-PRO I-PRO I-PRO I-PRO I-PRO O B-MISC O O O B-MISC O B-MISC I-MISC I-MISC O B-MISC I-MISC O B-MISC I-MISC O O O O O O O O O B-MAJ O B-MISC|CAREER|MAJOR                  |share_info      |7031     |13          |0         |TikTok  |2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "|1876435993213508                         |2025-02-26 16:37:00|Topic : Góc khuất ngành Quản_lí giải_trí và sự_kiện                                                                                                                                                                                                                                                                                         |O O O O B-MAJ I-MAJ I-MAJ I-MAJ I-MAJ                                                                                                                                                                                        |MAJOR                         |ask_info        |259      |100         |34        |facebook|2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "|1876177706572670                         |2025-02-26 11:54:00|Học khối A00 mà kém Tiếng Anh thì nên chọn ngành nào ?                                                                                                                                                                                                                                                                                      |O B-TERM I-TERM O O B-SUBJ I-SUBJ O O O O O O                                                                                                                                                                                |STUDY|SUBJECT_COMBINATION     |ask_advice      |143      |86          |3         |facebook|2025-12-06 15:25:54.054918|2025-12-06 15:25:54.054918|\n",
      "+-----------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------+----------------+---------+------------+----------+--------+--------------------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "=== Label Statistics ===\n",
      "\n",
      "Topic distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+\n",
      "|Label_Topic              |count|\n",
      "+-------------------------+-----+\n",
      "|MAJOR                    |645  |\n",
      "|UNIVERSITY               |564  |\n",
      "|MAJOR|UNIVERSITY         |345  |\n",
      "|CAREER|MAJOR             |308  |\n",
      "|OTHER                    |208  |\n",
      "|STUDY                    |154  |\n",
      "|TUITION|UNIVERSITY       |129  |\n",
      "|MAJOR|TUITION|UNIVERSITY |108  |\n",
      "|MAJOR|SUBJECT_COMBINATION|83   |\n",
      "|None                     |80   |\n",
      "+-------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "Intent distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 223:==================================================>  (223 + 6) / 235]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|Label_Intent    |count|\n",
      "+----------------+-----+\n",
      "|share_info      |1577 |\n",
      "|ask_info        |879  |\n",
      "|ask_advice      |401  |\n",
      "|other           |182  |\n",
      "|ask_confirmation|108  |\n",
      "|ask_comparison  |74   |\n",
      "|ask_experience  |74   |\n",
      "+----------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Đọc lại dữ liệu từ table\n",
    "df_verify = spark.table(\"nessie.silver_tables.result_multi_model\")\n",
    "\n",
    "print(f\"Total records in result_multi_model: {df_verify.count()}\")\n",
    "print(\"\\nSample records:\")\n",
    "df_verify.show(10, truncate=False)\n",
    "\n",
    "print(\"\\n=== Label Statistics ===\")\n",
    "print(\"\\nTopic distribution:\")\n",
    "df_verify.groupBy(\"Label_Topic\").count().orderBy(col(\"count\").desc()).show(10, truncate=False)\n",
    "\n",
    "print(\"\\nIntent distribution:\")\n",
    "df_verify.groupBy(\"Label_Intent\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba3479",
   "metadata": {},
   "source": [
    "## 10. Dừng Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74aa7a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session đã được dừng!\n"
     ]
    }
   ],
   "source": [
    "# Dừng Spark Session\n",
    "spark.stop()\n",
    "print(\"Spark Session đã được dừng!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
