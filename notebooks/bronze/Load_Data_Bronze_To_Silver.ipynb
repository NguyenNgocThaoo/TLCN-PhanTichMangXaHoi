{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24213a7",
   "metadata": {},
   "source": [
    "# Load Data từ Bronze Layer sang Silver Layer\n",
    "\n",
    "Notebook này sẽ đọc dữ liệu từ Bronze layer (MinIO) và xử lý để load vào các bảng Iceberg trong Silver layer với Nessie catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063eaad0",
   "metadata": {},
   "source": [
    "## 1. Import Libraries và Khởi tạo Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957d424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session đã được khởi tạo với Nessie catalog!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime\n",
    "import os\n",
    "import hashlib  # Để dùng trong batch processing nếu cần\n",
    "\n",
    "# Khởi tạo Spark Session với Iceberg và Nessie catalog\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    # .master(\"spark://spark-master:7077\") # để chạy DAG bên Spark Cluster\n",
    "    .appName(\"Load_Bronze_To_Silver\")\n",
    "    .config(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.uri\", \"http://nessie:19120/api/v2\")\n",
    "    .config(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "    .config(\"spark.sql.catalog.nessie.warehouse\", \"s3a://silver/\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.access-key\", \"admin\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.secret-key\", \"admin123\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.path-style-access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin123\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"Spark Session đã được khởi tạo với Nessie catalog!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43664703",
   "metadata": {},
   "source": [
    "## 2. Load Bảng SCHOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88066c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAD BẢNG SCHOOL\n",
      "================================================================================\n",
      "Đã ghi 265 dòng vào school\n",
      "+--------+--------------------------------------+-----------+--------------------------+--------------------------+\n",
      "|schoolId|schoolName                            |province   |created_at                |updated_at                |\n",
      "+--------+--------------------------------------+-----------+--------------------------+--------------------------+\n",
      "|DHF     |Đại học Ngoại Ngữ - Đại học Huế       |Huế        |2025-11-28 04:36:13.764956|2025-11-28 04:36:13.764956|\n",
      "|DVB     |Đại học Việt Bắc                      |Thái Nguyên|2025-11-28 04:36:13.764956|2025-11-28 04:36:13.764956|\n",
      "|DCQ     |Đại học Công Nghệ và Quản Lý Hữu Nghị |Hà Nội     |2025-11-28 04:36:13.764956|2025-11-28 04:36:13.764956|\n",
      "|NTT     |Đại học Nguyễn Tất Thành              |TP HCM     |2025-11-28 04:36:13.764956|2025-11-28 04:36:13.764956|\n",
      "|KGH     |Trường Sĩ Quan Không Quân - Hệ Đại học|Khánh Hòa  |2025-11-28 04:36:13.764956|2025-11-28 04:36:13.764956|\n",
      "+--------+--------------------------------------+-----------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOAD BẢNG SCHOOL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Đọc và merge tất cả các năm\n",
    "years = [2021, 2022, 2023, 2024, 2025]\n",
    "base_path = \"s3a://bronze/structured_data/danh sách các trường Đại Học (2021-2025)/Danh_sách_các_trường_Đại_Học_\"\n",
    "df_school = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv([f\"{base_path}{year}.csv\" for year in years]).select(\"TenTruong\", \"MaTruong\", \"TinhThanh\").dropDuplicates()\n",
    "\n",
    "# Transform\n",
    "df_school_silver = df_school.select(\n",
    "    col(\"MaTruong\").cast(\"string\").alias(\"schoolId\"),\n",
    "    col(\"TenTruong\").cast(\"string\").alias(\"schoolName\"),\n",
    "    col(\"TinhThanh\").cast(\"string\").alias(\"province\"),\n",
    "    current_timestamp().alias(\"created_at\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ").filter(col(\"schoolId\").isNotNull() & col(\"schoolName\").isNotNull())\n",
    "\n",
    "# Ghi vào Silver\n",
    "df_school_silver.writeTo(\"nessie.silver_tables.school\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"Đã ghi {df_school_silver.count()} dòng vào school\")\n",
    "\n",
    "# Verify\n",
    "spark.table(\"nessie.silver_tables.school\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0235c2c",
   "metadata": {},
   "source": [
    "## 3. Load Bảng MAJOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecf9d446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã ghi 3085 dòng vào major\n",
      "+-------+------------------------------------------------------------+--------------------------+--------------------------+\n",
      "|majorId|majorName                                                   |created_at                |updated_at                |\n",
      "+-------+------------------------------------------------------------+--------------------------+--------------------------+\n",
      "|106    |Khoa học Máy tính                                           |2025-11-28 04:36:14.993575|2025-11-28 04:36:14.993575|\n",
      "|107    |Kỹ thuật Máy tính                                           |2025-11-28 04:36:14.993575|2025-11-28 04:36:14.993575|\n",
      "|108    |Điện - Điện tử - Viễn Thông - Tự động hoá - Thiết kế vi mạch|2025-11-28 04:36:14.993575|2025-11-28 04:36:14.993575|\n",
      "|109    |Kỹ Thuật Cơ khí                                             |2025-11-28 04:36:14.993575|2025-11-28 04:36:14.993575|\n",
      "|110    |Kỹ Thuật Cơ Điện tử                                         |2025-11-28 04:36:14.993575|2025-11-28 04:36:14.993575|\n",
      "+-------+------------------------------------------------------------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, trim, regexp_replace, current_timestamp\n",
    "\n",
    "df_major = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"false\") \\\n",
    "    .option(\"encoding\", \"UTF-8\") \\\n",
    "    .csv(\"s3a://bronze/structured_data/danh sách các ngành đại học/Danh_sách_các_ngành.csv\")\n",
    "\n",
    "df_major_clean = df_major.select(\n",
    "    regexp_replace(trim(col(df_major.columns[0])).cast(\"string\"), r\"\\.0$\", \"\").alias(\"majorId\"),\n",
    "    trim(col(df_major.columns[1])).cast(\"string\").alias(\"majorName\")\n",
    ").filter(\n",
    "    (col(\"majorId\").isNotNull()) &\n",
    "    (col(\"majorName\").isNotNull()) &\n",
    "    (col(\"majorId\") != \"\") &\n",
    "    (col(\"majorName\") != \"\") &\n",
    "    (lower(col(\"majorId\")) != \"nan\")\n",
    ")\n",
    "\n",
    "# Chuẩn hoá để dedupe theo lowercase\n",
    "df_major_silver = df_major_clean \\\n",
    "    .withColumn(\"majorId_lower\", lower(col(\"majorId\"))) \\\n",
    "    .dropDuplicates([\"majorId_lower\"]) \\\n",
    "    .select(\n",
    "        col(\"majorId\"),\n",
    "        col(\"majorName\"),\n",
    "        current_timestamp().alias(\"created_at\"),\n",
    "        current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    "\n",
    "df_major_silver.writeTo(\"nessie.silver_tables.major\").using(\"iceberg\").createOrReplace()\n",
    "\n",
    "print(f\"Đã ghi {df_major_silver.count()} dòng vào major\")\n",
    "spark.table(\"nessie.silver_tables.major\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d64a8",
   "metadata": {},
   "source": [
    "## 4. Load Bảng SUBJECT_GROUP và SUBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c053cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAD BẢNG SUBJECT_GROUP và SUBJECT\n",
      "================================================================================\n",
      "Đã ghi 232 dòng vào subject_group\n",
      "Đã ghi 51 dòng vào subject\n",
      "+--------------+----------------+------------------+--------------------------+--------------------------+\n",
      "|subjectGroupId|subjectGroupName|subjectCombination|created_at                |updated_at                |\n",
      "+--------------+----------------+------------------+--------------------------+--------------------------+\n",
      "|1             |A00             |Toán-Lí-Hóa       |2025-11-28 04:36:16.067063|2025-11-28 04:36:16.067063|\n",
      "|2             |A01             |Toán-Lí-Ngoại ngữ |2025-11-28 04:36:16.067063|2025-11-28 04:36:16.067063|\n",
      "|3             |A02             |Toán-Lí-Sinh      |2025-11-28 04:36:16.067063|2025-11-28 04:36:16.067063|\n",
      "|4             |A03             |Toán-Lí-Sử        |2025-11-28 04:36:16.067063|2025-11-28 04:36:16.067063|\n",
      "|5             |A04             |Toán-Lí-Địa       |2025-11-28 04:36:16.067063|2025-11-28 04:36:16.067063|\n",
      "+--------------+----------------+------------------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------------------+--------------------------+--------------------------+\n",
      "|subjectId|subjectName          |created_at                |updated_at                |\n",
      "+---------+---------------------+--------------------------+--------------------------+\n",
      "|1        |biểu diễn nghệ thuật |2025-11-28 04:36:16.625444|2025-11-28 04:36:16.625444|\n",
      "|2        |Công nghệ công nghiệp|2025-11-28 04:36:16.625444|2025-11-28 04:36:16.625444|\n",
      "|3        |Công nghệ nông nghiệp|2025-11-28 04:36:16.625444|2025-11-28 04:36:16.625444|\n",
      "|4        |GDCD                 |2025-11-28 04:36:16.625444|2025-11-28 04:36:16.625444|\n",
      "|5        |Hát                  |2025-11-28 04:36:16.625444|2025-11-28 04:36:16.625444|\n",
      "+---------+---------------------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOAD BẢNG SUBJECT_GROUP và SUBJECT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Đọc file tohop_mon_fixed.csv\n",
    "df_tohop = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"encoding\", \"UTF-8\").csv(\"s3a://bronze/structured_data/tohop_mon_fixed.csv\")\n",
    "\n",
    "# --- SUBJECT_GROUP ---\n",
    "df_subject_group_silver = df_tohop.select(\n",
    "    col(df_tohop.columns[0]).cast(\"int\").alias(\"subjectGroupId\"),\n",
    "    col(df_tohop.columns[1]).cast(\"string\").alias(\"subjectGroupName\"),\n",
    "    col(df_tohop.columns[2]).cast(\"string\").alias(\"subjectCombination\"),\n",
    "    current_timestamp().alias(\"created_at\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ").filter(col(\"subjectGroupId\").isNotNull() & col(\"subjectGroupName\").isNotNull() & col(\"subjectCombination\").isNotNull()).dropDuplicates([\"subjectGroupName\", \"subjectCombination\"])\n",
    "df_subject_group_silver.writeTo(\"nessie.silver_tables.subject_group\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"Đã ghi {df_subject_group_silver.count()} dòng vào subject_group\")\n",
    "\n",
    "# --- SUBJECT ---\n",
    "df_subject = (\n",
    "    df_tohop.select(explode(split(col(df_tohop.columns[2]), \"-\")).alias(\"subjectName\"))\n",
    "            .withColumn(\"subjectName\", trim(col(\"subjectName\")))\n",
    "            .filter(col(\"subjectName\").isNotNull() & (col(\"subjectName\") != \"\"))\n",
    "            .withColumn(\"subjectName_lower\", lower(col(\"subjectName\")))\n",
    "            # loại bỏ trùng theo chữ thường\n",
    "            .dropDuplicates([\"subjectName_lower\"])\n",
    ")\n",
    "\n",
    "window_spec = Window.orderBy(\"subjectName_lower\")\n",
    "df_subject_silver = df_subject.withColumn(\"subjectId\", row_number().over(window_spec)).select(\n",
    "    col(\"subjectId\").cast(\"int\"),\n",
    "    col(\"subjectName\").cast(\"string\"),\n",
    "    current_timestamp().alias(\"created_at\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ")\n",
    "df_subject_silver.writeTo(\"nessie.silver_tables.subject\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"Đã ghi {df_subject_silver.count()} dòng vào subject\")\n",
    "\n",
    "# Verify\n",
    "spark.table(\"nessie.silver_tables.subject_group\").orderBy(\"subjectGroupId\").show(5, truncate=False)\n",
    "spark.table(\"nessie.silver_tables.subject\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6236f",
   "metadata": {},
   "source": [
    "## 5. Load Bảng SELECTION_METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d204061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAD BẢNG SELECTION_METHOD\n",
      "================================================================================\n",
      "Đã ghi 10 dòng vào selection_method\n",
      "+-----------------+------------------------------------------------------+--------------------------+--------------------------+\n",
      "|selectionMethodId|selectionMethodName                                   |created_at                |updated_at                |\n",
      "+-----------------+------------------------------------------------------+--------------------------+--------------------------+\n",
      "|1                |Điểm chuẩn theo phương thức Điểm học bạ               |2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "|2                |Điểm chuẩn theo phương thức Điểm thi THPT             |2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "|3                |Điểm chuẩn theo phương thức Điểm xét tuyển kết hợp    |2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "|4                |Điểm chuẩn theo phương thức Điểm xét tốt nghiệp THPT  |2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "|5                |Điểm chuẩn theo phương thức Điểm ĐGNL HCM             |2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "|6                |Điểm chuẩn theo phương thức Điểm ĐGNL HN              |2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "|7                |Điểm chuẩn theo phương thức Điểm ĐGNL ĐH Sư phạm HN   |2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "|8                |Điểm chuẩn theo phương thức Điểm ĐGNL ĐH Sư phạm TPHCM|2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "|9                |Điểm chuẩn theo phương thức Điểm Đánh giá Tư duy      |2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "|10               |Điểm chuẩn theo phương thức ƯTXT, XT thẳng            |2025-11-28 04:36:18.121363|2025-11-28 04:36:18.121363|\n",
      "+-----------------+------------------------------------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOAD BẢNG SELECTION_METHOD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Đọc từ file benchmark để lấy các phương thức xét tuyển\n",
    "df_benchmark = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"encoding\", \"UTF-8\").csv(\"s3a://bronze/structured_data/điểm chuẩn các trường (2021-2025)/Điểm_chuẩn_các_ngành_đại_học_năm(2021-2025)*.csv\")\n",
    "\n",
    "# Lấy PhuongThuc và loại bỏ \"năm ...\"\n",
    "df_selection = df_benchmark.select(trim(regexp_replace(col(\"PhuongThuc\"), r\"\\s*năm\\s+\\d{4}.*$\", \"\")).alias(\"selectionMethodName\")).filter(col(\"selectionMethodName\").isNotNull() & (col(\"selectionMethodName\") != \"\")).distinct()\n",
    "\n",
    "window_spec = Window.orderBy(\"selectionMethodName\")\n",
    "df_selection_method_silver = df_selection.withColumn(\"selectionMethodId\", row_number().over(window_spec)).select(\n",
    "    col(\"selectionMethodId\").cast(\"int\"),\n",
    "    col(\"selectionMethodName\").cast(\"string\"),\n",
    "    current_timestamp().alias(\"created_at\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ")\n",
    "df_selection_method_silver.writeTo(\"nessie.silver_tables.selection_method\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"Đã ghi {df_selection_method_silver.count()} dòng vào selection_method\")\n",
    "\n",
    "# Verify\n",
    "spark.table(\"nessie.silver_tables.selection_method\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911622a",
   "metadata": {},
   "source": [
    "## 6. Load Bảng GradingScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9ca8916-830b-4f32-bbbb-d0ac527e6568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAD BẢNG GRADING_SCALE TỪ PHANLOAITHANGDIEM\n",
      "================================================================================\n",
      "Đã ghi 10 dòng vào grading_scale\n",
      "+--------------+------+---------------+--------------------------+--------------------------+\n",
      "|gradingScaleId|value |description    |created_at                |updated_at                |\n",
      "+--------------+------+---------------+--------------------------+--------------------------+\n",
      "|0             |30.0  |Thang điểm 30  |2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "|1             |1200.0|Thang điểm 1200|2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "|2             |40.0  |Thang điểm 40  |2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "|3             |50.0  |Thang điểm 50  |2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "|4             |150.0 |Thang điểm 150 |2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "|5             |10.0  |Thang điểm 10  |2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "|6             |100.0 |Thang điểm 100 |2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "|7             |120.0 |Thang điểm 120 |2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "|8             |35.0  |Thang điểm 35  |2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "|9             |90.0  |Thang điểm 90  |2025-11-28 04:36:20.225053|2025-11-28 04:36:20.225053|\n",
      "+--------------+------+---------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOAD BẢNG GRADING_SCALE TỪ PHANLOAITHANGDIEM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Đọc dữ liệu gốc từ file CSV (giống benchmark)\n",
    "df_raw = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"encoding\", \"UTF-8\")\n",
    "        .csv(\"s3a://bronze/structured_data/điểm chuẩn các trường (2021-2025)/Điểm_chuẩn_các_ngành_đại_học_năm(2021-2025)*.csv\")\n",
    ")\n",
    "\n",
    "# 2. Lấy unique PhanLoaiThangDiem\n",
    "df_grading_raw = (\n",
    "    df_raw\n",
    "        .select(trim(col(\"PhanLoaiThangDiem\")).alias(\"description\"))\n",
    "        .filter(col(\"description\").isNotNull() & (col(\"description\") != \"\"))\n",
    "        .dropDuplicates([\"description\"])\n",
    ")\n",
    "\n",
    "# 3. Tách giá trị số trong description làm \"value\" (nếu có, vd: \"thang 40\" -> 40)\n",
    "df_grading = (\n",
    "    df_grading_raw\n",
    "        .withColumn(\n",
    "            \"value\",\n",
    "            regexp_extract(col(\"description\"), r\"(\\d+(?:\\.\\d+)?)\", 1).cast(\"float\")\n",
    "        )\n",
    "        .withColumn(\"gradingScaleId\", monotonically_increasing_id().cast(\"int\"))\n",
    "        .withColumn(\"created_at\", current_timestamp())\n",
    "        .withColumn(\"updated_at\", current_timestamp())\n",
    "        .select(\n",
    "            \"gradingScaleId\",\n",
    "            \"value\",\n",
    "            \"description\",\n",
    "            \"created_at\",\n",
    "            \"updated_at\"\n",
    "        )\n",
    ")\n",
    "\n",
    "# 4. Ghi vào bảng Iceberg grading_scale đã tạo trước đó\n",
    "df_grading.writeTo(\"nessie.silver_tables.grading_scale\") \\\n",
    "          .using(\"iceberg\") \\\n",
    "          .createOrReplace()\n",
    "\n",
    "print(f\"Đã ghi {df_grading.count()} dòng vào grading_scale\")\n",
    "\n",
    "# 5. Verify\n",
    "spark.table(\"nessie.silver_tables.grading_scale\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036e97a-c555-43a0-a6d4-fb1e673edf0f",
   "metadata": {},
   "source": [
    "## 6. Load Bảng BENCHMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24de0240-da7e-4d00-8870-78bfa419516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAD BẢNG BENCHMARK\n",
      "================================================================================\n",
      "Đã ghi 163399 dòng vào benchmark\n",
      "+-----------+--------+-------+--------------+-----------------+--------------+----+-----+--------------------------+--------------------------+\n",
      "|benchmarkId|schoolId|majorId|subjectGroupId|selectionMethodId|gradingScaleId|year|score|created_at                |updated_at                |\n",
      "+-----------+--------+-------+--------------+-----------------+--------------+----+-----+--------------------------+--------------------------+\n",
      "|1          |ANH     |7480201|1             |2                |0             |2025|21.98|2025-11-28 04:37:01.871063|2025-11-28 04:37:01.871063|\n",
      "|2          |ANH     |7480201|2             |2                |0             |2025|21.98|2025-11-28 04:37:01.871063|2025-11-28 04:37:01.871063|\n",
      "|3          |ANH     |7480201|198           |2                |0             |2025|21.98|2025-11-28 04:37:01.871063|2025-11-28 04:37:01.871063|\n",
      "|4          |ANH     |7480201|199           |2                |0             |2025|21.98|2025-11-28 04:37:01.871063|2025-11-28 04:37:01.871063|\n",
      "|5          |ANH     |7480201|200           |2                |0             |2025|21.98|2025-11-28 04:37:01.871063|2025-11-28 04:37:01.871063|\n",
      "+-----------+--------+-------+--------------+-----------------+--------------+----+-----+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2021|23215|\n",
      "|2022|27251|\n",
      "|2023|31775|\n",
      "|2024|40734|\n",
      "|2025|40424|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, trim, regexp_replace, current_timestamp, row_number\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LOAD BẢNG BENCHMARK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df_benchmark = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"encoding\", \"UTF-8\")\n",
    "    .csv(\"s3a://bronze/structured_data/điểm chuẩn các trường (2021-2025)/Điểm_chuẩn_các_ngành_đại_học_năm(2021-2025)*.csv\")\n",
    ")\n",
    "\n",
    "# Xử lý PhuongThuc\n",
    "df_benchmark = df_benchmark.withColumn(\n",
    "    \"PhuongThuc_cleaned\",\n",
    "    trim(regexp_replace(col(\"PhuongThuc\"), r\"\\s*năm\\s+\\d{4}.*$\", \"\"))\n",
    ")\n",
    "\n",
    "# Join lookup tables\n",
    "df_selection_lookup     = spark.table(\"nessie.silver_tables.selection_method\")\n",
    "df_subject_group_lookup = spark.table(\"nessie.silver_tables.subject_group\")\n",
    "df_grading_scale_lookup = spark.table(\"nessie.silver_tables.grading_scale\")\n",
    "\n",
    "# Bước 1: chuẩn hóa dữ liệu, chưa tạo ID\n",
    "df_benchmark_base = (\n",
    "    df_benchmark\n",
    "    .join(\n",
    "        df_selection_lookup,\n",
    "        df_benchmark[\"PhuongThuc_cleaned\"] == df_selection_lookup[\"selectionMethodName\"],\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        df_subject_group_lookup,\n",
    "        df_benchmark[\"KhoiThi\"] == df_subject_group_lookup[\"subjectGroupName\"],\n",
    "        \"left\"\n",
    "    )\n",
    "    .join(\n",
    "        df_grading_scale_lookup,\n",
    "        trim(df_benchmark[\"PhanLoaiThangDiem\"]) == df_grading_scale_lookup[\"description\"],\n",
    "        \"left\"\n",
    "    )\n",
    "    .select(\n",
    "        col(\"MaTruong\").cast(\"string\").alias(\"schoolId\"),\n",
    "        col(\"MaNganh\").cast(\"string\").alias(\"majorId\"),\n",
    "        col(\"subjectGroupId\").cast(\"int\"),\n",
    "        col(\"selectionMethodId\").cast(\"int\"),\n",
    "        col(\"gradingScaleId\").cast(\"int\"),\n",
    "        col(\"Nam\").cast(\"int\").alias(\"year\"),\n",
    "        col(\"DiemChuan\").cast(\"double\").alias(\"score\"),\n",
    "        # current_timestamp().alias(\"created_at\"),\n",
    "        # current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    "    .filter(\n",
    "        col(\"schoolId\").isNotNull() &\n",
    "        col(\"majorId\").isNotNull() &\n",
    "        col(\"gradingScaleId\").isNotNull() &\n",
    "        col(\"year\").isNotNull() &\n",
    "        col(\"score\").isNotNull() &\n",
    "        col(\"selectionMethodId\").isNotNull() \n",
    "        #col(\"subjectGroupId\").isNotNull()\n",
    "    )\n",
    "    .dropDuplicates([\n",
    "        \"schoolId\",\n",
    "        \"majorId\",\n",
    "        \"subjectGroupId\",\n",
    "        \"selectionMethodId\",\n",
    "        \"year\",\n",
    "        \"gradingScaleId\",\n",
    "        \"score\"\n",
    "    ])\n",
    ")\n",
    "# ✅ Bước 1.1: GROUP BY và LẤY TRUNG BÌNH SCORE\n",
    "# Với mỗi (schoolId, majorId, subjectGroupId, selectionMethodId, gradingScaleId, year)\n",
    "# chỉ còn 1 dòng, score = AVG(score)\n",
    "df_benchmark_grouped = (\n",
    "    df_benchmark_base\n",
    "    .groupBy(\n",
    "        \"schoolId\",\n",
    "        \"majorId\",\n",
    "        \"subjectGroupId\",\n",
    "        \"selectionMethodId\",\n",
    "        \"gradingScaleId\",\n",
    "        \"year\"\n",
    "    )\n",
    "    .agg(\n",
    "        round(avg(\"score\"), 2).alias(\"score\")\n",
    "    )\n",
    "    .withColumn(\"created_at\", current_timestamp())\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    ")\n",
    "\n",
    "# Bước 2: tạo ID tăng dần đều\n",
    "window_spec = Window.orderBy(\n",
    "    \"schoolId\",\n",
    "    \"majorId\",\n",
    "    \"subjectGroupId\",\n",
    "    \"selectionMethodId\",\n",
    "    \"gradingScaleId\",\n",
    "    \"year\"\n",
    ")\n",
    "\n",
    "df_benchmark_silver = (\n",
    "    df_benchmark_grouped\n",
    "    .withColumn(\"benchmarkId\", row_number().over(window_spec).cast(\"int\"))\n",
    "    .select(\n",
    "        \"benchmarkId\",\n",
    "        \"schoolId\",\n",
    "        \"majorId\",\n",
    "        \"subjectGroupId\",\n",
    "        \"selectionMethodId\",\n",
    "        \"gradingScaleId\",\n",
    "        \"year\",\n",
    "        \"score\",\n",
    "        \"created_at\",\n",
    "        \"updated_at\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ghi xuống bảng Silver\n",
    "df_benchmark_silver.writeTo(\"nessie.silver_tables.benchmark\").using(\"iceberg\").createOrReplace()\n",
    "\n",
    "print(f\"Đã ghi {df_benchmark_silver.count()} dòng vào benchmark\")\n",
    "\n",
    "# Verify\n",
    "spark.table(\"nessie.silver_tables.benchmark\").show(5, truncate=False)\n",
    "spark.table(\"nessie.silver_tables.benchmark\").groupBy(\"year\").count().orderBy(\"year\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18094e01",
   "metadata": {},
   "source": [
    "## 7. Load Bảng REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dbdfc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAD BẢNG REGION\n",
      "================================================================================\n",
      "Đã ghi 64 dòng vào region\n",
      "+--------+-----------------------+--------------------------+--------------------------+\n",
      "|regionId|regionName             |created_at                |updated_at                |\n",
      "+--------+-----------------------+--------------------------+--------------------------+\n",
      "|01      |Sở GDĐT Hà Nội         |2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "|02      |Sở GDĐT TP. Hồ Chí Minh|2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "|03      |Sở GDĐT Hải Phòng      |2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "|04      |Sở GDĐT Đà Nẵng        |2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "|05      |Sở GDĐT Hà Giang       |2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "|06      |Sở GDĐT Cao Bằng       |2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "|07      |Sở GDĐT Lai Châu       |2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "|08      |Sở GDĐT Lào Cai        |2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "|09      |Sở GDĐT Tuyên Quang    |2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "|10      |Sở GDĐT Lạng Sơn       |2025-11-28 04:35:05.581915|2025-11-28 04:35:05.581915|\n",
      "+--------+-----------------------+--------------------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOAD BẢNG REGION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_region = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"encoding\", \"UTF-8\").csv(\"s3a://bronze/structured_data/region.csv\")\n",
    "df_region_silver = df_region.select(\n",
    "    lpad(col(df_region.columns[0]).cast(\"string\"), 2, \"0\").alias(\"regionId\"),  # Format thành 2 chữ số: \"1\" -> \"01\"\n",
    "    col(df_region.columns[1]).cast(\"string\").alias(\"regionName\"),\n",
    "    current_timestamp().alias(\"created_at\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ").filter(col(\"regionId\").isNotNull() & col(\"regionName\").isNotNull()).dropDuplicates([\"regionId\"])\n",
    "\n",
    "df_region_silver.writeTo(\"nessie.silver_tables.region\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"Đã ghi {df_region_silver.count()} dòng vào region\")\n",
    "\n",
    "# Verify\n",
    "spark.table(\"nessie.silver_tables.region\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6217cf",
   "metadata": {},
   "source": [
    "## 8. Load Bảng STUDENT_SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d52c6fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAD BẢNG STUDENT_SCORES\n",
      "================================================================================\n",
      "Đọc được 993,901 dòng từ năm 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/local/lib/python3.10/socket.py\", line 717, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Không tìm thấy dữ liệu năm 2022\n",
      "Đọc được 1,025,333 dòng từ năm 2023\n",
      "Đọc được 1,061,466 dòng từ năm 2024\n",
      "Đọc được 1,152,914 dòng từ năm 2025\n",
      "\n",
      "Đã load 51 môn học để mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã ghi 5,190,113 dòng vào student_scores\n",
      "\n",
      "Xem mẫu dữ liệu (scores giờ là Map<subjectId, score>):\n",
      "+------------+--------+----+--------------------------------------------------------------------+--------------------------+--------------------------+\n",
      "|studentId   |regionId|year|scores                                                              |created_at                |updated_at                |\n",
      "+------------+--------+----+--------------------------------------------------------------------+--------------------------+--------------------------+\n",
      "|010000022022|01      |2022|{33 -> 8.5, 50 -> 7.5, 4 -> 8.25, 41 -> 8.4, 43 -> 6.75, 14 -> 7.6} |2025-11-28 04:35:11.429135|2025-11-28 04:35:11.429135|\n",
      "|010000072022|01      |2022|{33 -> 8.0, 50 -> 7.5, 4 -> 9.0, 41 -> 7.2, 43 -> 6.0, 14 -> 5.0}   |2025-11-28 04:35:11.429135|2025-11-28 04:35:11.429135|\n",
      "|010000082025|01      |2025|{33 -> 4.0, 50 -> 4.0, 43 -> 6.25}                                  |2025-11-28 04:35:11.429135|2025-11-28 04:35:11.429135|\n",
      "|010000102024|01      |2024|{33 -> 8.25, 50 -> 6.5, 4 -> 8.25, 41 -> 7.4, 43 -> 9.0, 14 -> 9.6} |2025-11-28 04:35:11.429135|2025-11-28 04:35:11.429135|\n",
      "|010000112024|01      |2024|{32 -> 6.25, 9 -> 6.75, 41 -> 7.2, 43 -> 8.5, 12 -> 7.75, 14 -> 9.0}|2025-11-28 04:35:11.429135|2025-11-28 04:35:11.429135|\n",
      "+------------+--------+----+--------------------------------------------------------------------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+-------+\n",
      "|year|  count|\n",
      "+----+-------+\n",
      "|2021| 985353|\n",
      "|2022| 968471|\n",
      "|2023|1021909|\n",
      "|2024|1061466|\n",
      "|2025|1152914|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOAD BẢNG STUDENT_SCORES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Đọc từ nhiều năm\n",
    "years = [2021,2022,2023,2024,2025]\n",
    "all_dfs = []\n",
    "for year in years:\n",
    "    try:\n",
    "        df_year = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"false\").option(\"encoding\", \"UTF-8\").csv(f\"s3a://bronze/structured_data/điểm từng thí sinh/{year}/*.csv\").withColumn(\"Year\", lit(year))\n",
    "        all_dfs.append(df_year)\n",
    "        print(f\"Đọc được {df_year.count():,} dòng từ năm {year}\")\n",
    "    except:\n",
    "        print(f\"Không tìm thấy dữ liệu năm {year}\")\n",
    "\n",
    "df_scores = all_dfs[0]\n",
    "for df in all_dfs[1:]:\n",
    "    df_scores = df_scores.union(df)\n",
    "\n",
    "# Đọc bảng subject để map tên môn -> subjectId\n",
    "df_subject_lookup = spark.table(\"nessie.silver_tables.subject\").select(\"subjectId\", \"subjectName\")\n",
    "subject_map = {row.subjectName: row.subjectId for row in df_subject_lookup.collect()}\n",
    "print(f\"\\nĐã load {len(subject_map)} môn học để mapping\")\n",
    "\n",
    "# UDF để parse điểm và map với subjectId\n",
    "from typing import Dict\n",
    "def parse_scores_with_subject_id(score_string: str) -> Dict[int, float]:\n",
    "    if not score_string or score_string.strip() == \"\":\n",
    "        return {}\n",
    "    scores_dict = {}\n",
    "    try:\n",
    "        pairs = score_string.split(\",\")\n",
    "        for pair in pairs:\n",
    "            if \":\" in pair:\n",
    "                subject_name, score = pair.split(\":\")\n",
    "                subject_name = subject_name.strip()\n",
    "                # Map tên môn -> subjectId\n",
    "                if subject_name in subject_map:\n",
    "                    subject_id = subject_map[subject_name]\n",
    "                    try:\n",
    "                        scores_dict[subject_id] = float(score.strip())\n",
    "                    except:\n",
    "                        pass\n",
    "    except:\n",
    "        pass\n",
    "    return scores_dict\n",
    "\n",
    "parse_scores_udf = udf(parse_scores_with_subject_id, MapType(IntegerType(), DoubleType()))\n",
    "\n",
    "# Transform\n",
    "df_student_scores_silver = df_scores.withColumn(\"studentId\", concat(col(\"SBD\"), col(\"Year\").cast(\"string\"))).withColumn(\"scores\", parse_scores_udf(col(\"DiemThi\"))).withColumn(\"regionId\", substring(col(\"SBD\"), 1, 2).cast(\"string\")).select(\n",
    "    col(\"studentId\").cast(\"string\"),\n",
    "    col(\"regionId\").cast(\"string\"),\n",
    "    col(\"Year\").cast(\"int\").alias(\"year\"),\n",
    "    col(\"scores\"),\n",
    "    current_timestamp().alias(\"created_at\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ").filter(col(\"studentId\").isNotNull() & col(\"year\").isNotNull() & col(\"scores\").isNotNull()).dropDuplicates([\"studentId\"])\n",
    "\n",
    "df_student_scores_silver.writeTo(\"nessie.silver_tables.student_scores\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"Đã ghi {df_student_scores_silver.count():,} dòng vào student_scores\")\n",
    "\n",
    "# Verify\n",
    "print(\"\\nXem mẫu dữ liệu (scores giờ là Map<subjectId, score>):\")\n",
    "spark.table(\"nessie.silver_tables.student_scores\").show(5, truncate=False)\n",
    "spark.table(\"nessie.silver_tables.student_scores\").groupBy(\"year\").count().orderBy(\"year\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Load Bảng ARTICLE và COMMENT từ TikTok Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import regexp_extract, split, size, when\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LOAD BẢNG ARTICLE VÀ COMMENT TỪ TIKTOK DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Đọc tất cả file CSV trong thư mục tiktok-data\n",
    "tiktok_files = [\n",
    "    \"s3a://bronze/tiktok-data/tiktok_comments_2025-11-07T07-09-34.csv\",\n",
    "    \"s3a://bronze/tiktok-data/tiktok_comments_2025-11-07T07-11-15.csv\"\n",
    "]\n",
    "\n",
    "# Khởi tạo ID counter cho article\n",
    "article_counter = 1\n",
    "comment_counter = 1\n",
    "\n",
    "# Danh sách để chứa tất cả article và comment\n",
    "all_articles = []\n",
    "all_comments = []\n",
    "\n",
    "for file_path in tiktok_files:\n",
    "    try:\n",
    "        print(f\"\\nXử lý file: {file_path}\")\n",
    "        \n",
    "        # Đọc file CSV với encoding UTF-8\n",
    "        df_raw = spark.read.option(\"header\", \"false\").option(\"encoding\", \"UTF-8\").csv(file_path)\n",
    "        \n",
    "        # Lấy thông tin metadata từ các dòng đầu\n",
    "        rows = df_raw.collect()\n",
    "        \n",
    "        # Parse thông tin article từ metadata\n",
    "        post_url = \"\"\n",
    "        author = \"\"\n",
    "        tag_name = \"\"\n",
    "        author_url = \"\"\n",
    "        time_publish = \"\"\n",
    "        like_count = 0\n",
    "        comment_count = 0\n",
    "        share_count = 0\n",
    "        title = \"\"  # Mô tả của bài đăng\n",
    "        \n",
    "        for row in rows[:15]:  # Chỉ xem 15 dòng đầu để lấy metadata\n",
    "            line = row[0] if row[0] else \"\"\n",
    "            \n",
    "            if \"Post URL:\" in line:\n",
    "                post_url = line.split(\"Post URL:\")[1].strip()\n",
    "            elif \"Người đăng:\" in line:\n",
    "                author = line.split(\"Người đăng:\")[1].strip()\n",
    "            elif \"Tag người đăng:\" in line:\n",
    "                tag_name = line.split(\"Tag người đăng:\")[1].strip()\n",
    "            elif \"URL người đăng:\" in line:\n",
    "                author_url = line.split(\"URL người đăng:\")[1].strip()\n",
    "            elif \"Thời gian đăng:\" in line:\n",
    "                time_str = line.split(\"Thời gian đăng:\")[1].strip()\n",
    "                # Convert format \"2-7-2024\" to timestamp\n",
    "                try:\n",
    "                    time_publish = datetime.strptime(time_str, \"%d-%m-%Y\")\n",
    "                except:\n",
    "                    time_publish = datetime.now()\n",
    "            elif \"Số lượt tym:\" in line:\n",
    "                tym_str = line.split(\"Số lượt tym:\")[1].strip()\n",
    "                try:\n",
    "                    if \"K\" in tym_str:\n",
    "                        like_count = int(float(tym_str.replace(\"K\", \"\")) * 1000)\n",
    "                    else:\n",
    "                        like_count = int(tym_str)\n",
    "                except:\n",
    "                    like_count = 0\n",
    "            elif \"Số lượt comment:\" in line:\n",
    "                try:\n",
    "                    comment_count = int(line.split(\"Số lượt comment:\")[1].strip())\n",
    "                except:\n",
    "                    comment_count = 0\n",
    "            elif \"Số lượt share:\" in line:\n",
    "                share_str = line.split(\"Số lượt share:\")[1].strip()\n",
    "                try:\n",
    "                    if share_str != \"N/A\":\n",
    "                        share_count = int(share_str)\n",
    "                    else:\n",
    "                        share_count = 0\n",
    "                except:\n",
    "                    share_count = 0\n",
    "            elif \"Mô tả của bài đăng:\" in line:\n",
    "                title = line.split(\"Mô tả của bài đăng:\")[1].strip().strip('\"')\n",
    "        \n",
    "        # Tạo record cho bảng article\n",
    "        article_data = {\n",
    "            \"articleID\": article_counter,\n",
    "            \"title\": title,\n",
    "            \"description\": None,  # Để null như yêu cầu\n",
    "            \"author\": author,\n",
    "            \"url\": post_url,\n",
    "            \"timePublish\": time_publish,\n",
    "            \"likeCount\": like_count,\n",
    "            \"commentCount\": comment_count,\n",
    "            \"shareCount\": share_count,\n",
    "            \"type\": \"TikTok\",\n",
    "            \"created_at\": datetime.now(),\n",
    "            \"updated_at\": datetime.now()\n",
    "        }\n",
    "        all_articles.append(article_data)\n",
    "        \n",
    "        # Tìm dòng header của comment (STT,Tên,Tag tên,...)\n",
    "        header_row_index = -1\n",
    "        for i, row in enumerate(rows):\n",
    "            if row[0] and \"STT,Tên,Tag tên\" in row[0]:\n",
    "                header_row_index = i\n",
    "                break\n",
    "        \n",
    "        if header_row_index >= 0:\n",
    "            # Đọc lại file từ dòng comment data\n",
    "            df_comments_raw = spark.read.option(\"header\", \"true\").option(\"encoding\", \"UTF-8\").csv(file_path)\n",
    "            \n",
    "            # Lọc chỉ lấy các dòng là comment (bắt đầu từ dòng có STT)\n",
    "            df_comments = df_comments_raw.filter(\n",
    "                col(\"STT\").cast(\"int\").isNotNull() & \n",
    "                col(\"STT\") != \"STT\"\n",
    "            )\n",
    "            \n",
    "            # Thu thập comment data\n",
    "            comment_rows = df_comments.collect()\n",
    "            \n",
    "            for row in comment_rows:\n",
    "                try:\n",
    "                    # Parse thời gian comment\n",
    "                    comment_time_str = row[\"Time\"] if row[\"Time\"] else \"\"\n",
    "                    comment_time = None\n",
    "                    try:\n",
    "                        comment_time = datetime.strptime(comment_time_str, \"%d-%m-%Y\")\n",
    "                    except:\n",
    "                        comment_time = datetime.now()\n",
    "                    \n",
    "                    # Xác định level comment\n",
    "                    level_comment = 2 if row[\"Level Comment\"] == \"Yes\" else 1\n",
    "                    \n",
    "                    # Parse reply info\n",
    "                    reply_to = row[\"Replied To Tag Name\"] if row[\"Replied To Tag Name\"] and row[\"Replied To Tag Name\"] != \"---\" else None\n",
    "                    \n",
    "                    comment_data = {\n",
    "                        \"commentID\": comment_counter,\n",
    "                        \"articleID\": article_counter,\n",
    "                        \"name\": row[\"Tên\"] if row[\"Tên\"] else \"\",\n",
    "                        \"tagName\": row[\"Tag tên\"] if row[\"Tag tên\"] else \"\",\n",
    "                        \"urlUser\": row[\"URL\"] if row[\"URL\"] else \"\",\n",
    "                        \"comment\": row[\"Comment\"] if row[\"Comment\"] else \"\",\n",
    "                        \"commentTime\": comment_time,\n",
    "                        \"commentLike\": int(row[\"Likes\"]) if row[\"Likes\"] and row[\"Likes\"].isdigit() else 0,\n",
    "                        \"levelComment\": level_comment,\n",
    "                        \"replyTo\": reply_to,\n",
    "                        \"numberOfReply\": int(row[\"Number of Replies\"]) if row[\"Number of Replies\"] and row[\"Number of Replies\"].isdigit() else 0,\n",
    "                        \"created_at\": datetime.now(),\n",
    "                        \"updated_at\": datetime.now()\n",
    "                    }\n",
    "                    all_comments.append(comment_data)\n",
    "                    comment_counter += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Lỗi xử lý comment: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        article_counter += 1\n",
    "        print(f\"Đã xử lý xong file {file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi xử lý file {file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTổng số article: {len(all_articles)}\")\n",
    "print(f\"Tổng số comment: {len(all_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo DataFrame cho article\n",
    "if all_articles:\n",
    "    article_schema = StructType([\n",
    "        StructField(\"articleID\", IntegerType(), False),\n",
    "        StructField(\"title\", StringType(), True),\n",
    "        StructField(\"description\", StringType(), True),\n",
    "        StructField(\"author\", StringType(), True),\n",
    "        StructField(\"url\", StringType(), True),\n",
    "        StructField(\"timePublish\", TimestampType(), True),\n",
    "        StructField(\"likeCount\", IntegerType(), True),\n",
    "        StructField(\"commentCount\", IntegerType(), True),\n",
    "        StructField(\"shareCount\", IntegerType(), True),\n",
    "        StructField(\"type\", StringType(), True),\n",
    "        StructField(\"created_at\", TimestampType(), True),\n",
    "        StructField(\"updated_at\", TimestampType(), True)\n",
    "    ])\n",
    "    \n",
    "    df_article_silver = spark.createDataFrame(all_articles, article_schema)\n",
    "    \n",
    "    # Ghi vào bảng article\n",
    "    df_article_silver.writeTo(\"nessie.silver_tables.article\").using(\"iceberg\").createOrReplace()\n",
    "    print(f\"Đã ghi {df_article_silver.count()} dòng vào bảng article\")\n",
    "    \n",
    "    # Verify\n",
    "    spark.table(\"nessie.silver_tables.article\").show(5, truncate=False)\n",
    "else:\n",
    "    print(\"Không có dữ liệu article để ghi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo DataFrame cho comment\n",
    "if all_comments:\n",
    "    comment_schema = StructType([\n",
    "        StructField(\"commentID\", IntegerType(), False),\n",
    "        StructField(\"articleID\", IntegerType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"tagName\", StringType(), True),\n",
    "        StructField(\"urlUser\", StringType(), True),\n",
    "        StructField(\"comment\", StringType(), True),\n",
    "        StructField(\"commentTime\", TimestampType(), True),\n",
    "        StructField(\"commentLike\", IntegerType(), True),\n",
    "        StructField(\"levelComment\", IntegerType(), True),\n",
    "        StructField(\"replyTo\", StringType(), True),\n",
    "        StructField(\"numberOfReply\", IntegerType(), True),\n",
    "        StructField(\"created_at\", TimestampType(), True),\n",
    "        StructField(\"updated_at\", TimestampType(), True)\n",
    "    ])\n",
    "    \n",
    "    df_comment_silver = spark.createDataFrame(all_comments, comment_schema)\n",
    "    \n",
    "    # Ghi vào bảng comment\n",
    "    df_comment_silver.writeTo(\"nessie.silver_tables.comment\").using(\"iceberg\").createOrReplace()\n",
    "    print(f\"Đã ghi {df_comment_silver.count()} dòng vào bảng comment\")\n",
    "    \n",
    "    # Verify\n",
    "    spark.table(\"nessie.silver_tables.comment\").show(5, truncate=False)\n",
    "    \n",
    "    # Thống kê theo article\n",
    "    print(\"\\nThống kê comment theo article:\")\n",
    "    spark.table(\"nessie.silver_tables.comment\").groupBy(\"articleID\").count().orderBy(\"articleID\").show()\n",
    "else:\n",
    "    print(\"Không có dữ liệu comment để ghi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
