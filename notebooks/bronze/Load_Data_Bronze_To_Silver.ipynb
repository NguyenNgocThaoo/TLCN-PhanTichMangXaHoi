{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c24213a7",
   "metadata": {},
   "source": [
    "# Load Data từ Bronze Layer sang Silver Layer\n",
    "\n",
    "Notebook này sẽ đọc dữ liệu từ Bronze layer (MinIO) và xử lý để load vào các bảng Iceberg trong Silver layer với Nessie catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063eaad0",
   "metadata": {},
   "source": [
    "## 1. Import Libraries và Khởi tạo Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed44bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Spark Session initialized | Master: spark://spark-master:7077 | App ID: app-20251205101919-0001\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import csv, io, os, re\n",
    "from datetime import datetime\n",
    "from typing import Dict\n",
    "\n",
    "# Cấu hình AWS/MinIO credentials\n",
    "os.environ.update({\n",
    "    'AWS_REGION': 'us-east-1',\n",
    "    'AWS_ACCESS_KEY_ID': 'admin',\n",
    "    'AWS_SECRET_ACCESS_KEY': 'admin123'\n",
    "})\n",
    "\n",
    "# Khởi tạo Spark Session với Nessie Catalog\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Load_Bronze_To_Silver\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    # Nessie Catalog\n",
    "    .config(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "    .config(\"spark.sql.catalog.nessie.uri\", \"http://nessie:19120/api/v2\")\n",
    "    .config(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "    .config(\"spark.sql.catalog.nessie.warehouse\", \"s3a://silver/\")\n",
    "    .config(\"spark.sql.catalog.nessie.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    # S3/MinIO Config\n",
    "    .config(\"spark.sql.catalog.nessie.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.access-key-id\", \"admin\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.secret-access-key\", \"admin123\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.path-style-access\", \"true\")\n",
    "    .config(\"spark.sql.catalog.nessie.s3.region\", \"us-east-1\")\n",
    "    # Hadoop S3A Config\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"admin123\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .config(\"spark.hadoop.fs.s3a.region\", \"us-east-1\")\n",
    "    # Executor Environment\n",
    "    .config(\"spark.executorEnv.AWS_REGION\", \"us-east-1\")\n",
    "    .config(\"spark.executorEnv.AWS_ACCESS_KEY_ID\", \"admin\")\n",
    "    .config(\"spark.executorEnv.AWS_SECRET_ACCESS_KEY\", \"admin123\")\n",
    "    # Local JAR files\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/hadoop-aws-3.3.4.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS nessie.silver_tables\")\n",
    "spark.sql(\"USE nessie.silver_tables\")\n",
    "print(f\" Spark Session initialized | Master: {spark.sparkContext.master} | App ID: {spark.sparkContext.applicationId}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43664703",
   "metadata": {},
   "source": [
    "## 2. Load Bảng SCHOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88066c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SCHOOL: Danh sách trường đại học từ 2021-2025\n",
    "base_path = \"s3a://bronze/structured_data/danh sách các trường Đại Học (2021-2025)/Danh_sách_các_trường_Đại_Học_\"\n",
    "df_school = (\n",
    "    spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\")\n",
    "    .csv([f\"{base_path}{year}.csv\" for year in range(2021, 2026)])\n",
    "    .select(\"TenTruong\", \"MaTruong\", \"TinhThanh\")\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "df_school_silver = df_school.select(\n",
    "    col(\"MaTruong\").cast(\"string\").alias(\"schoolId\"),\n",
    "    col(\"TenTruong\").cast(\"string\").alias(\"schoolName\"),\n",
    "    col(\"TinhThanh\").cast(\"string\").alias(\"province\"),\n",
    "    current_timestamp().alias(\"created_at\"),\n",
    "    current_timestamp().alias(\"updated_at\")\n",
    ").filter(col(\"schoolId\").isNotNull() & col(\"schoolName\").isNotNull())\n",
    "\n",
    "df_school_silver.writeTo(\"nessie.silver_tables.school\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"✅ SCHOOL: {df_school_silver.count()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0235c2c",
   "metadata": {},
   "source": [
    "## 3. Load Bảng MAJOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MAJOR: Danh sách ngành đại học, dedupe theo lowercase majorId\n",
    "df_major = (\n",
    "    spark.read.option(\"header\", \"true\").option(\"encoding\", \"UTF-8\")\n",
    "    .csv(\"s3a://bronze/structured_data/danh sách các ngành đại học/Danh_sách_các_ngành.csv\")\n",
    ")\n",
    "\n",
    "df_major_silver = (\n",
    "    df_major.select(\n",
    "        regexp_replace(trim(col(df_major.columns[0])), r\"\\.0$\", \"\").alias(\"majorId\"),\n",
    "        trim(col(df_major.columns[1])).alias(\"majorName\")\n",
    "    )\n",
    "    .filter(\n",
    "        col(\"majorId\").isNotNull() & (col(\"majorId\") != \"\") &\n",
    "        col(\"majorName\").isNotNull() & (col(\"majorName\") != \"\") &\n",
    "        (lower(col(\"majorId\")) != \"nan\")\n",
    "    )\n",
    "    .withColumn(\"majorId_lower\", lower(col(\"majorId\")))\n",
    "    .dropDuplicates([\"majorId_lower\"])\n",
    "    .select(\n",
    "        col(\"majorId\"),\n",
    "        col(\"majorName\"),\n",
    "        current_timestamp().alias(\"created_at\"),\n",
    "        current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df_major_silver.writeTo(\"nessie.silver_tables.major\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"✅ MAJOR: {df_major_silver.count()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d64a8",
   "metadata": {},
   "source": [
    "## 4. Load Bảng SUBJECT_GROUP và SUBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SUBJECT_GROUP & SUBJECT: Tổ hợp môn thi và danh sách môn học\n",
    "df_tohop = spark.read.option(\"header\", \"true\").option(\"encoding\", \"UTF-8\").csv(\"s3a://bronze/structured_data/tohop_mon_fixed.csv\")\n",
    "\n",
    "# Subject Group\n",
    "df_subject_group_silver = (\n",
    "    df_tohop.select(\n",
    "        col(df_tohop.columns[0]).cast(\"int\").alias(\"subjectGroupId\"),\n",
    "        col(df_tohop.columns[1]).alias(\"subjectGroupName\"),\n",
    "        col(df_tohop.columns[2]).alias(\"subjectCombination\"),\n",
    "        current_timestamp().alias(\"created_at\"),\n",
    "        current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    "    .filter(col(\"subjectGroupId\").isNotNull() & col(\"subjectGroupName\").isNotNull())\n",
    "    .dropDuplicates([\"subjectGroupName\", \"subjectCombination\"])\n",
    ")\n",
    "df_subject_group_silver.writeTo(\"nessie.silver_tables.subject_group\").using(\"iceberg\").createOrReplace()\n",
    "\n",
    "# Subject: Tách từ subjectCombination, dedupe theo lowercase\n",
    "df_subject_silver = (\n",
    "    df_tohop.select(explode(split(col(df_tohop.columns[2]), \"-\")).alias(\"subjectName\"))\n",
    "    .withColumn(\"subjectName\", trim(col(\"subjectName\")))\n",
    "    .filter(col(\"subjectName\").isNotNull() & (col(\"subjectName\") != \"\"))\n",
    "    .withColumn(\"subjectName_lower\", lower(col(\"subjectName\")))\n",
    "    .dropDuplicates([\"subjectName_lower\"])\n",
    "    .withColumn(\"subjectId\", row_number().over(Window.orderBy(\"subjectName_lower\")))\n",
    "    .select(\n",
    "        col(\"subjectId\").cast(\"int\"),\n",
    "        col(\"subjectName\"),\n",
    "        current_timestamp().alias(\"created_at\"),\n",
    "        current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    ")\n",
    "df_subject_silver.writeTo(\"nessie.silver_tables.subject\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"✅ SUBJECT_GROUP: {df_subject_group_silver.count()} | SUBJECT: {df_subject_silver.count()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6236f",
   "metadata": {},
   "source": [
    "## 5. Load Bảng SELECTION_METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SELECTION_METHOD: Phương thức xét tuyển (trích từ benchmark, loại bỏ \"năm YYYY\")\n",
    "df_benchmark = spark.read.option(\"header\", \"true\").option(\"encoding\", \"UTF-8\").csv(\n",
    "    \"s3a://bronze/structured_data/điểm chuẩn các trường (2021-2025)/Điểm_chuẩn_các_ngành_đại_học_năm(2021-2025)*.csv\"\n",
    ")\n",
    "\n",
    "df_selection_method_silver = (\n",
    "    df_benchmark.select(trim(regexp_replace(col(\"PhuongThuc\"), r\"\\s*năm\\s+\\d{4}.*$\", \"\")).alias(\"selectionMethodName\"))\n",
    "    .filter(col(\"selectionMethodName\").isNotNull() & (col(\"selectionMethodName\") != \"\"))\n",
    "    .distinct()\n",
    "    .withColumn(\"selectionMethodId\", row_number().over(Window.orderBy(\"selectionMethodName\")))\n",
    "    .select(\n",
    "        col(\"selectionMethodId\").cast(\"int\"),\n",
    "        col(\"selectionMethodName\"),\n",
    "        current_timestamp().alias(\"created_at\"),\n",
    "        current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    ")\n",
    "df_selection_method_silver.writeTo(\"nessie.silver_tables.selection_method\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"✅ SELECTION_METHOD: {df_selection_method_silver.count()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911622a",
   "metadata": {},
   "source": [
    "## 6. Load Bảng GradingScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca8916-830b-4f32-bbbb-d0ac527e6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD GRADING_SCALE: Phân loại thang điểm (trích từ benchmark, extract số từ description)\n",
    "df_grading_scale_silver = (\n",
    "    spark.read.option(\"header\", \"true\").option(\"encoding\", \"UTF-8\")\n",
    "    .csv(\"s3a://bronze/structured_data/điểm chuẩn các trường (2021-2025)/Điểm_chuẩn_các_ngành_đại_học_năm(2021-2025)*.csv\")\n",
    "    .select(trim(col(\"PhanLoaiThangDiem\")).alias(\"description\"))\n",
    "    .filter(col(\"description\").isNotNull() & (col(\"description\") != \"\"))\n",
    "    .dropDuplicates([\"description\"])\n",
    "    .withColumn(\"value\", regexp_extract(col(\"description\"), r\"(\\d+(?:\\.\\d+)?)\", 1).cast(\"float\"))\n",
    "    .withColumn(\"gradingScaleId\", monotonically_increasing_id().cast(\"int\"))\n",
    "    .select(\n",
    "        \"gradingScaleId\",\n",
    "        \"value\",\n",
    "        \"description\",\n",
    "        current_timestamp().alias(\"created_at\"),\n",
    "        current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    ")\n",
    "df_grading_scale_silver.writeTo(\"nessie.silver_tables.grading_scale\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"✅ GRADING_SCALE: {df_grading_scale_silver.count()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036e97a-c555-43a0-a6d4-fb1e673edf0f",
   "metadata": {},
   "source": [
    "## 6. Load Bảng BENCHMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24de0240-da7e-4d00-8870-78bfa419516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 2) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BENCHMARK: 163399 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# LOAD BENCHMARK: Điểm chuẩn xét tuyển, join với lookup tables, group by trính trùng lặp\n",
    "df_benchmark_raw = (\n",
    "    spark.read.option(\"header\", \"true\").option(\"encoding\", \"UTF-8\")\n",
    "    .csv(\"s3a://bronze/structured_data/điểm chuẩn các trường (2021-2025)/Điểm_chuẩn_các_ngành_đại_học_năm(2021-2025)*.csv\")\n",
    "    .withColumn(\"PhuongThuc_cleaned\", trim(regexp_replace(col(\"PhuongThuc\"), r\"\\s*năm\\s+\\d{4}.*$\", \"\")))\n",
    ")\n",
    "\n",
    "# Join với lookup tables\n",
    "df_benchmark_joined = (\n",
    "    df_benchmark_raw\n",
    "    .join(spark.table(\"nessie.silver_tables.selection_method\"), \n",
    "          df_benchmark_raw[\"PhuongThuc_cleaned\"] == col(\"selectionMethodName\"), \"left\")\n",
    "    .join(spark.table(\"nessie.silver_tables.subject_group\"), \n",
    "          df_benchmark_raw[\"KhoiThi\"] == col(\"subjectGroupName\"), \"left\")\n",
    "    .join(spark.table(\"nessie.silver_tables.grading_scale\"), \n",
    "          trim(df_benchmark_raw[\"PhanLoaiThangDiem\"]) == col(\"description\"), \"left\")\n",
    "    .select(\n",
    "        col(\"MaTruong\").cast(\"string\").alias(\"schoolId\"),\n",
    "        col(\"MaNganh\").cast(\"string\").alias(\"majorId\"),\n",
    "        col(\"subjectGroupId\").cast(\"int\"),\n",
    "        col(\"selectionMethodId\").cast(\"int\"),\n",
    "        col(\"gradingScaleId\").cast(\"int\"),\n",
    "        col(\"Nam\").cast(\"int\").alias(\"year\"),\n",
    "        col(\"DiemChuan\").cast(\"double\").alias(\"score\")\n",
    "    )\n",
    "    .filter(\n",
    "        col(\"schoolId\").isNotNull() & col(\"majorId\").isNotNull() &\n",
    "        col(\"gradingScaleId\").isNotNull() & col(\"year\").isNotNull() &\n",
    "        col(\"score\").isNotNull() & col(\"selectionMethodId\").isNotNull()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Group by để tránh trùng, lấy AVG score\n",
    "df_benchmark_silver = (\n",
    "    df_benchmark_joined\n",
    "    .groupBy(\"schoolId\", \"majorId\", \"subjectGroupId\", \"selectionMethodId\", \"gradingScaleId\", \"year\")\n",
    "    .agg(round(avg(\"score\"), 2).alias(\"score\"))\n",
    "    .withColumn(\"benchmarkId\", row_number().over(\n",
    "        Window.orderBy(\"schoolId\", \"majorId\", \"subjectGroupId\", \"selectionMethodId\", \"gradingScaleId\", \"year\")\n",
    "    ).cast(\"int\"))\n",
    "    .select(\n",
    "        \"benchmarkId\", \"schoolId\", \"majorId\", \"subjectGroupId\", \n",
    "        \"selectionMethodId\", \"gradingScaleId\", \"year\", \"score\",\n",
    "        current_timestamp().alias(\"created_at\"),\n",
    "        current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df_benchmark_silver.writeTo(\"nessie.silver_tables.benchmark\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"✅ BENCHMARK: {df_benchmark_silver.count()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18094e01",
   "metadata": {},
   "source": [
    "## 7. Load Bảng REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdfc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD REGION: Danh sách vùng thi, format regionId thành 2 chữ số (01, 02, ...)\n",
    "df_region = spark.read.option(\"header\", \"true\").option(\"encoding\", \"UTF-8\").csv(\"s3a://bronze/structured_data/region.csv\")\n",
    "df_region_silver = (\n",
    "    df_region.select(\n",
    "        lpad(col(df_region.columns[0]).cast(\"string\"), 2, \"0\").alias(\"regionId\"),\n",
    "        col(df_region.columns[1]).alias(\"regionName\"),\n",
    "        current_timestamp().alias(\"created_at\"),\n",
    "        current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    "    .filter(col(\"regionId\").isNotNull() & col(\"regionName\").isNotNull())\n",
    "    .dropDuplicates([\"regionId\"])\n",
    ")\n",
    "df_region_silver.writeTo(\"nessie.silver_tables.region\").using(\"iceberg\").createOrReplace()\n",
    "print(f\"✅ REGION: {df_region_silver.count()} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6217cf",
   "metadata": {},
   "source": [
    "## 8. Load Bảng STUDENT_SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD STUDENT_SCORES: Điểm thi từng thí sinh (2021-2025), parse scores thành Map<subjectId, score>\n",
    "df_scores = None\n",
    "for year in range(2021, 2026):\n",
    "    try:\n",
    "        df_year = (\n",
    "            spark.read.option(\"header\", \"true\").option(\"encoding\", \"UTF-8\")\n",
    "            .csv(f\"s3a://bronze/structured_data/điểm từng thí sinh/{year}/*.csv\")\n",
    "            .withColumn(\"Year\", lit(year))\n",
    "        )\n",
    "        df_scores = df_year if df_scores is None else df_scores.union(df_year)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Tạo subject map để convert tên môn -> subjectId\n",
    "subject_map = {row.subjectName: row.subjectId for row in \n",
    "               spark.table(\"nessie.silver_tables.subject\").select(\"subjectId\", \"subjectName\").collect()}\n",
    "\n",
    "# UDF parse scores: \"Toán:8.5,Văn:7.0\" -> {1: 8.5, 2: 7.0}\n",
    "def parse_scores(score_str: str) -> Dict[int, float]:\n",
    "    if not score_str or not score_str.strip(): return {}\n",
    "    result = {}\n",
    "    try:\n",
    "        for pair in score_str.split(\",\"):\n",
    "            if \":\" in pair:\n",
    "                name, score = pair.split(\":\")\n",
    "                if name.strip() in subject_map:\n",
    "                    try:\n",
    "                        result[subject_map[name.strip()]] = float(score.strip())\n",
    "                    except:\n",
    "                        pass\n",
    "    except:\n",
    "        pass\n",
    "    return result\n",
    "\n",
    "parse_scores_udf = udf(parse_scores, MapType(IntegerType(), DoubleType()))\n",
    "\n",
    "df_student_scores_silver = (\n",
    "    df_scores\n",
    "    .withColumn(\"studentId\", concat(col(\"SBD\"), col(\"Year\").cast(\"string\")))\n",
    "    .withColumn(\"regionId\", substring(col(\"SBD\"), 1, 2))\n",
    "    .withColumn(\"scores\", parse_scores_udf(col(\"DiemThi\")))\n",
    "    .select(\n",
    "        col(\"studentId\"),\n",
    "        col(\"regionId\"),\n",
    "        col(\"Year\").cast(\"int\").alias(\"year\"),\n",
    "        col(\"scores\"),\n",
    "        current_timestamp().alias(\"created_at\"),\n",
    "        current_timestamp().alias(\"updated_at\")\n",
    "    )\n",
    "    .filter(col(\"studentId\").isNotNull() & col(\"year\").isNotNull() & col(\"scores\").isNotNull())\n",
    "    .dropDuplicates([\"studentId\"])\n",
    ")\n",
    "\n",
    "df_student_scores_silver.writeTo(\"nessie.silver_tables.student_scores\").using(\"iceberg\").createOrReplace()\n",
    "print(f\" STUDENT_SCORES: {df_student_scores_silver.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95322d",
   "metadata": {},
   "source": [
    "## 9. Load Bảng ARTICLE và COMMENT từ TikTok Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TIKTOK ARTICLE & COMMENT: Parse CSV files với metadata ở đầu, comment ở cuối\n",
    "def clean_url(url: str):\n",
    "    \"\"\"Loại bỏ prefix URL TikTok\"\"\"\n",
    "    return url.replace(\"https://www.tiktok.com/\", \"\") if url else url\n",
    "\n",
    "def clean_reply_to(name: str):\n",
    "    \"\"\"Loại bỏ ?lang=vi-VN suffix\"\"\"\n",
    "    return name.replace(\"?lang=vi-VN\", \"\") if name and name.endswith(\"?lang=vi-VN\") else name\n",
    "\n",
    "def parse_number(num_str: str) -> int:\n",
    "    \"\"\"Parse số có thể chứa 'K' (nghìn)\"\"\"\n",
    "    try:\n",
    "        if not num_str or num_str == \"N/A\": return 0\n",
    "        return int(float(num_str.replace(\"K\", \"\")) * 1000) if \"K\" in num_str else int(num_str)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Lấy danh sách files TikTok\n",
    "tiktok_path = \"s3a://bronze/MangXaHoi/tiktok-data/comments/*.csv\"\n",
    "tiktok_files = [row.source_file for row in \n",
    "                spark.read.option(\"header\", \"false\").option(\"encoding\", \"UTF-8\").csv(tiktok_path)\n",
    "                .withColumn(\"source_file\", input_file_name()).select(\"source_file\").distinct().collect()]\n",
    "\n",
    "all_articles, all_comments = [], []\n",
    "article_id, comment_id = 1, 1\n",
    "\n",
    "for file_path in tiktok_files:\n",
    "    rows = spark.read.option(\"header\", \"false\").option(\"encoding\", \"UTF-8\").csv(file_path).collect()\n",
    "    \n",
    "    # Parse metadata từ 20 dòng đầu\n",
    "    metadata = {\"post_url\": \"\", \"author\": \"\", \"timePublish\": datetime.now(), \n",
    "                \"likeCount\": 0, \"commentCount\": 0, \"shareCount\": 0, \"title\": \"\"}\n",
    "    \n",
    "    for i, row in enumerate(rows[:20]):\n",
    "        line = row[0] if row[0] else \"\"\n",
    "        if \"Post URL:\" in line: metadata[\"post_url\"] = line.split(\"Post URL:\")[1].strip()\n",
    "        elif \"Người đăng:\" in line: metadata[\"author\"] = line.split(\"Người đăng:\")[1].strip()\n",
    "        elif \"Thời gian đăng:\" in line:\n",
    "            try: metadata[\"timePublish\"] = datetime.strptime(line.split(\"Thời gian đăng:\")[1].strip(), \"%d-%m-%Y\")\n",
    "            except: pass\n",
    "        elif \"Số lượt tym:\" in line: metadata[\"likeCount\"] = parse_number(line.split(\"Số lượt tym:\")[1].strip())\n",
    "        elif \"Số lượt comment:\" in line: metadata[\"commentCount\"] = parse_number(line.split(\"Số lượt comment:\")[1].strip())\n",
    "        elif \"Số lượt share:\" in line: metadata[\"shareCount\"] = parse_number(line.split(\"Số lượt share:\")[1].strip())\n",
    "        elif \"Mô tả của bài đăng:\" in line:\n",
    "            desc = line.split(\"Mô tả của bài đăng:\")[1].strip()\n",
    "            if desc.endswith('\"') and desc.count('\"') >= 2:\n",
    "                metadata[\"title\"] = desc.strip('\"')\n",
    "            else:\n",
    "                desc_lines = [desc.lstrip('\"')]\n",
    "                for j in range(i+1, len(rows)):\n",
    "                    next_line = rows[j][0] if rows[j][0] else \"\"\n",
    "                    desc_lines.append(next_line)\n",
    "                    if next_line.endswith('\"'): break\n",
    "                metadata[\"title\"] = \"\\n\".join(desc_lines).strip().strip('\"')\n",
    "    \n",
    "    all_articles.append({\n",
    "        \"articleID\": article_id, \"title\": metadata[\"title\"], \"description\": None,\n",
    "        \"author\": metadata[\"author\"], \"url\": clean_url(metadata[\"post_url\"]),\n",
    "        \"timePublish\": metadata[\"timePublish\"], \"likeCount\": metadata[\"likeCount\"],\n",
    "        \"commentCount\": metadata[\"commentCount\"], \"shareCount\": metadata[\"shareCount\"],\n",
    "        \"type\": \"TikTok\", \"created_at\": datetime.now(), \"updated_at\": datetime.now()\n",
    "    })\n",
    "    \n",
    "    # Parse comments bằng CSV reader\n",
    "    text_lines = [r.value or \"\" for r in spark.read.text(file_path).collect()]\n",
    "    header_idx = next((i for i, line in enumerate(text_lines) if line.startswith(\"STT,\") and \"Comment\" in line), -1)\n",
    "    \n",
    "    if header_idx >= 0:\n",
    "        csv_str = \"\\n\".join(text_lines[header_idx:])\n",
    "        for row in csv.DictReader(io.StringIO(csv_str)):\n",
    "            try:\n",
    "                all_comments.append({\n",
    "                    \"commentID\": comment_id, \"articleID\": article_id,\n",
    "                    \"name\": row.get(\"Tên\", \"\"), \"tagName\": row.get(\"Tag tên\", \"\"),\n",
    "                    \"urlUser\": clean_url(row.get(\"URL\", \"\")), \"comment\": row.get(\"Comment\", \"\"),\n",
    "                    \"commentTime\": datetime.strptime(row.get(\"Time\", \"\"), \"%d-%m-%Y\") if row.get(\"Time\") else datetime.now(),\n",
    "                    \"commentLike\": int(row.get(\"Likes\", \"0\")) if row.get(\"Likes\", \"\").isdigit() else 0,\n",
    "                    \"levelComment\": 2 if row.get(\"Level Comment\") == \"Yes\" else 1,\n",
    "                    \"replyTo\": clean_reply_to(row.get(\"Replied To Tag Name\", \"\")) if row.get(\"Replied To Tag Name\") not in [\"\", \"---\"] else None,\n",
    "                    \"numberOfReply\": int(row.get(\"Number of Replies\", \"0\")) if row.get(\"Number of Replies\", \"\").isdigit() else 0,\n",
    "                    \"created_at\": datetime.now(), \"updated_at\": datetime.now()\n",
    "                })\n",
    "                comment_id += 1\n",
    "            except: pass\n",
    "    article_id += 1\n",
    "\n",
    "# Ghi vào Silver\n",
    "article_schema = StructType([StructField(\"articleID\", IntegerType(), False), StructField(\"title\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True), StructField(\"author\", StringType(), True), StructField(\"url\", StringType(), True),\n",
    "    StructField(\"timePublish\", TimestampType(), True), StructField(\"likeCount\", IntegerType(), True),\n",
    "    StructField(\"commentCount\", IntegerType(), True), StructField(\"shareCount\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True), StructField(\"created_at\", TimestampType(), True), StructField(\"updated_at\", TimestampType(), True)])\n",
    "\n",
    "spark.createDataFrame(all_articles, article_schema).writeTo(\"nessie.silver_tables.article\").using(\"iceberg\").createOrReplace()\n",
    "\n",
    "comment_schema = StructType([StructField(\"commentID\", IntegerType(), False), StructField(\"articleID\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True), StructField(\"tagName\", StringType(), True), StructField(\"urlUser\", StringType(), True),\n",
    "    StructField(\"comment\", StringType(), True), StructField(\"commentTime\", TimestampType(), True), StructField(\"commentLike\", IntegerType(), True),\n",
    "    StructField(\"levelComment\", IntegerType(), True), StructField(\"replyTo\", StringType(), True), StructField(\"numberOfReply\", IntegerType(), True),\n",
    "    StructField(\"created_at\", TimestampType(), True), StructField(\"updated_at\", TimestampType(), True)])\n",
    "\n",
    "spark.createDataFrame(all_comments, comment_schema).writeTo(\"nessie.silver_tables.comment\").using(\"iceberg\").createOrReplace()\n",
    "print(f\" TIKTOK - ARTICLE: {len(all_articles)} | COMMENT: {len(all_comments)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo DataFrame cho article\n",
    "if all_articles:\n",
    "    article_schema = StructType([\n",
    "        StructField(\"articleID\", IntegerType(), False),\n",
    "        StructField(\"title\", StringType(), True),\n",
    "        StructField(\"description\", StringType(), True),\n",
    "        StructField(\"author\", StringType(), True),\n",
    "        StructField(\"url\", StringType(), True),\n",
    "        StructField(\"timePublish\", TimestampType(), True),\n",
    "        StructField(\"likeCount\", IntegerType(), True),\n",
    "        StructField(\"commentCount\", IntegerType(), True),\n",
    "        StructField(\"shareCount\", IntegerType(), True),\n",
    "        StructField(\"type\", StringType(), True),\n",
    "        StructField(\"created_at\", TimestampType(), True),\n",
    "        StructField(\"updated_at\", TimestampType(), True)\n",
    "    ])\n",
    "    \n",
    "    df_article_silver = spark.createDataFrame(all_articles, article_schema)\n",
    "    \n",
    "    # Ghi vào bảng article\n",
    "    df_article_silver.writeTo(\"nessie.silver_tables.article\").using(\"iceberg\").createOrReplace()\n",
    "    print(f\"Đã ghi {df_article_silver.count()} dòng vào bảng article\")\n",
    "    \n",
    "    # Verify\n",
    "    # spark.table(\"nessie.silver_tables.article\").show(5, truncate=False)\n",
    "else:\n",
    "    print(\"Không có dữ liệu article để ghi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo DataFrame cho comment\n",
    "if all_comments:\n",
    "    comment_schema = StructType([\n",
    "        StructField(\"commentID\", IntegerType(), False),\n",
    "        StructField(\"articleID\", IntegerType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"tagName\", StringType(), True),\n",
    "        StructField(\"urlUser\", StringType(), True),\n",
    "        StructField(\"comment\", StringType(), True),\n",
    "        StructField(\"commentTime\", TimestampType(), True),\n",
    "        StructField(\"commentLike\", IntegerType(), True),\n",
    "        StructField(\"levelComment\", IntegerType(), True),\n",
    "        StructField(\"replyTo\", StringType(), True),\n",
    "        StructField(\"numberOfReply\", IntegerType(), True),\n",
    "        StructField(\"created_at\", TimestampType(), True),\n",
    "        StructField(\"updated_at\", TimestampType(), True)\n",
    "    ])\n",
    "    \n",
    "    df_comment_silver = spark.createDataFrame(all_comments, comment_schema)\n",
    "    \n",
    "    # Ghi vào bảng comment\n",
    "    df_comment_silver.writeTo(\"nessie.silver_tables.comment\").using(\"iceberg\").createOrReplace()\n",
    "    print(f\"Đã ghi {df_comment_silver.count()} dòng vào bảng comment\")\n",
    "    \n",
    "    # Verify\n",
    "    spark.table(\"nessie.silver_tables.comment\").show(5, truncate=False)\n",
    "    \n",
    "    # Thống kê theo article\n",
    "    print(\"\\nThống kê comment theo article:\")\n",
    "    spark.table(\"nessie.silver_tables.comment\").groupBy(\"articleID\").count().orderBy(\"articleID\").show()\n",
    "else:\n",
    "    print(\"Không có dữ liệu comment để ghi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, trim, current_timestamp\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CẬP NHẬT DESCRIPTION CHO BẢNG ARTICLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ===== 1. Đọc file CSV mô tả =====\n",
    "CSV_PATH = \"s3a://bronze/MangXaHoi/Tiktok-data/sub/*.csv\"  # sửa path cho đúng\n",
    "\n",
    "df_desc_raw = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"false\")\n",
    "        .option(\"encoding\", \"UTF-8\")\n",
    "        .csv(CSV_PATH)\n",
    ")\n",
    "\n",
    "print(f\"Đọc được {df_desc_raw.count():,} dòng từ file mô tả\")\n",
    "\n",
    "# Chuẩn hoá cột ID & Description\n",
    "df_desc = df_desc_raw.select(\n",
    "    trim(col(\"url\")).alias(\"url\"),              # ID trùng với cột url của bảng article\n",
    "    trim(col(\"sub\")).alias(\"new_description\")\n",
    ").filter(col(\"url\").isNotNull() & (col(\"url\") != \"\"))\n",
    "\n",
    "print(f\"Số dòng dùng để cập nhật: {df_desc.count():,}\")\n",
    "\n",
    "# Tạo temp view để dùng trong SQL\n",
    "df_desc.createOrReplaceTempView(\"article_desc_update\")\n",
    "\n",
    "# ===== 2. MERGE vào bảng article =====\n",
    "# Chỉ cập nhật cột description (và updated_at cho tiện)\n",
    "spark.sql(\"\"\"\n",
    "MERGE INTO nessie.silver_tables.article AS a\n",
    "USING article_desc_update AS d\n",
    "ON a.url = d.url\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "  a.description = d.new_description,\n",
    "  a.updated_at = current_timestamp()\n",
    "\"\"\")\n",
    "\n",
    "print(\"Đã cập nhật description cho bảng article!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88959aa4-a9f3-4a7d-904e-9d859de6d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Facebook data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2331c-4b1b-4bdc-be81-b2cc07c9dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Map tháng tiếng Việt -> số\n",
    "MONTH_MAP = {\n",
    "    \"Tháng 1\": \"01\", \"Tháng 2\": \"02\", \"Tháng 3\": \"03\", \"Tháng 4\": \"04\",\n",
    "    \"Tháng 5\": \"05\", \"Tháng 6\": \"06\", \"Tháng 7\": \"07\", \"Tháng 8\": \"08\",\n",
    "    \"Tháng 9\": \"09\", \"Tháng 10\": \"10\", \"Tháng 11\": \"11\", \"Tháng 12\": \"12\"\n",
    "}\n",
    "\n",
    "def parse_vietnam_datetime(dt_str):\n",
    "    \"\"\"\n",
    "    Convert:\n",
    "    'Thứ Sáu, 1 Tháng 8, 2025 lúc 20:18'\n",
    "          ↓\n",
    "    '2025-08-01 20:18:00'\n",
    "    \"\"\"\n",
    "    if not dt_str:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Bỏ tiền tố thứ ngày\n",
    "        # Ví dụ: \"Thứ Sáu, \" → \"\"\n",
    "        dt_str = dt_str.split(\",\", 1)[1].strip()\n",
    "\n",
    "        # dt_str còn lại:\n",
    "        # \"1 Tháng 8, 2025 lúc 20:18\"\n",
    "\n",
    "        # Tách ngày – tháng tiếng Việt\n",
    "        # 1 Tháng 8\n",
    "        match = re.search(r\"(\\d+)\\s+(Tháng\\s+\\d+)\", dt_str)\n",
    "        if not match:\n",
    "            return None\n",
    "\n",
    "        day = match.group(1)\n",
    "        month_text = match.group(2)\n",
    "        month = MONTH_MAP.get(month_text)\n",
    "\n",
    "        # Lấy năm\n",
    "        year_match = re.search(r\",\\s*(\\d{4})\", dt_str)\n",
    "        if not year_match:\n",
    "            return None\n",
    "        year = year_match.group(1)\n",
    "\n",
    "        # Lấy giờ phút\n",
    "        time_match = re.search(r\"lúc\\s+(\\d{1,2}:\\d{2})\", dt_str)\n",
    "        if time_match:\n",
    "            time_str = time_match.group(1)\n",
    "        else:\n",
    "            time_str = \"00:00\"\n",
    "\n",
    "        # Format chuẩn: yyyy-MM-dd HH:mm:ss\n",
    "        final_str = f\"{year}-{month}-{int(day):02d} {time_str}:00\"\n",
    "        return final_str\n",
    "\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "parse_vn_time_udf = udf(parse_vietnam_datetime, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ddb7bd-e1ce-470d-8cf0-ff3a927dd117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "# DELETE FROM nessie.silver_tables.article\n",
    "# WHERE type = 'facebook'\n",
    "# \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5c831-3d1a-49a2-8577-38cb7f3f89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "# DELETE FROM nessie.silver_tables.comment\n",
    "# WHERE articleID NOT IN (\n",
    "#     SELECT articleID FROM nessie.silver_tables.article\n",
    "# )\n",
    "# \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aae2a5-07a5-4c26-8b24-32f59a791240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, trim, current_timestamp, to_timestamp,\n",
    "    row_number, lit, max as F_max\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LOAD DỮ LIỆU FACEBOOK VÀO BẢNG ARTICLE & COMMENT (KHÔNG TRÙNG ID)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "posts_path = \"s3a://bronze/MangXaHoi/Face-data/posts_FB.csv\"\n",
    "comments_path = \"s3a://bronze/MangXaHoi/Face-data/comments_FB.csv\"\n",
    "\n",
    "# ====================================================\n",
    "# 0. LẤY MAX ID HIỆN CÓ TRONG BẢNG\n",
    "# ====================================================\n",
    "# Nếu bảng rỗng thì maxID = None -> dùng 0\n",
    "try:\n",
    "    max_article_row = (\n",
    "        spark.table(\"nessie.silver_tables.article\")\n",
    "             .agg(F_max(\"articleID\").alias(\"maxID\"))\n",
    "             .collect()[0]\n",
    "    )\n",
    "    base_article_id = max_article_row[\"maxID\"] or 0\n",
    "except Exception:\n",
    "    base_article_id = 0\n",
    "\n",
    "try:\n",
    "    max_comment_row = (\n",
    "        spark.table(\"nessie.silver_tables.comment\")\n",
    "             .agg(F_max(\"commentID\").alias(\"maxID\"))\n",
    "             .collect()[0]\n",
    "    )\n",
    "    base_comment_id = max_comment_row[\"maxID\"] or 0\n",
    "except Exception:\n",
    "    base_comment_id = 0\n",
    "\n",
    "print(f\"base_article_id (offset) = {base_article_id}\")\n",
    "print(f\"base_comment_id (offset) = {base_comment_id}\")\n",
    "\n",
    "# ====================================================\n",
    "# 1. ĐỌC BẢNG POSTS_FB -> ARTICLE\n",
    "# ====================================================\n",
    "df_posts_raw = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"false\")\n",
    "        .option(\"encoding\", \"UTF-8\")\n",
    "        .csv(posts_path)\n",
    ")\n",
    "\n",
    "print(f\"Đọc được {df_posts_raw.count():,} dòng từ posts_FB\")\n",
    "\n",
    "df_posts_clean = df_posts_raw.select(\n",
    "    trim(col(\"ID\")).alias(\"url_post\"),      # URL bài viết (dùng để join)\n",
    "    trim(col(\"Title\")).alias(\"title\"),\n",
    "    trim(col(\"Description\")).alias(\"description\"),\n",
    "    trim(col(\"Author\")).alias(\"author\"),\n",
    "    trim(col(\"Url\")).alias(\"url_extra\"),\n",
    "    trim(col(\"TimePublish\")).alias(\"TimePublish_raw\"),\n",
    "    trim(col(\"Like\")).alias(\"Like_raw\"),\n",
    "    trim(col(\"Share\")).alias(\"Share_raw\"),\n",
    "    trim(col(\"Comment\")).alias(\"Comment_raw\")\n",
    ")\n",
    "\n",
    "df_posts_parsed = (\n",
    "    df_posts_clean\n",
    "        # Chuẩn hoá string tiếng Việt -> 'yyyy-MM-dd HH:mm:ss'\n",
    "        .withColumn(\"TimePublish_clean\", parse_vn_time_udf(col(\"TimePublish_raw\")))\n",
    "        # Convert string chuẩn -> timestamp\n",
    "        .withColumn(\"timePublish\", to_timestamp(col(\"TimePublish_clean\")))\n",
    "        .withColumn(\"likeCount\", col(\"Like_raw\").cast(\"int\"))\n",
    "        .withColumn(\"shareCount\", col(\"Share_raw\").cast(\"int\"))\n",
    "        .withColumn(\"commentCount\", col(\"Comment_raw\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Window để đánh số local trong batch FB\n",
    "w_article = Window.orderBy(\"url_post\")\n",
    "\n",
    "df_article_silver = (\n",
    "    df_posts_parsed\n",
    "        # articleID_local: 1,2,3,... trong batch Facebook\n",
    "        .withColumn(\"articleID_local\", row_number().over(w_article))\n",
    "        # articleID thật = offset + local\n",
    "        .withColumn(\n",
    "            \"articleID\",\n",
    "            (col(\"articleID_local\") + lit(base_article_id)).cast(\"int\")\n",
    "        )\n",
    "        .select(\n",
    "            col(\"articleID\"),\n",
    "            col(\"title\"),\n",
    "            col(\"description\"),\n",
    "            col(\"author\"),\n",
    "            col(\"url_post\").alias(\"url\"),\n",
    "            col(\"timePublish\"),\n",
    "            col(\"likeCount\"),\n",
    "            col(\"commentCount\"),\n",
    "            col(\"shareCount\"),\n",
    "            lit(\"facebook\").alias(\"type\"),\n",
    "            current_timestamp().alias(\"created_at\"),\n",
    "            current_timestamp().alias(\"updated_at\")\n",
    "        )\n",
    ")\n",
    "\n",
    "print(\"Mẫu dữ liệu article_silver:\")\n",
    "df_article_silver.show(5, truncate=False)\n",
    "\n",
    "# Ghi vào bảng article\n",
    "df_article_silver.writeTo(\"nessie.silver_tables.article\").using(\"iceberg\").append()\n",
    "print(f\"Đã ghi {df_article_silver.count():,} dòng vào nessie.silver_tables.article\")\n",
    "\n",
    "# Tạo lookup cho batch FB (chỉ cần url & articleID của batch này)\n",
    "df_article_fb_lookup = df_article_silver.select(\"articleID\", \"url\").distinct()\n",
    "\n",
    "# ====================================================\n",
    "# 2. ĐỌC BẢNG COMMENT_FB -> COMMENT, JOIN THEO URL\n",
    "# ====================================================\n",
    "df_cmt_raw = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"false\")\n",
    "        .option(\"encoding\", \"UTF-8\")\n",
    "        .csv(comments_path)\n",
    ")\n",
    "\n",
    "print(f\"Đọc được {df_cmt_raw.count():,} dòng từ comment_FB\")\n",
    "\n",
    "# comment_FB: STT,Id_post,Comment\n",
    "df_cmt_clean = df_cmt_raw.select(\n",
    "    trim(col(\"STT\")).alias(\"stt\"),\n",
    "    trim(col(\"Id_post\")).alias(\"post_url\"),\n",
    "    trim(col(\"Comment\")).alias(\"comment_text\")\n",
    ").filter(col(\"post_url\").isNotNull() & (col(\"post_url\") != \"\"))\n",
    "\n",
    "# JOIN comment với batch article FB vừa tạo (không join toàn bộ bảng để tránh nhầm nguồn khác)\n",
    "df_cmt_joined = (\n",
    "    df_cmt_clean.alias(\"c\")\n",
    "        .join(\n",
    "            df_article_fb_lookup.alias(\"a\"),\n",
    "            col(\"c.post_url\") == col(\"a.url\"),\n",
    "            \"inner\"\n",
    "        )\n",
    ")\n",
    "\n",
    "print(f\"Số dòng comment match với article FB: {df_cmt_joined.count():,}\")\n",
    "\n",
    "# Window để đánh số local comment trong batch FB\n",
    "w_comment = Window.orderBy(col(\"a.articleID\"), col(\"c.stt\"))\n",
    "\n",
    "df_comment_silver = (\n",
    "    df_cmt_joined\n",
    "        .withColumn(\"commentID_local\", row_number().over(w_comment))\n",
    "        .withColumn(\n",
    "            \"commentID\",\n",
    "            (col(\"commentID_local\") + lit(base_comment_id)).cast(\"int\")\n",
    "        )\n",
    "        .select(\n",
    "            col(\"commentID\"),\n",
    "            col(\"a.articleID\").alias(\"articleID\"),\n",
    "            lit(None).cast(\"string\").alias(\"name\"),\n",
    "            lit(None).cast(\"string\").alias(\"tagName\"),\n",
    "            lit(None).cast(\"string\").alias(\"urlUser\"),\n",
    "            col(\"comment_text\").alias(\"comment\"),\n",
    "            lit(None).cast(\"timestamp\").alias(\"commentTime\"),\n",
    "            lit(None).cast(\"int\").alias(\"commentLike\"),\n",
    "            lit(1).cast(\"int\").alias(\"levelComment\"),\n",
    "            lit(None).cast(\"string\").alias(\"replyTo\"),\n",
    "            lit(0).cast(\"int\").alias(\"numberOfReply\"),\n",
    "            current_timestamp().alias(\"created_at\"),\n",
    "            current_timestamp().alias(\"updated_at\")\n",
    "        )\n",
    ")\n",
    "\n",
    "print(\"Mẫu dữ liệu comment_silver:\")\n",
    "df_comment_silver.show(5, truncate=False)\n",
    "\n",
    "df_comment_silver.writeTo(\"nessie.silver_tables.comment\").using(\"iceberg\").append()\n",
    "print(f\"Đã ghi {df_comment_silver.count():,} dòng vào nessie.silver_tables.comment\")\n",
    "\n",
    "# ====================================================\n",
    "# 3. CHECK LẠI\n",
    "# ====================================================\n",
    "print(\"\\nCHECK lại article (facebook):\")\n",
    "spark.table(\"nessie.silver_tables.article\").where(\"type = 'facebook'\").show(5, truncate=False)\n",
    "\n",
    "print(\"\\nCHECK lại comment (facebook, join với article):\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT c.commentID, c.articleID, a.title, c.comment\n",
    "FROM nessie.silver_tables.comment c\n",
    "JOIN nessie.silver_tables.article a\n",
    "  ON c.articleID = a.articleID\n",
    "WHERE a.type = 'facebook'\n",
    "LIMIT 10\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5d23f",
   "metadata": {},
   "source": [
    "## 12. Dừng Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9516960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dừng Spark Session để giải phóng resources\n",
    "spark.stop()\n",
    "print(\" Spark Session đã được dừng!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
